{"type":"system","subtype":"init","cwd":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini","session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","KillShell","AskUserQuestion","Skill","EnterPlanMode","LSP"],"mcp_servers":[],"model":"claude-opus-4-5-20251101","permissionMode":"bypassPermissions","slash_commands":["paper-finder","paper-writer","compact","context","cost","init","pr-comments","release-notes","review","security-review"],"apiKeySource":"none","claude_code_version":"2.0.76","output_style":"default","agents":["general-purpose","statusline-setup","Explore","Plan"],"skills":["paper-finder","paper-writer"],"plugins":[],"uuid":"dc65a04c-b441-4886-8c3f-2504beb1c8db"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Rb39oVnSzQk7eyZNFH8miH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011oipCRr7e14sqF19MDL8X8","name":"Bash","input":{"command":"pwd","description":"Verify current working directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":19049,"cache_read_input_tokens":14993,"cache_creation":{"ephemeral_5m_input_tokens":19049,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"0289f25a-843f-4dec-8437-5006fe992a10"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Rb39oVnSzQk7eyZNFH8miH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YQ2DvykfSpxqfbC1ZVDzzs","name":"Bash","input":{"command":"nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv 2>/dev/null || echo \"NO_GPU\"","description":"Check GPU availability"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":19049,"cache_read_input_tokens":14993,"cache_creation":{"ephemeral_5m_input_tokens":19049,"ephemeral_1h_input_tokens":0},"output_tokens":161,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"806353ca-a652-455c-a235-8997c128dcbb"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011oipCRr7e14sqF19MDL8X8","type":"tool_result","content":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"0084026a-57a3-44e9-9167-5a00aef17218","tool_use_result":{"stdout":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini","stderr":"","interrupted":false,"isImage":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YQ2DvykfSpxqfbC1ZVDzzs","type":"tool_result","content":"name, memory.total [MiB], memory.free [MiB]\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"f5205989-6353-4cf2-9c59-07b9a0a25864","tool_use_result":{"stdout":"name, memory.total [MiB], memory.free [MiB]\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB\nNVIDIA GeForce RTX 3090, 24576 MiB, 24161 MiB","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VpcUeXXDYPesixSkhCLBXy","type":"message","role":"assistant","content":[{"type":"text","text":"I'm in the correct workspace and have access to 2x NVIDIA RTX 3090 GPUs with ~24GB VRAM each. Let me start by reading the pre-gathered resources to understand the research landscape."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":321,"cache_read_input_tokens":34042,"cache_creation":{"ephemeral_5m_input_tokens":321,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"e6530fc1-3268-4b10-9304-173c99bec150"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VpcUeXXDYPesixSkhCLBXy","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019pEZXapHCeN1bsZpJMLkwJ","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/literature_review.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":321,"cache_read_input_tokens":34042,"cache_creation":{"ephemeral_5m_input_tokens":321,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"79bd6160-9a48-4b2c-919d-4364b53fd351"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VpcUeXXDYPesixSkhCLBXy","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01W6vbXTZ7PkXuNcre9CF3cA","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/resources.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":321,"cache_read_input_tokens":34042,"cache_creation":{"ephemeral_5m_input_tokens":321,"ephemeral_1h_input_tokens":0},"output_tokens":196,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"26d9d169-9193-439f-8b8a-df8a8d9a2edd"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019pEZXapHCeN1bsZpJMLkwJ","type":"tool_result","content":"     1→# Literature Review: Evaluating Linguistic Performance in LLMs\n     2→\n     3→## Research Area Overview\n     4→\n     5→This literature review examines recent research on evaluating and understanding multilingual capabilities of Large Language Models (LLMs). The central research hypothesis under investigation is that LLMs trained predominantly on English data may underperform when deployed in non-English-speaking contexts, and that these models may possess implicit internal translation mechanisms that convert non-English inputs to English for processing.\n     6→\n     7→The reviewed papers span four main areas:\n     8→1. **Linguistic discrimination in LLMs** - Safety and quality disparities across languages\n     9→2. **Internal multilingual processing mechanisms** - How LLMs handle non-English inputs\n    10→3. **Multilingual evaluation benchmarks** - Standardized frameworks for cross-lingual assessment\n    11→4. **Comprehensive surveys** - Corpora, alignment, and bias in multilingual LLMs\n    12→\n    13→---\n    14→\n    15→## Key Papers\n    16→\n    17→### Paper 1: Evaluating and Mitigating Linguistic Discrimination in Large Language Models\n    18→\n    19→- **Authors**: Guoliang Dong, Haoyu Wang, Jun Sun, Xinyu Wang\n    20→- **Year**: 2024\n    21→- **Source**: arXiv:2404.18534\n    22→- **PDF**: papers/evaluating_linguistic_discrimination.pdf\n    23→\n    24→**Key Contribution**: Systematically evaluates linguistic discrimination from both safety and quality perspectives, proposing LDFighter as a mitigation strategy.\n    25→\n    26→**Methodology**:\n    27→- Evaluated 4 LLMs: Llama2-13b, Gemma-7b, GPT-3.5-turbo, Gemini-pro\n    28→- Used AdvBench (harmful queries) and NQ (natural questions) datasets\n    29→- Assessed 74 languages for safety (jailbreak rate) and quality (F1 score)\n    30→\n    31→**Key Findings**:\n    32→- **Safety disparities**: High-resource languages (English, French, Russian, Spanish) show 1.04% average jailbreak rate; low-resource languages (Bengali, Georgian, Nepali, Maithili) show 27.7% jailbreak rate\n    33→- **Quality disparities**: English, Danish, Czech, Slovenian achieve 0.1494 average F1; Kannada, Southern Pashto, Tajik, Telugu achieve only 0.0341 average F1\n    34→- **Correlation with training data**: Languages with >0.005% share in pretraining data show better safety performance\n    35→\n    36→**Proposed Solution**: LDFighter - translates queries to top-k languages, gets responses, translates back to pivot language (English), uses similarity-based voting for final answer\n    37→\n    38→**Code Available**: Not mentioned in paper\n    39→\n    40→**Relevance to Hypothesis**: Directly supports the hypothesis - demonstrates significant performance gaps between English and low-resource languages across both safety and quality metrics.\n    41→\n    42→---\n    43→\n    44→### Paper 2: How do Large Language Models Handle Multilingualism?\n    45→\n    46→- **Authors**: Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing\n    47→- **Year**: 2024 (NeurIPS 2024)\n    48→- **Source**: arXiv:2402.18815\n    49→- **PDF**: papers/how_llms_handle_multilingualism.pdf\n    50→\n    51→**Key Contribution**: Proposes and validates the Multilingual Workflow (MWork) hypothesis - that LLMs internally convert non-English queries to English for processing.\n    52→\n    53→**Methodology**:\n    54→- Developed Parallel Language-specific Neuron Detection (PLND) to identify language-specific neurons\n    55→- Tested on multiple benchmarks: XQuAD (understanding), MGSM (reasoning), X-CSQA (knowledge), XLSum (generation)\n    56→- Deactivated language-specific neurons to verify functionality\n    57→\n    58→**Key Findings**:\n    59→- **Three-stage workflow confirmed**:\n    60→  1. **Understanding**: Non-English queries converted to unified (English-centric) representation\n    61→  2. **Task-solving**: Reasoning in English (self-attention) + knowledge extraction (feed-forward)\n    62→  3. **Generation**: Output converted back to original query language\n    63→- Only 0.13% of neurons are language-specific, yet deactivating them causes 99% performance drop on multilingual summarization\n    64→- Deactivating understanding layer neurons: English stable, non-English -14%\n    65→\n    66→**Practical Application**: Fine-tuning language-specific neurons with 400 documents improves high-resource languages by 3.6% and low-resource languages by 2.3%\n    67→\n    68→**Code Available**: https://github.com/DAMO-NLP-SG/multilingual_analysis\n    69→\n    70→**Relevance to Hypothesis**: Strongly supports the hypothesis about implicit translation mechanisms - demonstrates LLMs convert multilingual inputs to English internally for processing.\n    71→\n    72→---\n    73→\n    74→### Paper 3: MuBench: Assessment of Multilingual Capabilities Across 61 Languages\n    75→\n    76→- **Authors**: Wenhan Han, Yifan Zhang, et al.\n    77→- **Year**: 2025\n    78→- **Source**: arXiv:2506.19468\n    79→- **PDF**: papers/mubench.pdf\n    80→\n    81→**Key Contribution**: Comprehensive multilingual benchmark with cross-lingual alignment, introducing Multilingual Consistency (MLC) as a complementary metric.\n    82→\n    83→**Methodology**:\n    84→- 61 languages covering >60% global population\n    85→- Translated widely-used English benchmarks with rigorous quality control\n    86→- Includes code-switched variants for mixed-language evaluation\n    87→- Human evaluation across 16 languages\n    88→\n    89→**Tasks Covered**:\n    90→- Natural Language Understanding: SNLI, MultiNLI, WinoGrande\n    91→- Commonsense Reasoning: HellaSwag, StoryCloze\n    92→- Factual Recall: BMLAMA\n    93→- Knowledge-based QA: MMLU, MMLU Pro\n    94→- Academic & Technical Reasoning: GPQA, ARC-Easy, ARC-Challenge\n    95→- Truthfulness: TruthfulQA\n    96→\n    97→**Key Findings**:\n    98→- Models fall short of claimed multilingual coverage\n    99→- Persistent performance gap between English and low-resource languages\n   100→- Gap does not consistently narrow with increased model size\n   101→- Larger models not necessarily more robust in code-switched settings\n   102→- Parallel corpora improve both accuracy and consistency\n   103→\n   104→**Dataset Available**: https://huggingface.co/datasets/aialt/MuBench\n   105→\n   106→**Relevance to Hypothesis**: Provides empirical evidence for English-centric bias across a wide range of tasks and languages.\n   107→\n   108→---\n   109→\n   110→### Paper 4: GlotEval: A Test Suite for Massively Multilingual Evaluation\n   111→\n   112→- **Authors**: Hengyu Luo, Zihao Li, et al.\n   113→- **Year**: 2025\n   114→- **Source**: arXiv:2504.04155\n   115→- **PDF**: papers/gloteval.pdf\n   116→\n   117→**Key Contribution**: Unified evaluation framework integrating 27 benchmarks with ISO 639-3 standardization, supporting non-English-centric evaluation.\n   118→\n   119→**Methodology**:\n   120→- Standardized all benchmarks to ISO 639-3 language codes\n   121→- Supports 9 key tasks spanning dozens to hundreds of languages\n   122→- Language-specific prompt templates\n   123→- Non-English-centered machine translation evaluation\n   124→\n   125→**Tasks Supported**:\n   126→1. Machine Translation\n   127→2. Text Classification\n   128→3. Summarization\n   129→4. Open-ended Generation\n   130→5. Reading Comprehension\n   131→6. Sequence Labeling\n   132→7. Intrinsic Evaluation\n   133→8. Instruction Following\n   134→9. Reasoning\n   135→\n   136→**Key Features**:\n   137→- Cross-benchmark analysis by language/language group\n   138→- Microsoft Translator integration for prompt propagation (130+ languages)\n   139→- Any language can serve as pivot for translation evaluation\n   140→\n   141→**Code Available**: https://github.com/MaLA-LM/GlotEval\n   142→\n   143→**Relevance to Hypothesis**: Provides the evaluation infrastructure needed to systematically test multilingual LLM performance across diverse languages.\n   144→\n   145→---\n   146→\n   147→### Paper 5: A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias\n   148→\n   149→- **Authors**: Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Kexin Xu, Yuqi Ye, Hanwen Gu\n   150→- **Year**: 2024\n   151→- **Source**: arXiv:2404.00929\n   152→- **PDF**: papers/multilingual_llm_survey.pdf\n   153→\n   154→**Key Contribution**: Comprehensive survey covering MLLMs' evolution, training corpora, multilingual representations, and bias.\n   155→\n   156→**Topics Covered**:\n   157→\n   158→1. **MLLM Overview**: Evolution from mBERT to BLOOM/LLaMA, key techniques, multilingual capacities\n   159→\n   160→2. **Training Corpora Analysis**:\n   161→   - ChatGPT: 92.099% English, only 0.16% Chinese\n   162→   - Language imbalance in major corpora (Wikipedia, Common Crawl)\n   163→   - \"Curse of multilinguality\": more languages help low-resource up to a point, then overall performance decreases\n   164→\n   165→3. **Multilingual Alignment**:\n   166→   - Static, contextual, and combined multilingual representations\n   167→   - Factors affecting alignment: initial alignment solution, mapping linearity, typological distance, pretraining data\n   168→\n   169→4. **Bias in MLLMs**:\n   170→   - Categories of bias\n   171→   - Evaluation metrics\n   172→   - Debiasing techniques\n   173→   - Most bias studies limited to English\n   174→\n   175→**Key Insights**:\n   176→- Scale, quality, and diversity of corpora significantly impact MLLM performance\n   177→- Under-representation of low-resource languages leads to poor performance\n   178→- Universal language representation remains challenging\n   179→\n   180→**Relevance to Hypothesis**: Provides foundational context explaining why LLMs exhibit English-centric bias (training data imbalance) and the challenges in achieving cross-lingual transfer.\n   181→\n   182→---\n   183→\n   184→## Common Methodologies\n   185→\n   186→### Evaluation Approaches\n   187→- **Cross-lingual benchmarks**: Translate English benchmarks to target languages\n   188→- **Language-specific metrics**: Jailbreak rate, F1 score, accuracy by language\n   189→- **Consistency metrics**: Multilingual Consistency (MLC) for aligned samples\n   190→\n   191→### Models Commonly Evaluated\n   192→- GPT-3.5-turbo, GPT-4\n   193→- Gemini-pro\n   194→- LLaMA-2 (7B, 13B)\n   195→- Gemma (7B)\n   196→- BLOOM, BLOOMZ\n   197→- Vicuna\n   198→- Qwen\n   199→\n   200→### Language Categorization\n   201→- **High-resource**: English, French, Spanish, Russian, German, Chinese, Japanese\n   202→- **Mid-resource**: Arabic, Korean, Portuguese, Turkish, Vietnamese, Indonesian\n   203→- **Low-resource**: Bengali, Nepali, Georgian, Maithili, Kannada, Telugu\n   204→\n   205→---\n   206→\n   207→## Standard Baselines\n   208→\n   209→| Baseline Type | Common Approaches |\n   210→|--------------|-------------------|\n   211→| Translation-based | Translate query to English, process, translate back |\n   212→| Direct inference | Run model directly on target language |\n   213→| Zero-shot | No target language examples |\n   214→| Few-shot | Include examples in target language |\n   215→\n   216→---\n   217→\n   218→## Evaluation Metrics\n   219→\n   220→| Metric | Description | Use Case |\n   221→|--------|-------------|----------|\n   222→| Accuracy | Correct answers / Total | General task performance |\n   223→| F1 Score | Harmonic mean of precision/recall | QA tasks |\n   224→| Jailbreak Rate | Successful harmful responses / Total | Safety evaluation |\n   225→| BLEU/chrF++ | Translation quality | Machine translation |\n   226→| Multilingual Consistency (MLC) | Consistency across languages for aligned samples | Cross-lingual transfer |\n   227→\n   228→---\n   229→\n   230→## Datasets in the Literature\n   231→\n   232→### Benchmark Datasets\n   233→| Dataset | Languages | Task | Used By |\n   234→|---------|-----------|------|---------|\n   235→| MMLU | 61 (MuBench) | Knowledge QA | Papers 3, 4 |\n   236→| XNLI | 15 | NLI | Paper 4 |\n   237→| XQuAD | 10 | Reading comprehension | Paper 2 |\n   238→| MGSM | 10 | Math reasoning | Paper 2 |\n   239→| Belebele | 122 | Reading comprehension | Paper 4 |\n   240→| AdvBench | Multi | Safety (jailbreak) | Paper 1 |\n   241→| NQ | Multi | Open-domain QA | Paper 1 |\n   242→| FLORES-200 | 200 | Translation | Paper 4 |\n   243→\n   244→### Training Corpora\n   245→- Common Crawl (mC4, CC-100)\n   246→- Wikipedia (various languages)\n   247→- ROOTS (BLOOM's corpus)\n   248→- Parallel corpora (OPUS, CCAligned)\n   249→\n   250→---\n   251→\n   252→## Gaps and Opportunities\n   253→\n   254→1. **Limited low-resource language evaluation**: Most benchmarks still focus on high-resource languages\n   255→2. **Cultural bias**: Many benchmarks have Western-centric content\n   256→3. **Code-switching**: Mixed-language scenarios underexplored\n   257→4. **Dynamic evaluation**: Most benchmarks are static; no evaluation of adaptation\n   258→5. **Safety in low-resource**: Limited safety evaluation for underrepresented languages\n   259→6. **Mechanistic understanding**: Internal multilingual processing needs more investigation\n   260→\n   261→---\n   262→\n   263→## Recommendations for Our Experiment\n   264→\n   265→### Recommended Datasets\n   266→1. **MuBench** (Primary): 61 languages, multiple tasks, aligned samples, available on HuggingFace\n   267→2. **MMLU (Multilingual)**: Standard knowledge benchmark, well-established\n   268→3. **FLORES-200**: For translation-based evaluation\n   269→4. **Belebele**: For broad language coverage reading comprehension\n   270→\n   271→### Recommended Baselines\n   272→1. Direct inference in target language\n   273→2. English translation → inference → back-translation\n   274→3. Compare open models (LLaMA, Gemma) vs. closed (GPT-4, Claude)\n   275→\n   276→### Recommended Metrics\n   277→1. **Accuracy per language** - Primary performance metric\n   278→2. **Multilingual Consistency (MLC)** - Cross-lingual transfer assessment\n   279→3. **Performance gap ratio** - (English accuracy - Target accuracy) / English accuracy\n   280→\n   281→### Methodological Considerations\n   282→1. **Language selection**: Include high/mid/low-resource languages from different families\n   283→2. **Task diversity**: Test both understanding and generation tasks\n   284→3. **Prompt language**: Test both English prompts and target language prompts\n   285→4. **Internal analysis**: Consider probing hidden states for language representation (per Paper 2)\n   286→\n   287→---\n   288→\n   289→## References\n   290→\n   291→1. Dong, G., et al. (2024). Evaluating and Mitigating Linguistic Discrimination in Large Language Models. arXiv:2404.18534\n   292→2. Zhao, Y., et al. (2024). How do Large Language Models Handle Multilingualism? NeurIPS 2024. arXiv:2402.18815\n   293→3. Han, W., et al. (2025). MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages. arXiv:2506.19468\n   294→4. Luo, H., et al. (2025). GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models. arXiv:2504.04155\n   295→5. Xu, Y., et al. (2024). A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias. arXiv:2404.00929\n   296→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"a0712de8-7511-4911-a4ad-484ae7774467","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/literature_review.md","content":"# Literature Review: Evaluating Linguistic Performance in LLMs\n\n## Research Area Overview\n\nThis literature review examines recent research on evaluating and understanding multilingual capabilities of Large Language Models (LLMs). The central research hypothesis under investigation is that LLMs trained predominantly on English data may underperform when deployed in non-English-speaking contexts, and that these models may possess implicit internal translation mechanisms that convert non-English inputs to English for processing.\n\nThe reviewed papers span four main areas:\n1. **Linguistic discrimination in LLMs** - Safety and quality disparities across languages\n2. **Internal multilingual processing mechanisms** - How LLMs handle non-English inputs\n3. **Multilingual evaluation benchmarks** - Standardized frameworks for cross-lingual assessment\n4. **Comprehensive surveys** - Corpora, alignment, and bias in multilingual LLMs\n\n---\n\n## Key Papers\n\n### Paper 1: Evaluating and Mitigating Linguistic Discrimination in Large Language Models\n\n- **Authors**: Guoliang Dong, Haoyu Wang, Jun Sun, Xinyu Wang\n- **Year**: 2024\n- **Source**: arXiv:2404.18534\n- **PDF**: papers/evaluating_linguistic_discrimination.pdf\n\n**Key Contribution**: Systematically evaluates linguistic discrimination from both safety and quality perspectives, proposing LDFighter as a mitigation strategy.\n\n**Methodology**:\n- Evaluated 4 LLMs: Llama2-13b, Gemma-7b, GPT-3.5-turbo, Gemini-pro\n- Used AdvBench (harmful queries) and NQ (natural questions) datasets\n- Assessed 74 languages for safety (jailbreak rate) and quality (F1 score)\n\n**Key Findings**:\n- **Safety disparities**: High-resource languages (English, French, Russian, Spanish) show 1.04% average jailbreak rate; low-resource languages (Bengali, Georgian, Nepali, Maithili) show 27.7% jailbreak rate\n- **Quality disparities**: English, Danish, Czech, Slovenian achieve 0.1494 average F1; Kannada, Southern Pashto, Tajik, Telugu achieve only 0.0341 average F1\n- **Correlation with training data**: Languages with >0.005% share in pretraining data show better safety performance\n\n**Proposed Solution**: LDFighter - translates queries to top-k languages, gets responses, translates back to pivot language (English), uses similarity-based voting for final answer\n\n**Code Available**: Not mentioned in paper\n\n**Relevance to Hypothesis**: Directly supports the hypothesis - demonstrates significant performance gaps between English and low-resource languages across both safety and quality metrics.\n\n---\n\n### Paper 2: How do Large Language Models Handle Multilingualism?\n\n- **Authors**: Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing\n- **Year**: 2024 (NeurIPS 2024)\n- **Source**: arXiv:2402.18815\n- **PDF**: papers/how_llms_handle_multilingualism.pdf\n\n**Key Contribution**: Proposes and validates the Multilingual Workflow (MWork) hypothesis - that LLMs internally convert non-English queries to English for processing.\n\n**Methodology**:\n- Developed Parallel Language-specific Neuron Detection (PLND) to identify language-specific neurons\n- Tested on multiple benchmarks: XQuAD (understanding), MGSM (reasoning), X-CSQA (knowledge), XLSum (generation)\n- Deactivated language-specific neurons to verify functionality\n\n**Key Findings**:\n- **Three-stage workflow confirmed**:\n  1. **Understanding**: Non-English queries converted to unified (English-centric) representation\n  2. **Task-solving**: Reasoning in English (self-attention) + knowledge extraction (feed-forward)\n  3. **Generation**: Output converted back to original query language\n- Only 0.13% of neurons are language-specific, yet deactivating them causes 99% performance drop on multilingual summarization\n- Deactivating understanding layer neurons: English stable, non-English -14%\n\n**Practical Application**: Fine-tuning language-specific neurons with 400 documents improves high-resource languages by 3.6% and low-resource languages by 2.3%\n\n**Code Available**: https://github.com/DAMO-NLP-SG/multilingual_analysis\n\n**Relevance to Hypothesis**: Strongly supports the hypothesis about implicit translation mechanisms - demonstrates LLMs convert multilingual inputs to English internally for processing.\n\n---\n\n### Paper 3: MuBench: Assessment of Multilingual Capabilities Across 61 Languages\n\n- **Authors**: Wenhan Han, Yifan Zhang, et al.\n- **Year**: 2025\n- **Source**: arXiv:2506.19468\n- **PDF**: papers/mubench.pdf\n\n**Key Contribution**: Comprehensive multilingual benchmark with cross-lingual alignment, introducing Multilingual Consistency (MLC) as a complementary metric.\n\n**Methodology**:\n- 61 languages covering >60% global population\n- Translated widely-used English benchmarks with rigorous quality control\n- Includes code-switched variants for mixed-language evaluation\n- Human evaluation across 16 languages\n\n**Tasks Covered**:\n- Natural Language Understanding: SNLI, MultiNLI, WinoGrande\n- Commonsense Reasoning: HellaSwag, StoryCloze\n- Factual Recall: BMLAMA\n- Knowledge-based QA: MMLU, MMLU Pro\n- Academic & Technical Reasoning: GPQA, ARC-Easy, ARC-Challenge\n- Truthfulness: TruthfulQA\n\n**Key Findings**:\n- Models fall short of claimed multilingual coverage\n- Persistent performance gap between English and low-resource languages\n- Gap does not consistently narrow with increased model size\n- Larger models not necessarily more robust in code-switched settings\n- Parallel corpora improve both accuracy and consistency\n\n**Dataset Available**: https://huggingface.co/datasets/aialt/MuBench\n\n**Relevance to Hypothesis**: Provides empirical evidence for English-centric bias across a wide range of tasks and languages.\n\n---\n\n### Paper 4: GlotEval: A Test Suite for Massively Multilingual Evaluation\n\n- **Authors**: Hengyu Luo, Zihao Li, et al.\n- **Year**: 2025\n- **Source**: arXiv:2504.04155\n- **PDF**: papers/gloteval.pdf\n\n**Key Contribution**: Unified evaluation framework integrating 27 benchmarks with ISO 639-3 standardization, supporting non-English-centric evaluation.\n\n**Methodology**:\n- Standardized all benchmarks to ISO 639-3 language codes\n- Supports 9 key tasks spanning dozens to hundreds of languages\n- Language-specific prompt templates\n- Non-English-centered machine translation evaluation\n\n**Tasks Supported**:\n1. Machine Translation\n2. Text Classification\n3. Summarization\n4. Open-ended Generation\n5. Reading Comprehension\n6. Sequence Labeling\n7. Intrinsic Evaluation\n8. Instruction Following\n9. Reasoning\n\n**Key Features**:\n- Cross-benchmark analysis by language/language group\n- Microsoft Translator integration for prompt propagation (130+ languages)\n- Any language can serve as pivot for translation evaluation\n\n**Code Available**: https://github.com/MaLA-LM/GlotEval\n\n**Relevance to Hypothesis**: Provides the evaluation infrastructure needed to systematically test multilingual LLM performance across diverse languages.\n\n---\n\n### Paper 5: A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias\n\n- **Authors**: Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Kexin Xu, Yuqi Ye, Hanwen Gu\n- **Year**: 2024\n- **Source**: arXiv:2404.00929\n- **PDF**: papers/multilingual_llm_survey.pdf\n\n**Key Contribution**: Comprehensive survey covering MLLMs' evolution, training corpora, multilingual representations, and bias.\n\n**Topics Covered**:\n\n1. **MLLM Overview**: Evolution from mBERT to BLOOM/LLaMA, key techniques, multilingual capacities\n\n2. **Training Corpora Analysis**:\n   - ChatGPT: 92.099% English, only 0.16% Chinese\n   - Language imbalance in major corpora (Wikipedia, Common Crawl)\n   - \"Curse of multilinguality\": more languages help low-resource up to a point, then overall performance decreases\n\n3. **Multilingual Alignment**:\n   - Static, contextual, and combined multilingual representations\n   - Factors affecting alignment: initial alignment solution, mapping linearity, typological distance, pretraining data\n\n4. **Bias in MLLMs**:\n   - Categories of bias\n   - Evaluation metrics\n   - Debiasing techniques\n   - Most bias studies limited to English\n\n**Key Insights**:\n- Scale, quality, and diversity of corpora significantly impact MLLM performance\n- Under-representation of low-resource languages leads to poor performance\n- Universal language representation remains challenging\n\n**Relevance to Hypothesis**: Provides foundational context explaining why LLMs exhibit English-centric bias (training data imbalance) and the challenges in achieving cross-lingual transfer.\n\n---\n\n## Common Methodologies\n\n### Evaluation Approaches\n- **Cross-lingual benchmarks**: Translate English benchmarks to target languages\n- **Language-specific metrics**: Jailbreak rate, F1 score, accuracy by language\n- **Consistency metrics**: Multilingual Consistency (MLC) for aligned samples\n\n### Models Commonly Evaluated\n- GPT-3.5-turbo, GPT-4\n- Gemini-pro\n- LLaMA-2 (7B, 13B)\n- Gemma (7B)\n- BLOOM, BLOOMZ\n- Vicuna\n- Qwen\n\n### Language Categorization\n- **High-resource**: English, French, Spanish, Russian, German, Chinese, Japanese\n- **Mid-resource**: Arabic, Korean, Portuguese, Turkish, Vietnamese, Indonesian\n- **Low-resource**: Bengali, Nepali, Georgian, Maithili, Kannada, Telugu\n\n---\n\n## Standard Baselines\n\n| Baseline Type | Common Approaches |\n|--------------|-------------------|\n| Translation-based | Translate query to English, process, translate back |\n| Direct inference | Run model directly on target language |\n| Zero-shot | No target language examples |\n| Few-shot | Include examples in target language |\n\n---\n\n## Evaluation Metrics\n\n| Metric | Description | Use Case |\n|--------|-------------|----------|\n| Accuracy | Correct answers / Total | General task performance |\n| F1 Score | Harmonic mean of precision/recall | QA tasks |\n| Jailbreak Rate | Successful harmful responses / Total | Safety evaluation |\n| BLEU/chrF++ | Translation quality | Machine translation |\n| Multilingual Consistency (MLC) | Consistency across languages for aligned samples | Cross-lingual transfer |\n\n---\n\n## Datasets in the Literature\n\n### Benchmark Datasets\n| Dataset | Languages | Task | Used By |\n|---------|-----------|------|---------|\n| MMLU | 61 (MuBench) | Knowledge QA | Papers 3, 4 |\n| XNLI | 15 | NLI | Paper 4 |\n| XQuAD | 10 | Reading comprehension | Paper 2 |\n| MGSM | 10 | Math reasoning | Paper 2 |\n| Belebele | 122 | Reading comprehension | Paper 4 |\n| AdvBench | Multi | Safety (jailbreak) | Paper 1 |\n| NQ | Multi | Open-domain QA | Paper 1 |\n| FLORES-200 | 200 | Translation | Paper 4 |\n\n### Training Corpora\n- Common Crawl (mC4, CC-100)\n- Wikipedia (various languages)\n- ROOTS (BLOOM's corpus)\n- Parallel corpora (OPUS, CCAligned)\n\n---\n\n## Gaps and Opportunities\n\n1. **Limited low-resource language evaluation**: Most benchmarks still focus on high-resource languages\n2. **Cultural bias**: Many benchmarks have Western-centric content\n3. **Code-switching**: Mixed-language scenarios underexplored\n4. **Dynamic evaluation**: Most benchmarks are static; no evaluation of adaptation\n5. **Safety in low-resource**: Limited safety evaluation for underrepresented languages\n6. **Mechanistic understanding**: Internal multilingual processing needs more investigation\n\n---\n\n## Recommendations for Our Experiment\n\n### Recommended Datasets\n1. **MuBench** (Primary): 61 languages, multiple tasks, aligned samples, available on HuggingFace\n2. **MMLU (Multilingual)**: Standard knowledge benchmark, well-established\n3. **FLORES-200**: For translation-based evaluation\n4. **Belebele**: For broad language coverage reading comprehension\n\n### Recommended Baselines\n1. Direct inference in target language\n2. English translation → inference → back-translation\n3. Compare open models (LLaMA, Gemma) vs. closed (GPT-4, Claude)\n\n### Recommended Metrics\n1. **Accuracy per language** - Primary performance metric\n2. **Multilingual Consistency (MLC)** - Cross-lingual transfer assessment\n3. **Performance gap ratio** - (English accuracy - Target accuracy) / English accuracy\n\n### Methodological Considerations\n1. **Language selection**: Include high/mid/low-resource languages from different families\n2. **Task diversity**: Test both understanding and generation tasks\n3. **Prompt language**: Test both English prompts and target language prompts\n4. **Internal analysis**: Consider probing hidden states for language representation (per Paper 2)\n\n---\n\n## References\n\n1. Dong, G., et al. (2024). Evaluating and Mitigating Linguistic Discrimination in Large Language Models. arXiv:2404.18534\n2. Zhao, Y., et al. (2024). How do Large Language Models Handle Multilingualism? NeurIPS 2024. arXiv:2402.18815\n3. Han, W., et al. (2025). MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages. arXiv:2506.19468\n4. Luo, H., et al. (2025). GlotEval: A Test Suite for Massively Multilingual Evaluation of Large Language Models. arXiv:2504.04155\n5. Xu, Y., et al. (2024). A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias. arXiv:2404.00929\n","numLines":296,"startLine":1,"totalLines":296}}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01W6vbXTZ7PkXuNcre9CF3cA","type":"tool_result","content":"     1→# Resources Catalog: Evaluating Linguistic Performance in LLMs\n     2→\n     3→## Summary\n     4→\n     5→This document catalogs all resources gathered for researching the hypothesis that LLMs trained predominantly on English data underperform in non-English contexts and may possess implicit internal translation mechanisms.\n     6→\n     7→**Research Hypothesis**: Large language models trained predominantly on English data may underperform when deployed in non-English-speaking countries. Evaluating LLM performance across multiple languages will reveal the extent of English-centric bias and whether these models possess implicit internal translation mechanisms.\n     8→\n     9→---\n    10→\n    11→## Papers\n    12→\n    13→**Total papers downloaded**: 5\n    14→\n    15→| # | Title | Authors | Year | File | Key Contribution |\n    16→|---|-------|---------|------|------|------------------|\n    17→| 1 | Evaluating and Mitigating Linguistic Discrimination in LLMs | Dong et al. | 2024 | papers/evaluating_linguistic_discrimination.pdf | Safety/quality disparities across 74 languages |\n    18→| 2 | How do Large Language Models Handle Multilingualism? | Zhao et al. | 2024 | papers/how_llms_handle_multilingualism.pdf | MWork hypothesis - internal English translation |\n    19→| 3 | MuBench: Multilingual Capabilities Across 61 Languages | Han et al. | 2025 | papers/mubench.pdf | Comprehensive benchmark with cross-lingual alignment |\n    20→| 4 | GlotEval: Massively Multilingual Evaluation | Luo et al. | 2025 | papers/gloteval.pdf | Unified framework integrating 27 benchmarks |\n    21→| 5 | Survey on Multilingual LLMs: Corpora, Alignment, Bias | Xu et al. | 2024 | papers/multilingual_llm_survey.pdf | Comprehensive survey on training data and bias |\n    22→\n    23→See `papers/README.md` for detailed descriptions.\n    24→\n    25→---\n    26→\n    27→## Datasets\n    28→\n    29→**Total datasets available**: 3 (2 multilingual benchmarks + 1 legacy)\n    30→\n    31→### Primary Datasets\n    32→\n    33→| Dataset | Source | Languages | Size per Lang | Task | Location |\n    34→|---------|--------|-----------|---------------|------|----------|\n    35→| MuBench MMLU | HuggingFace | 61 (15 downloaded) | 12,338 | Multi-choice QA | HuggingFace / datasets/mubench/ |\n    36→| Belebele | HuggingFace | 122 (15 downloaded) | 900 | Reading Comprehension | HuggingFace / datasets/belebele/ |\n    37→| MMLU Abstract Algebra | Local | 1 (English) | ~100 | Multi-choice QA | datasets/mmlu_abstract_algebra/ |\n    38→\n    39→### Language Coverage\n    40→\n    41→| Resource Level | MuBench Languages | Belebele Languages |\n    42→|----------------|-------------------|-------------------|\n    43→| High | English, Chinese, Spanish, French, German | English, Chinese, Spanish, French, German |\n    44→| Mid | Arabic, Korean, Vietnamese, Turkish, Indonesian | Arabic, Korean, Vietnamese, Turkish, Indonesian |\n    45→| Low | Bengali, Telugu, Swahili, Hindi, Tamil | Bengali, Telugu, Swahili, Nepali, Tamil |\n    46→\n    47→### Download Instructions Summary\n    48→\n    49→```python\n    50→# MuBench MMLU\n    51→from datasets import load_dataset\n    52→ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n    53→\n    54→# Belebele\n    55→ds = load_dataset(\"facebook/belebele\", \"zho_Hans\", split=\"test\")\n    56→```\n    57→\n    58→See `datasets/README.md` for detailed instructions.\n    59→\n    60→---\n    61→\n    62→## Code Repositories\n    63→\n    64→**Total repositories cloned**: 2\n    65→\n    66→| Repository | URL | Purpose | Location |\n    67→|------------|-----|---------|----------|\n    68→| multilingual_analysis | github.com/DAMO-NLP-SG/multilingual_analysis | PLND, MWork verification | code/multilingual_analysis/ |\n    69→| GlotEval | github.com/MaLA-LM/GlotEval | Unified multilingual evaluation | code/GlotEval/ |\n    70→\n    71→### Key Scripts\n    72→\n    73→| Script | Repository | Purpose |\n    74→|--------|------------|---------|\n    75→| test_layer.py | multilingual_analysis | Layer embedding decoding to visualize language shifts |\n    76→| detect_neurons.py | multilingual_analysis | Detect language-specific neurons using PLND |\n    77→| main.py | GlotEval | Main entry point for standardized multilingual evaluation |\n    78→\n    79→See `code/README.md` for detailed descriptions.\n    80→\n    81→---\n    82→\n    83→## Resource Gathering Notes\n    84→\n    85→### Search Strategy\n    86→\n    87→1. **Literature Search**: Used arXiv, Semantic Scholar, and Papers with Code to identify relevant multilingual LLM evaluation papers from 2023-2025\n    88→2. **Dataset Search**: Prioritized HuggingFace datasets with broad language coverage and cross-lingual alignment (aligned test items across languages)\n    89→3. **Code Search**: Identified repositories from paper references and Papers with Code\n    90→\n    91→### Selection Criteria\n    92→\n    93→**Papers**:\n    94→- Focus on multilingual performance evaluation\n    95→- Empirical studies showing performance disparities across languages\n    96→- Mechanistic investigations of how LLMs process non-English input\n    97→- Comprehensive surveys providing context\n    98→\n    99→**Datasets**:\n   100→- Cross-lingual alignment (same test items in multiple languages)\n   101→- Coverage of low-resource languages\n   102→- Standardized evaluation format (multiple choice for easier comparison)\n   103→- Available via HuggingFace for easy access\n   104→\n   105→**Code**:\n   106→- Open-source implementations of key methodologies\n   107→- Relevant to investigating internal multilingual mechanisms\n   108→- Provides evaluation infrastructure\n   109→\n   110→### Challenges Encountered\n   111→\n   112→1. **Large PDF files**: Some papers exceeded 5MB; used chunked reading to extract key sections\n   113→2. **JSON serialization**: Belebele dataset had datetime fields requiring conversion\n   114→3. **Dataset configs**: Both MuBench and Belebele require specific config names for each language\n   115→\n   116→### Gaps and Workarounds\n   117→\n   118→1. **No jailbreak datasets**: The AdvBench dataset used in Paper 1 is for safety evaluation; could be added if safety testing is needed\n   119→2. **No translation benchmarks**: FLORES-200 could be added for translation evaluation\n   120→3. **Limited mechanistic tools**: Only one repo (multilingual_analysis) provides tools for internal mechanism analysis\n   121→\n   122→---\n   123→\n   124→## Recommendations for Experiment Design\n   125→\n   126→Based on gathered resources, the following experiment design is recommended:\n   127→\n   128→### 1. Primary Dataset\n   129→**MuBench MMLU** - Provides aligned samples across 61 languages for direct comparison\n   130→\n   131→### 2. Language Selection\n   132→Test 15 languages across three resource levels:\n   133→- **High**: en, zh, es, fr, de\n   134→- **Mid**: ar, ko, vi, tr, id\n   135→- **Low**: bn, te, sw, hi, ta\n   136→\n   137→### 3. Baseline Methods\n   138→1. **Direct inference**: Run model on target language input\n   139→2. **English translation**: Translate input to English, run model, translate back\n   140→3. Compare open models (LLaMA, Gemma) vs. closed models (GPT-4, Claude)\n   141→\n   142→### 4. Evaluation Metrics\n   143→1. **Accuracy per language**: Primary performance metric\n   144→2. **Performance gap ratio**: (En_accuracy - Lang_accuracy) / En_accuracy\n   145→3. **Multilingual Consistency (MLC)**: For aligned samples, check consistency of answers\n   146→\n   147→### 5. Internal Mechanism Analysis (Optional)\n   148→Use multilingual_analysis repo to:\n   149→- Decode layer embeddings to visualize language representation shifts\n   150→- Detect and analyze language-specific neurons\n   151→- Verify if model converts to English internally\n   152→\n   153→### 6. Experimental Protocol\n   154→```python\n   155→# Pseudocode for experiment\n   156→models = [\"gpt-4\", \"claude-3\", \"llama-3\", \"gemma-2\"]\n   157→languages = HIGH_RESOURCE + MID_RESOURCE + LOW_RESOURCE\n   158→\n   159→results = {}\n   160→for model in models:\n   161→    for lang in languages:\n   162→        dataset = load_mubench_mmlu(lang)\n   163→        accuracy = evaluate(model, dataset)\n   164→        results[(model, lang)] = accuracy\n   165→\n   166→# Analyze:\n   167→# 1. Per-model language performance gaps\n   168→# 2. Correlation between language resource level and performance\n   169→# 3. Cross-lingual consistency on aligned samples\n   170→```\n   171→\n   172→---\n   173→\n   174→## File Structure Summary\n   175→\n   176→```\n   177→workspace/\n   178→├── papers/                           # Downloaded PDFs\n   179→│   ├── README.md                     # Paper descriptions\n   180→│   ├── evaluating_linguistic_discrimination.pdf\n   181→│   ├── how_llms_handle_multilingualism.pdf\n   182→│   ├── mubench.pdf\n   183→│   ├── gloteval.pdf\n   184→│   └── multilingual_llm_survey.pdf\n   185→├── datasets/                         # Dataset samples and info\n   186→│   ├── README.md                     # Download instructions\n   187→│   ├── .gitignore                    # Excludes large files\n   188→│   ├── belebele/                     # Belebele samples\n   189→│   │   ├── samples.json\n   190→│   │   └── dataset_info.json\n   191→│   ├── mubench/                      # MuBench samples\n   192→│   │   ├── mmlu_samples.json\n   193→│   │   └── dataset_info.json\n   194→│   └── mmlu_abstract_algebra/        # Legacy dataset\n   195→├── code/                             # Cloned repositories\n   196→│   ├── README.md                     # Repository descriptions\n   197→│   ├── multilingual_analysis/        # PLND implementation\n   198→│   └── GlotEval/                     # Evaluation framework\n   199→├── literature_review.md              # Comprehensive paper review\n   200→├── resources.md                      # This file\n   201→└── .resource_finder_complete         # Completion marker\n   202→```\n   203→\n   204→---\n   205→\n   206→## Quick Reference\n   207→\n   208→### Load MuBench Dataset\n   209→```python\n   210→from datasets import load_dataset\n   211→ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_{lang}\", split=\"test\")\n   212→# Replace {lang} with: en, zh, es, fr, de, ar, ko, vi, tr, id, bn, te, sw, hi, ta\n   213→```\n   214→\n   215→### Load Belebele Dataset\n   216→```python\n   217→from datasets import load_dataset\n   218→ds = load_dataset(\"facebook/belebele\", \"{lang_code}\", split=\"test\")\n   219→# Replace {lang_code} with: eng_Latn, zho_Hans, spa_Latn, etc.\n   220→```\n   221→\n   222→### Key Paper Findings\n   223→1. **Performance gaps exist**: Low-resource languages show 27.7% jailbreak rate vs 1.04% for high-resource (Paper 1)\n   224→2. **Internal English translation**: LLMs convert non-English queries to English internally (Paper 2)\n   225→3. **Larger models don't solve the problem**: Performance gap doesn't consistently narrow with model size (Paper 3)\n   226→4. **Training data is the root cause**: English comprises 92% of ChatGPT's training data (Paper 5)\n   227→\n   228→---\n   229→\n   230→## Next Steps for Experiment Runner\n   231→\n   232→1. Load datasets from HuggingFace using the provided code snippets\n   233→2. Set up model inference (API calls for GPT-4/Claude, local inference for LLaMA/Gemma)\n   234→3. Run evaluation across all 15 languages\n   235→4. Calculate metrics: accuracy, performance gap, consistency\n   236→5. (Optional) Use multilingual_analysis repo to probe internal representations\n   237→6. Generate visualizations and write results report\n   238→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"78ca99cb-0750-41c4-a39f-c9cad6d8ea0e","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/resources.md","content":"# Resources Catalog: Evaluating Linguistic Performance in LLMs\n\n## Summary\n\nThis document catalogs all resources gathered for researching the hypothesis that LLMs trained predominantly on English data underperform in non-English contexts and may possess implicit internal translation mechanisms.\n\n**Research Hypothesis**: Large language models trained predominantly on English data may underperform when deployed in non-English-speaking countries. Evaluating LLM performance across multiple languages will reveal the extent of English-centric bias and whether these models possess implicit internal translation mechanisms.\n\n---\n\n## Papers\n\n**Total papers downloaded**: 5\n\n| # | Title | Authors | Year | File | Key Contribution |\n|---|-------|---------|------|------|------------------|\n| 1 | Evaluating and Mitigating Linguistic Discrimination in LLMs | Dong et al. | 2024 | papers/evaluating_linguistic_discrimination.pdf | Safety/quality disparities across 74 languages |\n| 2 | How do Large Language Models Handle Multilingualism? | Zhao et al. | 2024 | papers/how_llms_handle_multilingualism.pdf | MWork hypothesis - internal English translation |\n| 3 | MuBench: Multilingual Capabilities Across 61 Languages | Han et al. | 2025 | papers/mubench.pdf | Comprehensive benchmark with cross-lingual alignment |\n| 4 | GlotEval: Massively Multilingual Evaluation | Luo et al. | 2025 | papers/gloteval.pdf | Unified framework integrating 27 benchmarks |\n| 5 | Survey on Multilingual LLMs: Corpora, Alignment, Bias | Xu et al. | 2024 | papers/multilingual_llm_survey.pdf | Comprehensive survey on training data and bias |\n\nSee `papers/README.md` for detailed descriptions.\n\n---\n\n## Datasets\n\n**Total datasets available**: 3 (2 multilingual benchmarks + 1 legacy)\n\n### Primary Datasets\n\n| Dataset | Source | Languages | Size per Lang | Task | Location |\n|---------|--------|-----------|---------------|------|----------|\n| MuBench MMLU | HuggingFace | 61 (15 downloaded) | 12,338 | Multi-choice QA | HuggingFace / datasets/mubench/ |\n| Belebele | HuggingFace | 122 (15 downloaded) | 900 | Reading Comprehension | HuggingFace / datasets/belebele/ |\n| MMLU Abstract Algebra | Local | 1 (English) | ~100 | Multi-choice QA | datasets/mmlu_abstract_algebra/ |\n\n### Language Coverage\n\n| Resource Level | MuBench Languages | Belebele Languages |\n|----------------|-------------------|-------------------|\n| High | English, Chinese, Spanish, French, German | English, Chinese, Spanish, French, German |\n| Mid | Arabic, Korean, Vietnamese, Turkish, Indonesian | Arabic, Korean, Vietnamese, Turkish, Indonesian |\n| Low | Bengali, Telugu, Swahili, Hindi, Tamil | Bengali, Telugu, Swahili, Nepali, Tamil |\n\n### Download Instructions Summary\n\n```python\n# MuBench MMLU\nfrom datasets import load_dataset\nds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n\n# Belebele\nds = load_dataset(\"facebook/belebele\", \"zho_Hans\", split=\"test\")\n```\n\nSee `datasets/README.md` for detailed instructions.\n\n---\n\n## Code Repositories\n\n**Total repositories cloned**: 2\n\n| Repository | URL | Purpose | Location |\n|------------|-----|---------|----------|\n| multilingual_analysis | github.com/DAMO-NLP-SG/multilingual_analysis | PLND, MWork verification | code/multilingual_analysis/ |\n| GlotEval | github.com/MaLA-LM/GlotEval | Unified multilingual evaluation | code/GlotEval/ |\n\n### Key Scripts\n\n| Script | Repository | Purpose |\n|--------|------------|---------|\n| test_layer.py | multilingual_analysis | Layer embedding decoding to visualize language shifts |\n| detect_neurons.py | multilingual_analysis | Detect language-specific neurons using PLND |\n| main.py | GlotEval | Main entry point for standardized multilingual evaluation |\n\nSee `code/README.md` for detailed descriptions.\n\n---\n\n## Resource Gathering Notes\n\n### Search Strategy\n\n1. **Literature Search**: Used arXiv, Semantic Scholar, and Papers with Code to identify relevant multilingual LLM evaluation papers from 2023-2025\n2. **Dataset Search**: Prioritized HuggingFace datasets with broad language coverage and cross-lingual alignment (aligned test items across languages)\n3. **Code Search**: Identified repositories from paper references and Papers with Code\n\n### Selection Criteria\n\n**Papers**:\n- Focus on multilingual performance evaluation\n- Empirical studies showing performance disparities across languages\n- Mechanistic investigations of how LLMs process non-English input\n- Comprehensive surveys providing context\n\n**Datasets**:\n- Cross-lingual alignment (same test items in multiple languages)\n- Coverage of low-resource languages\n- Standardized evaluation format (multiple choice for easier comparison)\n- Available via HuggingFace for easy access\n\n**Code**:\n- Open-source implementations of key methodologies\n- Relevant to investigating internal multilingual mechanisms\n- Provides evaluation infrastructure\n\n### Challenges Encountered\n\n1. **Large PDF files**: Some papers exceeded 5MB; used chunked reading to extract key sections\n2. **JSON serialization**: Belebele dataset had datetime fields requiring conversion\n3. **Dataset configs**: Both MuBench and Belebele require specific config names for each language\n\n### Gaps and Workarounds\n\n1. **No jailbreak datasets**: The AdvBench dataset used in Paper 1 is for safety evaluation; could be added if safety testing is needed\n2. **No translation benchmarks**: FLORES-200 could be added for translation evaluation\n3. **Limited mechanistic tools**: Only one repo (multilingual_analysis) provides tools for internal mechanism analysis\n\n---\n\n## Recommendations for Experiment Design\n\nBased on gathered resources, the following experiment design is recommended:\n\n### 1. Primary Dataset\n**MuBench MMLU** - Provides aligned samples across 61 languages for direct comparison\n\n### 2. Language Selection\nTest 15 languages across three resource levels:\n- **High**: en, zh, es, fr, de\n- **Mid**: ar, ko, vi, tr, id\n- **Low**: bn, te, sw, hi, ta\n\n### 3. Baseline Methods\n1. **Direct inference**: Run model on target language input\n2. **English translation**: Translate input to English, run model, translate back\n3. Compare open models (LLaMA, Gemma) vs. closed models (GPT-4, Claude)\n\n### 4. Evaluation Metrics\n1. **Accuracy per language**: Primary performance metric\n2. **Performance gap ratio**: (En_accuracy - Lang_accuracy) / En_accuracy\n3. **Multilingual Consistency (MLC)**: For aligned samples, check consistency of answers\n\n### 5. Internal Mechanism Analysis (Optional)\nUse multilingual_analysis repo to:\n- Decode layer embeddings to visualize language representation shifts\n- Detect and analyze language-specific neurons\n- Verify if model converts to English internally\n\n### 6. Experimental Protocol\n```python\n# Pseudocode for experiment\nmodels = [\"gpt-4\", \"claude-3\", \"llama-3\", \"gemma-2\"]\nlanguages = HIGH_RESOURCE + MID_RESOURCE + LOW_RESOURCE\n\nresults = {}\nfor model in models:\n    for lang in languages:\n        dataset = load_mubench_mmlu(lang)\n        accuracy = evaluate(model, dataset)\n        results[(model, lang)] = accuracy\n\n# Analyze:\n# 1. Per-model language performance gaps\n# 2. Correlation between language resource level and performance\n# 3. Cross-lingual consistency on aligned samples\n```\n\n---\n\n## File Structure Summary\n\n```\nworkspace/\n├── papers/                           # Downloaded PDFs\n│   ├── README.md                     # Paper descriptions\n│   ├── evaluating_linguistic_discrimination.pdf\n│   ├── how_llms_handle_multilingualism.pdf\n│   ├── mubench.pdf\n│   ├── gloteval.pdf\n│   └── multilingual_llm_survey.pdf\n├── datasets/                         # Dataset samples and info\n│   ├── README.md                     # Download instructions\n│   ├── .gitignore                    # Excludes large files\n│   ├── belebele/                     # Belebele samples\n│   │   ├── samples.json\n│   │   └── dataset_info.json\n│   ├── mubench/                      # MuBench samples\n│   │   ├── mmlu_samples.json\n│   │   └── dataset_info.json\n│   └── mmlu_abstract_algebra/        # Legacy dataset\n├── code/                             # Cloned repositories\n│   ├── README.md                     # Repository descriptions\n│   ├── multilingual_analysis/        # PLND implementation\n│   └── GlotEval/                     # Evaluation framework\n├── literature_review.md              # Comprehensive paper review\n├── resources.md                      # This file\n└── .resource_finder_complete         # Completion marker\n```\n\n---\n\n## Quick Reference\n\n### Load MuBench Dataset\n```python\nfrom datasets import load_dataset\nds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_{lang}\", split=\"test\")\n# Replace {lang} with: en, zh, es, fr, de, ar, ko, vi, tr, id, bn, te, sw, hi, ta\n```\n\n### Load Belebele Dataset\n```python\nfrom datasets import load_dataset\nds = load_dataset(\"facebook/belebele\", \"{lang_code}\", split=\"test\")\n# Replace {lang_code} with: eng_Latn, zho_Hans, spa_Latn, etc.\n```\n\n### Key Paper Findings\n1. **Performance gaps exist**: Low-resource languages show 27.7% jailbreak rate vs 1.04% for high-resource (Paper 1)\n2. **Internal English translation**: LLMs convert non-English queries to English internally (Paper 2)\n3. **Larger models don't solve the problem**: Performance gap doesn't consistently narrow with model size (Paper 3)\n4. **Training data is the root cause**: English comprises 92% of ChatGPT's training data (Paper 5)\n\n---\n\n## Next Steps for Experiment Runner\n\n1. Load datasets from HuggingFace using the provided code snippets\n2. Set up model inference (API calls for GPT-4/Claude, local inference for LLaMA/Gemma)\n3. Run evaluation across all 15 languages\n4. Calculate metrics: accuracy, performance gap, consistency\n5. (Optional) Use multilingual_analysis repo to probe internal representations\n6. Generate visualizations and write results report\n","numLines":238,"startLine":1,"totalLines":238}}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QvcJ8rYGi486Rw49iG9fBY","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! I now have a comprehensive understanding of the research landscape. Let me also check the datasets directory and code repositories to understand what's already available."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8369,"cache_read_input_tokens":34363,"cache_creation":{"ephemeral_5m_input_tokens":8369,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"ac870d79-511b-46b4-9623-4d01a0e51e1c"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QvcJ8rYGi486Rw49iG9fBY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GnqGYwXjJYSzpU8V1QWfsb","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/datasets/README.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8369,"cache_read_input_tokens":34363,"cache_creation":{"ephemeral_5m_input_tokens":8369,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"6ec6f763-3ef8-4cca-841f-b5e12986fe5c"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QvcJ8rYGi486Rw49iG9fBY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HpNa2QmFkFqzMqMnHPrAJe","name":"Bash","input":{"command":"ls -la /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/code/","description":"List code directory contents"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8369,"cache_read_input_tokens":34363,"cache_creation":{"ephemeral_5m_input_tokens":8369,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"af75c4ca-75be-449c-a2c5-8a3197aa74d8"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QvcJ8rYGi486Rw49iG9fBY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01NJAbporhDytxoCBP5vGisb","name":"Bash","input":{"command":"ls -la /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/datasets/","description":"List datasets directory contents"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8369,"cache_read_input_tokens":34363,"cache_creation":{"ephemeral_5m_input_tokens":8369,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"2f43628f-6173-4476-8e03-1334972e8442"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GnqGYwXjJYSzpU8V1QWfsb","type":"tool_result","content":"     1→# Datasets for Multilingual LLM Evaluation\n     2→\n     3→This directory contains datasets for evaluating linguistic performance in Large Language Models across multiple languages.\n     4→\n     5→**Note**: Large data files are NOT committed to git due to size. Follow the download instructions below to obtain the full datasets.\n     6→\n     7→## Available Datasets\n     8→\n     9→### 1. MuBench MMLU (Multilingual MMLU)\n    10→\n    11→**Source**: [HuggingFace - aialt/MuBench](https://huggingface.co/datasets/aialt/MuBench)\n    12→\n    13→**Description**: MuBench provides cross-linguistically aligned evaluations of the MMLU benchmark across 61 languages. Questions are translated from English while maintaining semantic consistency.\n    14→\n    15→**Languages Available** (15 selected):\n    16→| Language | Code | Resource Level | Test Size |\n    17→|----------|------|----------------|-----------|\n    18→| English | en | High | 12,338 |\n    19→| Chinese | zh | High | 12,338 |\n    20→| Spanish | es | High | 12,338 |\n    21→| French | fr | High | 12,338 |\n    22→| German | de | High | 12,338 |\n    23→| Arabic | ar | Mid | 12,338 |\n    24→| Korean | ko | Mid | 12,338 |\n    25→| Vietnamese | vi | Mid | 12,338 |\n    26→| Turkish | tr | Mid | 12,338 |\n    27→| Indonesian | id | Mid | 12,338 |\n    28→| Bengali | bn | Low | 12,338 |\n    29→| Telugu | te | Low | 12,338 |\n    30→| Swahili | sw | Low | 12,338 |\n    31→| Hindi | hi | Mid | 12,338 |\n    32→| Tamil | ta | Low | 12,338 |\n    33→\n    34→**Task**: Multiple-choice question answering (4 options: A, B, C, D)\n    35→\n    36→**Format**:\n    37→```json\n    38→{\n    39→  \"_id\": \"test_0\",\n    40→  \"prompt\": \"Question: ... \\nChoice A: ...\\nChoice B: ...\\nChoice C: ...\\nChoice D: ...\\nAnswer with A, B, C or D:\\nAnswer:\",\n    41→  \"choices\": [\"A\", \"B\", \"C\", \"D\"],\n    42→  \"label\": 1  // Index of correct answer (0-indexed)\n    43→}\n    44→```\n    45→\n    46→#### Download Instructions\n    47→\n    48→**Using HuggingFace (recommended):**\n    49→```python\n    50→from datasets import load_dataset\n    51→\n    52→# Download English version\n    53→ds_en = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_en\", split=\"test\")\n    54→\n    55→# Download Chinese version\n    56→ds_zh = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n    57→\n    58→# Download any language - replace 'xx' with language code\n    59→# ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_xx\", split=\"test\")\n    60→\n    61→# Available language codes: en, zh, es, fr, de, ar, ko, vi, tr, id, bn, te, sw, hi, ta\n    62→# (and many more - see HuggingFace page for full list)\n    63→```\n    64→\n    65→**Loading samples locally:**\n    66→```python\n    67→import json\n    68→with open(\"datasets/mubench/mmlu_samples.json\", \"r\") as f:\n    69→    samples = json.load(f)\n    70→# Access: samples[\"en\"][\"samples\"], samples[\"zh\"][\"samples\"], etc.\n    71→```\n    72→\n    73→---\n    74→\n    75→### 2. Belebele (Multilingual Reading Comprehension)\n    76→\n    77→**Source**: [HuggingFace - facebook/belebele](https://huggingface.co/datasets/facebook/belebele)\n    78→\n    79→**Description**: Belebele is a multiple-choice machine reading comprehension dataset spanning 122 language variants. Each question is linked to a passage and has 4 answer choices.\n    80→\n    81→**Languages Available** (15 selected):\n    82→| Language | Code | Resource Level | Test Size |\n    83→|----------|------|----------------|-----------|\n    84→| English | eng_Latn | High | 900 |\n    85→| Chinese (Simplified) | zho_Hans | High | 900 |\n    86→| Spanish | spa_Latn | High | 900 |\n    87→| French | fra_Latn | High | 900 |\n    88→| German | deu_Latn | High | 900 |\n    89→| Arabic | arb_Arab | Mid | 900 |\n    90→| Korean | kor_Hang | Mid | 900 |\n    91→| Vietnamese | vie_Latn | Mid | 900 |\n    92→| Turkish | tur_Latn | Mid | 900 |\n    93→| Indonesian | ind_Latn | Mid | 900 |\n    94→| Bengali | ben_Beng | Low | 900 |\n    95→| Telugu | tel_Telu | Low | 900 |\n    96→| Swahili | swh_Latn | Low | 900 |\n    97→| Nepali | npi_Deva | Low | 900 |\n    98→| Tamil | tam_Taml | Low | 900 |\n    99→\n   100→**Task**: Reading comprehension with multiple-choice answers\n   101→\n   102→**Format**:\n   103→```json\n   104→{\n   105→  \"link\": \"...\",\n   106→  \"question_number\": 1,\n   107→  \"flores_passage\": \"...\",  // The reading passage\n   108→  \"question\": \"...\",        // The question\n   109→  \"mc_answer1\": \"...\",      // Option 1\n   110→  \"mc_answer2\": \"...\",      // Option 2\n   111→  \"mc_answer3\": \"...\",      // Option 3\n   112→  \"mc_answer4\": \"...\",      // Option 4\n   113→  \"correct_answer_num\": 2,  // Correct answer (1-indexed)\n   114→  \"dialect\": \"...\",\n   115→  \"ds\": \"...\"\n   116→}\n   117→```\n   118→\n   119→#### Download Instructions\n   120→\n   121→**Using HuggingFace (recommended):**\n   122→```python\n   123→from datasets import load_dataset\n   124→\n   125→# Download English version\n   126→ds_en = load_dataset(\"facebook/belebele\", \"eng_Latn\", split=\"test\")\n   127→\n   128→# Download Chinese version\n   129→ds_zh = load_dataset(\"facebook/belebele\", \"zho_Hans\", split=\"test\")\n   130→\n   131→# Download any language - use ISO codes from the table above\n   132→# Full list: https://huggingface.co/datasets/facebook/belebele\n   133→```\n   134→\n   135→**Loading samples locally:**\n   136→```python\n   137→import json\n   138→with open(\"datasets/belebele/samples.json\", \"r\") as f:\n   139→    samples = json.load(f)\n   140→# Access: samples[\"eng_Latn\"][\"samples\"], samples[\"zho_Hans\"][\"samples\"], etc.\n   141→```\n   142→\n   143→---\n   144→\n   145→### 3. MMLU Abstract Algebra (Legacy)\n   146→\n   147→**Source**: Pre-downloaded HuggingFace MMLU subset\n   148→\n   149→**Location**: `datasets/mmlu_abstract_algebra/`\n   150→\n   151→**Description**: Abstract algebra subset from the original MMLU benchmark.\n   152→\n   153→---\n   154→\n   155→## Usage for Experiments\n   156→\n   157→### Recommended Experiment Setup\n   158→\n   159→```python\n   160→from datasets import load_dataset\n   161→import json\n   162→\n   163→# 1. Define language groups\n   164→HIGH_RESOURCE = [\"en\", \"zh\", \"es\", \"fr\", \"de\"]\n   165→MID_RESOURCE = [\"ar\", \"ko\", \"vi\", \"tr\", \"id\"]\n   166→LOW_RESOURCE = [\"bn\", \"te\", \"sw\", \"hi\", \"ta\"]\n   167→\n   168→# 2. Load MuBench for each language\n   169→def load_mubench_mmlu(lang_code):\n   170→    \"\"\"Load MuBench MMLU for a specific language.\"\"\"\n   171→    config = f\"MMLUDataset_en_template_{lang_code}\"\n   172→    return load_dataset(\"aialt/MuBench\", config, split=\"test\")\n   173→\n   174→# 3. Evaluate LLM on each language\n   175→def evaluate_multilingual(model, tokenizer):\n   176→    results = {}\n   177→    for lang in HIGH_RESOURCE + MID_RESOURCE + LOW_RESOURCE:\n   178→        dataset = load_mubench_mmlu(lang)\n   179→        accuracy = run_evaluation(model, tokenizer, dataset)\n   180→        results[lang] = accuracy\n   181→    return results\n   182→```\n   183→\n   184→### Evaluation Metrics\n   185→\n   186→1. **Per-language Accuracy**: Correct answers / Total questions\n   187→2. **Performance Gap**: (English accuracy - Target accuracy) / English accuracy\n   188→3. **Cross-lingual Consistency**: For aligned samples, check if model gives same answer\n   189→\n   190→---\n   191→\n   192→## File Structure\n   193→\n   194→```\n   195→datasets/\n   196→├── README.md                    # This file\n   197→├── .gitignore                   # Excludes large data files\n   198→├── belebele/\n   199→│   ├── samples.json             # Sample data for all languages\n   200→│   ├── dataset_info.json        # Dataset metadata\n   201→│   └── *_sample.json            # Per-language samples\n   202→├── mubench/\n   203→│   ├── mmlu_samples.json        # Sample data for all languages\n   204→│   ├── dataset_info.json        # Dataset metadata\n   205→│   └── mmlu_en_sample.json      # English samples\n   206→└── mmlu_abstract_algebra/       # Legacy dataset\n   207→    ├── dev/\n   208→    ├── test/\n   209→    └── validation/\n   210→```\n   211→\n   212→---\n   213→\n   214→## Notes for Experiment Runner\n   215→\n   216→1. **Data Loading**: Use HuggingFace `load_dataset` for full evaluation; samples in this directory are for reference only\n   217→2. **Language Selection**: The 15 languages cover high/mid/low resource levels for comprehensive analysis\n   218→3. **Alignment**: Both MuBench and Belebele provide aligned samples across languages, enabling direct comparison\n   219→4. **Prompt Language**: MuBench uses English prompts (instruction) with translated content; Belebele has fully translated passages\n   220→\n   221→---\n   222→\n   223→## References\n   224→\n   225→- MuBench: Han, W., et al. (2025). \"MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages.\" arXiv:2506.19468\n   226→- Belebele: Bandarkar, L., et al. (2023). \"The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants.\"\n   227→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"2c6edf15-d8ac-42d8-ac7f-78862e6f95db","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/datasets/README.md","content":"# Datasets for Multilingual LLM Evaluation\n\nThis directory contains datasets for evaluating linguistic performance in Large Language Models across multiple languages.\n\n**Note**: Large data files are NOT committed to git due to size. Follow the download instructions below to obtain the full datasets.\n\n## Available Datasets\n\n### 1. MuBench MMLU (Multilingual MMLU)\n\n**Source**: [HuggingFace - aialt/MuBench](https://huggingface.co/datasets/aialt/MuBench)\n\n**Description**: MuBench provides cross-linguistically aligned evaluations of the MMLU benchmark across 61 languages. Questions are translated from English while maintaining semantic consistency.\n\n**Languages Available** (15 selected):\n| Language | Code | Resource Level | Test Size |\n|----------|------|----------------|-----------|\n| English | en | High | 12,338 |\n| Chinese | zh | High | 12,338 |\n| Spanish | es | High | 12,338 |\n| French | fr | High | 12,338 |\n| German | de | High | 12,338 |\n| Arabic | ar | Mid | 12,338 |\n| Korean | ko | Mid | 12,338 |\n| Vietnamese | vi | Mid | 12,338 |\n| Turkish | tr | Mid | 12,338 |\n| Indonesian | id | Mid | 12,338 |\n| Bengali | bn | Low | 12,338 |\n| Telugu | te | Low | 12,338 |\n| Swahili | sw | Low | 12,338 |\n| Hindi | hi | Mid | 12,338 |\n| Tamil | ta | Low | 12,338 |\n\n**Task**: Multiple-choice question answering (4 options: A, B, C, D)\n\n**Format**:\n```json\n{\n  \"_id\": \"test_0\",\n  \"prompt\": \"Question: ... \\nChoice A: ...\\nChoice B: ...\\nChoice C: ...\\nChoice D: ...\\nAnswer with A, B, C or D:\\nAnswer:\",\n  \"choices\": [\"A\", \"B\", \"C\", \"D\"],\n  \"label\": 1  // Index of correct answer (0-indexed)\n}\n```\n\n#### Download Instructions\n\n**Using HuggingFace (recommended):**\n```python\nfrom datasets import load_dataset\n\n# Download English version\nds_en = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_en\", split=\"test\")\n\n# Download Chinese version\nds_zh = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n\n# Download any language - replace 'xx' with language code\n# ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_xx\", split=\"test\")\n\n# Available language codes: en, zh, es, fr, de, ar, ko, vi, tr, id, bn, te, sw, hi, ta\n# (and many more - see HuggingFace page for full list)\n```\n\n**Loading samples locally:**\n```python\nimport json\nwith open(\"datasets/mubench/mmlu_samples.json\", \"r\") as f:\n    samples = json.load(f)\n# Access: samples[\"en\"][\"samples\"], samples[\"zh\"][\"samples\"], etc.\n```\n\n---\n\n### 2. Belebele (Multilingual Reading Comprehension)\n\n**Source**: [HuggingFace - facebook/belebele](https://huggingface.co/datasets/facebook/belebele)\n\n**Description**: Belebele is a multiple-choice machine reading comprehension dataset spanning 122 language variants. Each question is linked to a passage and has 4 answer choices.\n\n**Languages Available** (15 selected):\n| Language | Code | Resource Level | Test Size |\n|----------|------|----------------|-----------|\n| English | eng_Latn | High | 900 |\n| Chinese (Simplified) | zho_Hans | High | 900 |\n| Spanish | spa_Latn | High | 900 |\n| French | fra_Latn | High | 900 |\n| German | deu_Latn | High | 900 |\n| Arabic | arb_Arab | Mid | 900 |\n| Korean | kor_Hang | Mid | 900 |\n| Vietnamese | vie_Latn | Mid | 900 |\n| Turkish | tur_Latn | Mid | 900 |\n| Indonesian | ind_Latn | Mid | 900 |\n| Bengali | ben_Beng | Low | 900 |\n| Telugu | tel_Telu | Low | 900 |\n| Swahili | swh_Latn | Low | 900 |\n| Nepali | npi_Deva | Low | 900 |\n| Tamil | tam_Taml | Low | 900 |\n\n**Task**: Reading comprehension with multiple-choice answers\n\n**Format**:\n```json\n{\n  \"link\": \"...\",\n  \"question_number\": 1,\n  \"flores_passage\": \"...\",  // The reading passage\n  \"question\": \"...\",        // The question\n  \"mc_answer1\": \"...\",      // Option 1\n  \"mc_answer2\": \"...\",      // Option 2\n  \"mc_answer3\": \"...\",      // Option 3\n  \"mc_answer4\": \"...\",      // Option 4\n  \"correct_answer_num\": 2,  // Correct answer (1-indexed)\n  \"dialect\": \"...\",\n  \"ds\": \"...\"\n}\n```\n\n#### Download Instructions\n\n**Using HuggingFace (recommended):**\n```python\nfrom datasets import load_dataset\n\n# Download English version\nds_en = load_dataset(\"facebook/belebele\", \"eng_Latn\", split=\"test\")\n\n# Download Chinese version\nds_zh = load_dataset(\"facebook/belebele\", \"zho_Hans\", split=\"test\")\n\n# Download any language - use ISO codes from the table above\n# Full list: https://huggingface.co/datasets/facebook/belebele\n```\n\n**Loading samples locally:**\n```python\nimport json\nwith open(\"datasets/belebele/samples.json\", \"r\") as f:\n    samples = json.load(f)\n# Access: samples[\"eng_Latn\"][\"samples\"], samples[\"zho_Hans\"][\"samples\"], etc.\n```\n\n---\n\n### 3. MMLU Abstract Algebra (Legacy)\n\n**Source**: Pre-downloaded HuggingFace MMLU subset\n\n**Location**: `datasets/mmlu_abstract_algebra/`\n\n**Description**: Abstract algebra subset from the original MMLU benchmark.\n\n---\n\n## Usage for Experiments\n\n### Recommended Experiment Setup\n\n```python\nfrom datasets import load_dataset\nimport json\n\n# 1. Define language groups\nHIGH_RESOURCE = [\"en\", \"zh\", \"es\", \"fr\", \"de\"]\nMID_RESOURCE = [\"ar\", \"ko\", \"vi\", \"tr\", \"id\"]\nLOW_RESOURCE = [\"bn\", \"te\", \"sw\", \"hi\", \"ta\"]\n\n# 2. Load MuBench for each language\ndef load_mubench_mmlu(lang_code):\n    \"\"\"Load MuBench MMLU for a specific language.\"\"\"\n    config = f\"MMLUDataset_en_template_{lang_code}\"\n    return load_dataset(\"aialt/MuBench\", config, split=\"test\")\n\n# 3. Evaluate LLM on each language\ndef evaluate_multilingual(model, tokenizer):\n    results = {}\n    for lang in HIGH_RESOURCE + MID_RESOURCE + LOW_RESOURCE:\n        dataset = load_mubench_mmlu(lang)\n        accuracy = run_evaluation(model, tokenizer, dataset)\n        results[lang] = accuracy\n    return results\n```\n\n### Evaluation Metrics\n\n1. **Per-language Accuracy**: Correct answers / Total questions\n2. **Performance Gap**: (English accuracy - Target accuracy) / English accuracy\n3. **Cross-lingual Consistency**: For aligned samples, check if model gives same answer\n\n---\n\n## File Structure\n\n```\ndatasets/\n├── README.md                    # This file\n├── .gitignore                   # Excludes large data files\n├── belebele/\n│   ├── samples.json             # Sample data for all languages\n│   ├── dataset_info.json        # Dataset metadata\n│   └── *_sample.json            # Per-language samples\n├── mubench/\n│   ├── mmlu_samples.json        # Sample data for all languages\n│   ├── dataset_info.json        # Dataset metadata\n│   └── mmlu_en_sample.json      # English samples\n└── mmlu_abstract_algebra/       # Legacy dataset\n    ├── dev/\n    ├── test/\n    └── validation/\n```\n\n---\n\n## Notes for Experiment Runner\n\n1. **Data Loading**: Use HuggingFace `load_dataset` for full evaluation; samples in this directory are for reference only\n2. **Language Selection**: The 15 languages cover high/mid/low resource levels for comprehensive analysis\n3. **Alignment**: Both MuBench and Belebele provide aligned samples across languages, enabling direct comparison\n4. **Prompt Language**: MuBench uses English prompts (instruction) with translated content; Belebele has fully translated passages\n\n---\n\n## References\n\n- MuBench: Han, W., et al. (2025). \"MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages.\" arXiv:2506.19468\n- Belebele: Bandarkar, L., et al. (2023). \"The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants.\"\n","numLines":227,"startLine":1,"totalLines":227}}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HpNa2QmFkFqzMqMnHPrAJe","type":"tool_result","content":"total 39\ndrwxrwx---  4 haokunliu haokunliu    5 Jan 18 21:49 .\ndrwxrwx--- 12 haokunliu haokunliu   17 Jan 18 21:50 ..\ndrwxrwx---  9 haokunliu haokunliu   18 Jan 18 21:48 GlotEval\ndrwxrwx---  8 haokunliu haokunliu   11 Jan 18 21:48 multilingual_analysis\n-rw-------  1 haokunliu haokunliu 4227 Jan 18 21:49 README.md","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"b6501062-0b27-47c8-aa4a-66698b0fb402","tool_use_result":{"stdout":"total 39\ndrwxrwx---  4 haokunliu haokunliu    5 Jan 18 21:49 .\ndrwxrwx--- 12 haokunliu haokunliu   17 Jan 18 21:50 ..\ndrwxrwx---  9 haokunliu haokunliu   18 Jan 18 21:48 GlotEval\ndrwxrwx---  8 haokunliu haokunliu   11 Jan 18 21:48 multilingual_analysis\n-rw-------  1 haokunliu haokunliu 4227 Jan 18 21:49 README.md","stderr":"","interrupted":false,"isImage":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01NJAbporhDytxoCBP5vGisb","type":"tool_result","content":"total 44\ndrwxrwx---  5 haokunliu haokunliu    7 Jan 18 21:50 .\ndrwxrwx--- 12 haokunliu haokunliu   17 Jan 18 21:50 ..\ndrwxrwx---  2 haokunliu haokunliu   19 Jan 18 21:46 belebele\n-rw-rw----  1 haokunliu haokunliu  247 Jan 18 21:50 .gitignore\ndrwxrwx---  5 haokunliu haokunliu    7 Jan 18 19:49 mmlu_abstract_algebra\ndrwxrwx---  2 haokunliu haokunliu    5 Jan 18 21:47 mubench\n-rw-------  1 haokunliu haokunliu 7424 Jan 18 21:48 README.md","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"3e074f4a-99ff-438f-aaed-72655230d7c7","tool_use_result":{"stdout":"total 44\ndrwxrwx---  5 haokunliu haokunliu    7 Jan 18 21:50 .\ndrwxrwx--- 12 haokunliu haokunliu   17 Jan 18 21:50 ..\ndrwxrwx---  2 haokunliu haokunliu   19 Jan 18 21:46 belebele\n-rw-rw----  1 haokunliu haokunliu  247 Jan 18 21:50 .gitignore\ndrwxrwx---  5 haokunliu haokunliu    7 Jan 18 19:49 mmlu_abstract_algebra\ndrwxrwx---  2 haokunliu haokunliu    5 Jan 18 21:47 mubench\n-rw-------  1 haokunliu haokunliu 7424 Jan 18 21:48 README.md","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_014VZXk9Nkd59VEE7RsC6tV8","type":"message","role":"assistant","content":[{"type":"text","text":"I have a comprehensive understanding of the resources. Now let me create a todo list to track the research and start with the environment setup and planning phase."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4068,"cache_read_input_tokens":42732,"cache_creation":{"ephemeral_5m_input_tokens":4068,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"00738b3b-91ca-4347-a04b-b9e4b88a7218"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_014VZXk9Nkd59VEE7RsC6tV8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RGhnua6yqpu7DzAn8QDx2i","name":"TodoWrite","input":{"todos":[{"content":"Set up isolated virtual environment and install dependencies","status":"in_progress","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"pending","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":4068,"cache_read_input_tokens":42732,"cache_creation":{"ephemeral_5m_input_tokens":4068,"ephemeral_1h_input_tokens":0},"output_tokens":288,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c8639057-ea36-4fa3-bc14-570db376f0f3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RGhnua6yqpu7DzAn8QDx2i","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"7f59d856-7131-43f5-9c73-31ffa4c8fe26","tool_use_result":{"oldTodos":[],"newTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"in_progress","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"pending","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_013pYEyU3WzhMwTry9e7Zzbn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01J1fXULfwVFugivGwaQ68Hf","name":"Bash","input":{"command":"cat > pyproject.toml << 'EOF'\n[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = []\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\nEOF\ncat pyproject.toml","description":"Create pyproject.toml for workspace"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":322,"cache_read_input_tokens":46800,"cache_creation":{"ephemeral_5m_input_tokens":322,"ephemeral_1h_input_tokens":0},"output_tokens":201,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"83f18627-4dde-4a37-8caa-4b835224428d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01J1fXULfwVFugivGwaQ68Hf","type":"tool_result","content":"[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = []\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"ff71d938-2c18-4a78-a8ab-7749f6b44876","tool_use_result":{"stdout":"[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = []\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01J4hErK5eL6FcFThdNYj9Nx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011maCcTRZqY1QWzcuv6ufMq","name":"Bash","input":{"command":"uv venv && source .venv/bin/activate && python --version","description":"Create virtual environment with uv"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":262,"cache_read_input_tokens":47122,"cache_creation":{"ephemeral_5m_input_tokens":262,"ephemeral_1h_input_tokens":0},"output_tokens":117,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"647032ae-a23b-4afe-8e04-9408adfa5663"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011maCcTRZqY1QWzcuv6ufMq","type":"tool_result","content":"Python 3.12.2\nUsing CPython 3.12.2 interpreter at: /data/miniconda3/bin/python3\nCreating virtual environment at: .venv\nActivate with: source .venv/bin/activate","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"74e6bf41-d9e8-4b71-831a-e26fa1579aa2","tool_use_result":{"stdout":"Python 3.12.2\nUsing CPython 3.12.2 interpreter at: /data/miniconda3/bin/python3\nCreating virtual environment at: .venv\nActivate with: source .venv/bin/activate","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01LfGQbvN9d3NzDeEz9Kbhp2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016FceGw3axT54hDyP4XAcQJ","name":"Bash","input":{"command":"source .venv/bin/activate && uv add datasets numpy pandas matplotlib seaborn openai anthropic python-dotenv tqdm requests aiohttp tiktoken","description":"Install core dependencies with uv","timeout":180000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":157,"cache_read_input_tokens":47384,"cache_creation":{"ephemeral_5m_input_tokens":157,"ephemeral_1h_input_tokens":0},"output_tokens":126,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"986c4a1c-c88e-453b-9689-b012a1c2eedd"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 1\nResolved 66 packages in 180ms\n   Building research-workspace @ file:///data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini\n  × Failed to build `research-workspace @\n  │ file:///data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini`\n  ├─▶ The build backend returned an error\n  ╰─▶ Call to `hatchling.build.build_editable` failed (exit status: 1)\n\n      [stderr]\n      Traceback (most recent call last):\n        File \"<string>\", line 11, in <module>\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/build.py\",\n      line 83, in build_editable\n          return os.path.basename(next(builder.build(directory=wheel_directory,\n      versions=[\"editable\"])))\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 157, in build\n          artifact = version_api[version](directory, **build_data)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 522, in build_editable\n          return self.build_editable_detection(directory, **build_data)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 534, in build_editable_detection\n          for included_file in self.recurse_selected_project_files():\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 182, in recurse_selected_project_files\n          if self.config.only_include:\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/config.py\",\n      line 715, in only_include\n          only_include = only_include_config.get(\"only-include\",\n      self.default_only_include()) or self.packages\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 268, in default_only_include\n          return self.default_file_selection_options.only_include\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 256, in default_file_selection_options\n          raise ValueError(message)\n      ValueError: Unable to determine which files to ship\n      inside the wheel using the following heuristics:\n      https://hatch.pypa.io/latest/plugins/builder/wheel/#default-file-selection\n\n      The most likely cause of this is that there is no directory that matches\n      the name of your project (research_workspace).\n\n      At least one file selection option must be defined\n      in the `tool.hatch.build.targets.wheel` table, see:\n      https://hatch.pypa.io/latest/config/build/\n\n      As an example, if you intend to ship a directory named `foo` that\n      resides within a `src` directory located at the root of your project,\n      you can define the following:\n\n      [tool.hatch.build.targets.wheel]\n      packages = [\"src/foo\"]\n\n      hint: This usually indicates a problem with the package or the build\n      environment.\n  help: If you want to add the package regardless of the failed resolution,\n        provide the `--frozen` flag to skip locking and syncing.","is_error":true,"tool_use_id":"toolu_016FceGw3axT54hDyP4XAcQJ"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"dcc11d18-2e87-4201-acc7-c8dd2932d05d","tool_use_result":"Error: Exit code 1\nResolved 66 packages in 180ms\n   Building research-workspace @ file:///data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini\n  × Failed to build `research-workspace @\n  │ file:///data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini`\n  ├─▶ The build backend returned an error\n  ╰─▶ Call to `hatchling.build.build_editable` failed (exit status: 1)\n\n      [stderr]\n      Traceback (most recent call last):\n        File \"<string>\", line 11, in <module>\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/build.py\",\n      line 83, in build_editable\n          return os.path.basename(next(builder.build(directory=wheel_directory,\n      versions=[\"editable\"])))\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 157, in build\n          artifact = version_api[version](directory, **build_data)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 522, in build_editable\n          return self.build_editable_detection(directory, **build_data)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 534, in build_editable_detection\n          for included_file in self.recurse_selected_project_files():\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/plugin/interface.py\",\n      line 182, in recurse_selected_project_files\n          if self.config.only_include:\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/config.py\",\n      line 715, in only_include\n          only_include = only_include_config.get(\"only-include\",\n      self.default_only_include()) or self.packages\n      \n      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 268, in default_only_include\n          return self.default_file_selection_options.only_include\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        File \"/data/miniconda3/lib/python3.12/functools.py\", line 995, in\n      __get__\n          val = self.func(instance)\n                ^^^^^^^^^^^^^^^^^^^\n        File\n      \"/data/haokunliu/.cache/builds-v0/.tmp0OBJvL/lib/python3.12/site-packages/hatchling/builders/wheel.py\",\n      line 256, in default_file_selection_options\n          raise ValueError(message)\n      ValueError: Unable to determine which files to ship\n      inside the wheel using the following heuristics:\n      https://hatch.pypa.io/latest/plugins/builder/wheel/#default-file-selection\n\n      The most likely cause of this is that there is no directory that matches\n      the name of your project (research_workspace).\n\n      At least one file selection option must be defined\n      in the `tool.hatch.build.targets.wheel` table, see:\n      https://hatch.pypa.io/latest/config/build/\n\n      As an example, if you intend to ship a directory named `foo` that\n      resides within a `src` directory located at the root of your project,\n      you can define the following:\n\n      [tool.hatch.build.targets.wheel]\n      packages = [\"src/foo\"]\n\n      hint: This usually indicates a problem with the package or the build\n      environment.\n  help: If you want to add the package regardless of the failed resolution,\n        provide the `--frozen` flag to skip locking and syncing."}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01WPRcku3HtphQXvcnD4Vse6","type":"message","role":"assistant","content":[{"type":"text","text":"Let me fix the pyproject.toml to work properly with hatchling:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1362,"cache_read_input_tokens":47541,"cache_creation":{"ephemeral_5m_input_tokens":1362,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"2f2240a9-d16d-4510-9c79-5880e1f9ecae"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01WPRcku3HtphQXvcnD4Vse6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GxwSQK2vAzEyUMwityhCbL","name":"Bash","input":{"command":"cat > pyproject.toml << 'EOF'\n[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"datasets\",\n    \"numpy\",\n    \"pandas\",\n    \"matplotlib\",\n    \"seaborn\",\n    \"openai\",\n    \"anthropic\",\n    \"python-dotenv\",\n    \"tqdm\",\n    \"requests\",\n    \"aiohttp\",\n    \"tiktoken\"\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.hatch.build.targets.wheel]\npackages = []\nEOF\ncat pyproject.toml","description":"Fix pyproject.toml configuration"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1362,"cache_read_input_tokens":47541,"cache_creation":{"ephemeral_5m_input_tokens":1362,"ephemeral_1h_input_tokens":0},"output_tokens":281,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"4da2c832-89a9-4bea-aa06-bd3ca4abe854"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GxwSQK2vAzEyUMwityhCbL","type":"tool_result","content":"[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"datasets\",\n    \"numpy\",\n    \"pandas\",\n    \"matplotlib\",\n    \"seaborn\",\n    \"openai\",\n    \"anthropic\",\n    \"python-dotenv\",\n    \"tqdm\",\n    \"requests\",\n    \"aiohttp\",\n    \"tiktoken\"\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.hatch.build.targets.wheel]\npackages = []","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"57dd794f-27b5-4ed4-9269-fe1fa3bce919","tool_use_result":{"stdout":"[project]\nname = \"research-workspace\"\nversion = \"0.1.0\"\ndescription = \"Research workspace for multilingual LLM evaluation experiments\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"datasets\",\n    \"numpy\",\n    \"pandas\",\n    \"matplotlib\",\n    \"seaborn\",\n    \"openai\",\n    \"anthropic\",\n    \"python-dotenv\",\n    \"tqdm\",\n    \"requests\",\n    \"aiohttp\",\n    \"tiktoken\"\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.hatch.build.targets.wheel]\npackages = []","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01GeG5uHPh2oUkb4TftSvdKb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014aryAr6R6mH5K3vtBMBeBB","name":"Bash","input":{"command":"source .venv/bin/activate && uv pip install datasets numpy pandas matplotlib seaborn openai anthropic python-dotenv tqdm requests aiohttp tiktoken 2>&1 | tail -20","description":"Install dependencies with uv pip","timeout":300000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":459,"cache_read_input_tokens":48903,"cache_creation":{"ephemeral_5m_input_tokens":459,"ephemeral_1h_input_tokens":0},"output_tokens":136,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"567f43e5-a709-4298-ba52-7b316699ddc2"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014aryAr6R6mH5K3vtBMBeBB","type":"tool_result","content":" + pyparsing==3.3.1\n + python-dateutil==2.9.0.post0\n + python-dotenv==1.2.1\n + pytz==2025.2\n + pyyaml==6.0.3\n + regex==2026.1.15\n + requests==2.32.5\n + seaborn==0.13.2\n + shellingham==1.5.4\n + six==1.17.0\n + sniffio==1.3.1\n + tiktoken==0.12.0\n + tqdm==4.67.1\n + typer-slim==0.21.1\n + typing-extensions==4.15.0\n + typing-inspection==0.4.2\n + tzdata==2025.3\n + urllib3==2.6.3\n + xxhash==3.6.0\n + yarl==1.22.0","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"235928a8-bdde-47dd-87f4-10271bf1c9d2","tool_use_result":{"stdout":" + pyparsing==3.3.1\n + python-dateutil==2.9.0.post0\n + python-dotenv==1.2.1\n + pytz==2025.2\n + pyyaml==6.0.3\n + regex==2026.1.15\n + requests==2.32.5\n + seaborn==0.13.2\n + shellingham==1.5.4\n + six==1.17.0\n + sniffio==1.3.1\n + tiktoken==0.12.0\n + tqdm==4.67.1\n + typer-slim==0.21.1\n + typing-extensions==4.15.0\n + typing-inspection==0.4.2\n + tzdata==2025.3\n + urllib3==2.6.3\n + xxhash==3.6.0\n + yarl==1.22.0","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VNQbVCsMp49SwLesMUzkND","type":"message","role":"assistant","content":[{"type":"text","text":"Dependencies installed successfully. Let me verify the environment and then check what API keys are available:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":595,"cache_read_input_tokens":49362,"cache_creation":{"ephemeral_5m_input_tokens":595,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"1a710684-93c6-4f81-8b6d-23e2052363f8"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VNQbVCsMp49SwLesMUzkND","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Mj5yfpudoRdhGvHNouTGND","name":"Bash","input":{"command":"source .venv/bin/activate && python -c \"\nimport sys\nprint(f'Python: {sys.version}')\nimport datasets; print(f'datasets: {datasets.__version__}')\nimport openai; print(f'openai: {openai.__version__}')\nimport anthropic; print(f'anthropic: {anthropic.__version__}')\nimport pandas; print(f'pandas: {pandas.__version__}')\nimport matplotlib; print(f'matplotlib: {matplotlib.__version__}')\nimport numpy; print(f'numpy: {numpy.__version__}')\n\"","description":"Verify installed packages"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":595,"cache_read_input_tokens":49362,"cache_creation":{"ephemeral_5m_input_tokens":595,"ephemeral_1h_input_tokens":0},"output_tokens":229,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"f8a48982-e600-4474-b88c-ecd17fa275fc"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Mj5yfpudoRdhGvHNouTGND","type":"tool_result","content":"Python: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\ndatasets: 4.5.0\nopenai: 2.15.0\nanthropic: 0.76.0\npandas: 2.3.3\nmatplotlib: 3.10.8\nnumpy: 2.4.1","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"f2d620fc-7546-4b0d-923d-149090eac23f","tool_use_result":{"stdout":"Python: 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0]\ndatasets: 4.5.0\nopenai: 2.15.0\nanthropic: 0.76.0\npandas: 2.3.3\nmatplotlib: 3.10.8\nnumpy: 2.4.1","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01N8ZngFWqHaArUR69Hcqdvs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GcNHsd5hz4qczBBMU38iCq","name":"Bash","input":{"command":"echo \"OPENAI_API_KEY: ${OPENAI_API_KEY:+set}\" && echo \"ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:+set}\" && echo \"OPENROUTER_API_KEY: ${OPENROUTER_API_KEY:+set}\"","description":"Check available API keys"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":344,"cache_read_input_tokens":49957,"cache_creation":{"ephemeral_5m_input_tokens":344,"ephemeral_1h_input_tokens":0},"output_tokens":141,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c3364b75-f21f-4b49-b047-fc5371b282b0"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GcNHsd5hz4qczBBMU38iCq","type":"tool_result","content":"OPENAI_API_KEY: set\nANTHROPIC_API_KEY: \nOPENROUTER_API_KEY: set","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"11114a2d-7282-4b47-8d08-68196d68abb7","tool_use_result":{"stdout":"OPENAI_API_KEY: set\nANTHROPIC_API_KEY: \nOPENROUTER_API_KEY: set","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01YNpUBrH7RxzbrN1MskMZWT","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! I have OpenAI API key and OpenRouter API key available. Let me update the todo list and create the planning document:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":50301,"cache_creation":{"ephemeral_5m_input_tokens":399,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"b92ebcfc-0c2e-4741-95f7-b7c55756c3d7"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01YNpUBrH7RxzbrN1MskMZWT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016xBiufzHeMUpHRMJ4f4S6w","name":"TodoWrite","input":{"todos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"in_progress","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":50301,"cache_creation":{"ephemeral_5m_input_tokens":399,"ephemeral_1h_input_tokens":0},"output_tokens":279,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"33419ed9-cc97-43cc-99da-bf2f21c29247"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016xBiufzHeMUpHRMJ4f4S6w","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"3a4105ff-5579-4bc8-91cc-78c64a6c2cdc","tool_use_result":{"oldTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"in_progress","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"pending","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}],"newTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"in_progress","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CKWGZUwUhCxBavxkD3Zees","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me write the planning.md document:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":321,"cache_read_input_tokens":50700,"cache_creation":{"ephemeral_5m_input_tokens":321,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"8ed7f870-b1d7-4c1f-ba8a-0763df2f5317"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CKWGZUwUhCxBavxkD3Zees","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SoiiqxFBPhgvmGyHxcMRDQ","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/planning.md","content":"# Research Plan: Evaluating Linguistic Performance in LLMs\n\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\n\nLarge language models are increasingly deployed at national scale in non-English-speaking countries (e.g., xAI's partnership with Venezuela, OpenAI's partnership with Estonia), yet their capability evaluations remain overwhelmingly English-centric. This creates a significant risk: governments and organizations may deploy models that underperform for their populations, potentially exacerbating digital divides and AI-driven inequalities. Understanding the magnitude of performance gaps across languages is essential for responsible AI deployment worldwide.\n\n### Gap in Existing Work\n\nFrom the literature review, while several comprehensive benchmarks exist (MuBench, GlotEval, Belebele), and one paper (Zhao et al., 2024) has proposed the \"Multilingual Workflow\" hypothesis for internal processing mechanisms, there is limited **comparative evaluation of state-of-the-art 2025 LLMs** across resource levels with a focus on:\n1. Direct comparison of multiple frontier models (GPT-4, Claude, Gemini, LLaMA) on the same aligned multilingual benchmark\n2. Quantifying the \"performance gap ratio\" systematically across language resource levels\n3. Testing whether translation-based approaches close the performance gap\n\n### Our Novel Contribution\n\nWe will conduct a **systematic empirical study** comparing multiple frontier LLMs (GPT-4o, GPT-4.1, Claude Sonnet 4.5 via OpenRouter, Gemini 2.5 Pro via OpenRouter) across 12 languages representing high, mid, and low-resource categories using the MuBench MMLU benchmark. Our contribution:\n1. **Quantified performance gaps**: Measure exact accuracy differences between English and other languages for 2025's frontier models\n2. **Translation baseline**: Test whether \"translate to English → process → translate back\" mitigates performance gaps\n3. **Cross-model comparison**: Determine which models are most/least affected by language resource levels\n4. **Reproducible benchmark**: Provide code and methodology for ongoing multilingual evaluation\n\n### Experiment Justification\n\n**Experiment 1: Direct Multilingual Evaluation**\n- *Why needed?* Establishes baseline performance across languages for current frontier models. Literature shows 2024 models had significant gaps; we need updated measurements for 2025 models.\n\n**Experiment 2: Translation-Based Approach**\n- *Why needed?* The MWork hypothesis (Zhao et al., 2024) suggests LLMs internally translate to English. If true, explicit translation might improve low-resource language performance. This tests a practical mitigation strategy.\n\n**Experiment 3: Cross-Model Comparison**\n- *Why needed?* Different training corpora and architectures may lead to different multilingual capabilities. Identifying the best models for non-English deployment has practical value.\n\n---\n\n## Research Question\n\n**Primary Question**: How do state-of-the-art LLMs (GPT-4o, GPT-4.1, Claude, Gemini) perform across high, mid, and low-resource languages on standardized knowledge benchmarks?\n\n**Secondary Questions**:\n1. What is the performance gap ratio between English and other languages?\n2. Does explicit translation to English improve low-resource language performance?\n3. Which model architecture exhibits the smallest cross-lingual performance gap?\n\n---\n\n## Hypothesis Decomposition\n\n**H1**: LLMs trained predominantly on English data will show significantly lower accuracy on low-resource languages compared to English.\n- *Measurable*: Accuracy_lowresource < 0.8 * Accuracy_english (>20% gap)\n\n**H2**: The performance gap will be correlated with language resource level.\n- *Measurable*: Spearman correlation between language resource ranking and accuracy\n\n**H3**: Translation-based approaches will partially close the performance gap for low-resource languages.\n- *Measurable*: Accuracy_translated > Accuracy_direct for low-resource languages\n\n---\n\n## Proposed Methodology\n\n### Approach\n\nWe use the **MuBench MMLU** dataset as our primary benchmark because:\n1. It provides **aligned test items** across 61 languages (same questions, translated)\n2. Multiple-choice format enables simple, unambiguous evaluation (accuracy)\n3. 12,338 questions per language provides statistical power\n4. Covers diverse knowledge domains (STEM, humanities, social sciences)\n\nWe will evaluate across **12 languages** spanning three resource levels:\n- **High-resource** (4): English (en), Chinese (zh), Spanish (es), French (fr)\n- **Mid-resource** (4): Arabic (ar), Korean (ko), Vietnamese (vi), Indonesian (id)\n- **Low-resource** (4): Bengali (bn), Telugu (te), Swahili (sw), Tamil (ta)\n\n### Experimental Steps\n\n#### Phase 1: Data Preparation (10 min)\n1. Load MuBench MMLU dataset from HuggingFace for all 12 languages\n2. Sample 500 questions per language (to manage API costs while maintaining statistical power)\n3. Validate data format and alignment across languages\n4. Create stratified sample ensuring subject diversity\n\n#### Phase 2: Model Setup (10 min)\n1. Configure API clients for:\n   - OpenAI: GPT-4o (`gpt-4o`), GPT-4.1 (`gpt-4.1`)\n   - OpenRouter: Claude Sonnet 4.5 (`anthropic/claude-sonnet-4.5`), Gemini 2.5 Pro (`google/gemini-2.5-pro`)\n2. Set consistent parameters: temperature=0, max_tokens=10\n3. Implement retry logic with exponential backoff\n4. Add rate limiting to stay within API quotas\n\n#### Phase 3: Direct Evaluation (60-90 min)\n1. For each model and each language:\n   - Send prompt with question and multiple-choice options\n   - Parse model response to extract selected answer (A/B/C/D)\n   - Record accuracy\n2. Run all 4 models × 12 languages × 500 questions = 24,000 API calls\n3. Log all responses for reproducibility\n\n#### Phase 4: Translation Baseline (30-45 min)\n1. For low-resource languages (bn, te, sw, ta):\n   - Translate question to English\n   - Get model response\n   - Compare accuracy with direct approach\n2. Use a single model (GPT-4o) for translation baseline\n\n#### Phase 5: Analysis (30 min)\n1. Calculate per-language accuracy with 95% confidence intervals\n2. Compute performance gap ratios\n3. Statistical tests for significance\n4. Generate visualizations\n\n### Baselines\n\n1. **English baseline**: Performance on English questions (upper bound)\n2. **Random baseline**: 25% accuracy for 4-choice questions (lower bound)\n3. **Translation baseline**: Translate to English before evaluation\n\n### Evaluation Metrics\n\n| Metric | Formula | Interpretation |\n|--------|---------|----------------|\n| **Accuracy** | Correct / Total | Raw performance per language |\n| **Performance Gap Ratio (PGR)** | (Acc_en - Acc_lang) / Acc_en | Relative degradation from English |\n| **Normalized Score** | (Acc - 0.25) / (Acc_en - 0.25) | Performance above random, normalized to English |\n| **Cross-lingual Consistency** | Agreement on aligned samples | Whether model gives same answer across languages |\n\n### Statistical Analysis Plan\n\n1. **Primary analysis**: One-way ANOVA for accuracy across language resource levels\n2. **Post-hoc tests**: Tukey HSD for pairwise language group comparisons\n3. **Correlation analysis**: Spearman correlation between resource level and accuracy\n4. **Effect sizes**: Cohen's d for English vs. low-resource comparison\n5. **Significance level**: α = 0.05, with Bonferroni correction for multiple comparisons\n\n---\n\n## Expected Outcomes\n\n### If H1 (English superiority) is supported:\n- Low-resource language accuracy will be 20-40% lower than English\n- This aligns with prior work (Dong et al., 2024: 0.03 vs 0.15 F1)\n\n### If H2 (resource-level correlation) is supported:\n- Clear monotonic decrease: High > Mid > Low resource accuracy\n- Spearman ρ > 0.7 (strong correlation)\n\n### If H3 (translation helps) is supported:\n- Translated accuracy > Direct accuracy for low-resource languages\n- Partial but not complete closure of gap (based on MWork hypothesis)\n\n### If hypotheses are not supported:\n- Would suggest 2025 models have improved multilingual training\n- Would be an important finding: progress toward multilingual parity\n\n---\n\n## Timeline and Milestones\n\n| Phase | Estimated Duration | Deliverable |\n|-------|-------------------|-------------|\n| Data Preparation | 10 min | Loaded, validated dataset |\n| Model Setup | 10 min | Configured API clients |\n| Direct Evaluation | 60-90 min | Raw accuracy for all models/languages |\n| Translation Baseline | 30-45 min | Translation-based accuracy |\n| Analysis | 30 min | Statistical tests, visualizations |\n| Documentation | 30 min | REPORT.md, README.md |\n| **Total** | **2.5-3.5 hours** | Complete research deliverables |\n\n---\n\n## Potential Challenges\n\n| Challenge | Mitigation |\n|-----------|------------|\n| API rate limits | Implement exponential backoff; batch requests; use async calls |\n| API costs | Sample 500 questions per language instead of full 12,338 |\n| Model response parsing | Use regex patterns; log failures for manual review |\n| Translation quality | Use same model (GPT-4o) for consistency; acknowledge as limitation |\n| Non-Latin scripts | Verify tokenization; test with sample before full run |\n\n---\n\n## Success Criteria\n\nThe research will be considered successful if we achieve:\n\n1. **Complete data collection**: Accuracy measurements for all 4 models × 12 languages\n2. **Statistical validity**: >95% response rate, sufficient samples for significance testing\n3. **Reproducibility**: All code, prompts, and raw data documented\n4. **Actionable insights**: Clear ranking of models by multilingual capability\n5. **Novel findings**: Updated 2025 baseline for multilingual LLM performance\n\n---\n\n## File Structure\n\n```\nworkspace/\n├── planning.md              # This file\n├── src/\n│   ├── evaluate.py          # Main evaluation script\n│   ├── analysis.py          # Statistical analysis\n│   └── utils.py             # Helper functions\n├── results/\n│   ├── raw/                 # Raw API responses\n│   ├── metrics.json         # Computed metrics\n│   └── plots/               # Visualizations\n├── REPORT.md                # Final research report\n└── README.md                # Project overview\n```\n\n---\n\n## References\n\n1. Dong, G., et al. (2024). Evaluating and Mitigating Linguistic Discrimination in Large Language Models. arXiv:2404.18534\n2. Zhao, Y., et al. (2024). How do Large Language Models Handle Multilingualism? NeurIPS 2024. arXiv:2402.18815\n3. Han, W., et al. (2025). MuBench: Assessment of Multilingual Capabilities. arXiv:2506.19468\n4. Luo, H., et al. (2025). GlotEval: Massively Multilingual Evaluation. arXiv:2504.04155\n5. Xu, Y., et al. (2024). Survey on Multilingual LLMs. arXiv:2404.00929\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":321,"cache_read_input_tokens":50700,"cache_creation":{"ephemeral_5m_input_tokens":321,"ephemeral_1h_input_tokens":0},"output_tokens":2890,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"37e4c590-8055-4efc-9104-6b3a06cf9b41"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SoiiqxFBPhgvmGyHxcMRDQ","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/planning.md"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c4b30fc1-dd3e-4b55-98be-ac54667edec4","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/planning.md","content":"# Research Plan: Evaluating Linguistic Performance in LLMs\n\n## Motivation & Novelty Assessment\n\n### Why This Research Matters\n\nLarge language models are increasingly deployed at national scale in non-English-speaking countries (e.g., xAI's partnership with Venezuela, OpenAI's partnership with Estonia), yet their capability evaluations remain overwhelmingly English-centric. This creates a significant risk: governments and organizations may deploy models that underperform for their populations, potentially exacerbating digital divides and AI-driven inequalities. Understanding the magnitude of performance gaps across languages is essential for responsible AI deployment worldwide.\n\n### Gap in Existing Work\n\nFrom the literature review, while several comprehensive benchmarks exist (MuBench, GlotEval, Belebele), and one paper (Zhao et al., 2024) has proposed the \"Multilingual Workflow\" hypothesis for internal processing mechanisms, there is limited **comparative evaluation of state-of-the-art 2025 LLMs** across resource levels with a focus on:\n1. Direct comparison of multiple frontier models (GPT-4, Claude, Gemini, LLaMA) on the same aligned multilingual benchmark\n2. Quantifying the \"performance gap ratio\" systematically across language resource levels\n3. Testing whether translation-based approaches close the performance gap\n\n### Our Novel Contribution\n\nWe will conduct a **systematic empirical study** comparing multiple frontier LLMs (GPT-4o, GPT-4.1, Claude Sonnet 4.5 via OpenRouter, Gemini 2.5 Pro via OpenRouter) across 12 languages representing high, mid, and low-resource categories using the MuBench MMLU benchmark. Our contribution:\n1. **Quantified performance gaps**: Measure exact accuracy differences between English and other languages for 2025's frontier models\n2. **Translation baseline**: Test whether \"translate to English → process → translate back\" mitigates performance gaps\n3. **Cross-model comparison**: Determine which models are most/least affected by language resource levels\n4. **Reproducible benchmark**: Provide code and methodology for ongoing multilingual evaluation\n\n### Experiment Justification\n\n**Experiment 1: Direct Multilingual Evaluation**\n- *Why needed?* Establishes baseline performance across languages for current frontier models. Literature shows 2024 models had significant gaps; we need updated measurements for 2025 models.\n\n**Experiment 2: Translation-Based Approach**\n- *Why needed?* The MWork hypothesis (Zhao et al., 2024) suggests LLMs internally translate to English. If true, explicit translation might improve low-resource language performance. This tests a practical mitigation strategy.\n\n**Experiment 3: Cross-Model Comparison**\n- *Why needed?* Different training corpora and architectures may lead to different multilingual capabilities. Identifying the best models for non-English deployment has practical value.\n\n---\n\n## Research Question\n\n**Primary Question**: How do state-of-the-art LLMs (GPT-4o, GPT-4.1, Claude, Gemini) perform across high, mid, and low-resource languages on standardized knowledge benchmarks?\n\n**Secondary Questions**:\n1. What is the performance gap ratio between English and other languages?\n2. Does explicit translation to English improve low-resource language performance?\n3. Which model architecture exhibits the smallest cross-lingual performance gap?\n\n---\n\n## Hypothesis Decomposition\n\n**H1**: LLMs trained predominantly on English data will show significantly lower accuracy on low-resource languages compared to English.\n- *Measurable*: Accuracy_lowresource < 0.8 * Accuracy_english (>20% gap)\n\n**H2**: The performance gap will be correlated with language resource level.\n- *Measurable*: Spearman correlation between language resource ranking and accuracy\n\n**H3**: Translation-based approaches will partially close the performance gap for low-resource languages.\n- *Measurable*: Accuracy_translated > Accuracy_direct for low-resource languages\n\n---\n\n## Proposed Methodology\n\n### Approach\n\nWe use the **MuBench MMLU** dataset as our primary benchmark because:\n1. It provides **aligned test items** across 61 languages (same questions, translated)\n2. Multiple-choice format enables simple, unambiguous evaluation (accuracy)\n3. 12,338 questions per language provides statistical power\n4. Covers diverse knowledge domains (STEM, humanities, social sciences)\n\nWe will evaluate across **12 languages** spanning three resource levels:\n- **High-resource** (4): English (en), Chinese (zh), Spanish (es), French (fr)\n- **Mid-resource** (4): Arabic (ar), Korean (ko), Vietnamese (vi), Indonesian (id)\n- **Low-resource** (4): Bengali (bn), Telugu (te), Swahili (sw), Tamil (ta)\n\n### Experimental Steps\n\n#### Phase 1: Data Preparation (10 min)\n1. Load MuBench MMLU dataset from HuggingFace for all 12 languages\n2. Sample 500 questions per language (to manage API costs while maintaining statistical power)\n3. Validate data format and alignment across languages\n4. Create stratified sample ensuring subject diversity\n\n#### Phase 2: Model Setup (10 min)\n1. Configure API clients for:\n   - OpenAI: GPT-4o (`gpt-4o`), GPT-4.1 (`gpt-4.1`)\n   - OpenRouter: Claude Sonnet 4.5 (`anthropic/claude-sonnet-4.5`), Gemini 2.5 Pro (`google/gemini-2.5-pro`)\n2. Set consistent parameters: temperature=0, max_tokens=10\n3. Implement retry logic with exponential backoff\n4. Add rate limiting to stay within API quotas\n\n#### Phase 3: Direct Evaluation (60-90 min)\n1. For each model and each language:\n   - Send prompt with question and multiple-choice options\n   - Parse model response to extract selected answer (A/B/C/D)\n   - Record accuracy\n2. Run all 4 models × 12 languages × 500 questions = 24,000 API calls\n3. Log all responses for reproducibility\n\n#### Phase 4: Translation Baseline (30-45 min)\n1. For low-resource languages (bn, te, sw, ta):\n   - Translate question to English\n   - Get model response\n   - Compare accuracy with direct approach\n2. Use a single model (GPT-4o) for translation baseline\n\n#### Phase 5: Analysis (30 min)\n1. Calculate per-language accuracy with 95% confidence intervals\n2. Compute performance gap ratios\n3. Statistical tests for significance\n4. Generate visualizations\n\n### Baselines\n\n1. **English baseline**: Performance on English questions (upper bound)\n2. **Random baseline**: 25% accuracy for 4-choice questions (lower bound)\n3. **Translation baseline**: Translate to English before evaluation\n\n### Evaluation Metrics\n\n| Metric | Formula | Interpretation |\n|--------|---------|----------------|\n| **Accuracy** | Correct / Total | Raw performance per language |\n| **Performance Gap Ratio (PGR)** | (Acc_en - Acc_lang) / Acc_en | Relative degradation from English |\n| **Normalized Score** | (Acc - 0.25) / (Acc_en - 0.25) | Performance above random, normalized to English |\n| **Cross-lingual Consistency** | Agreement on aligned samples | Whether model gives same answer across languages |\n\n### Statistical Analysis Plan\n\n1. **Primary analysis**: One-way ANOVA for accuracy across language resource levels\n2. **Post-hoc tests**: Tukey HSD for pairwise language group comparisons\n3. **Correlation analysis**: Spearman correlation between resource level and accuracy\n4. **Effect sizes**: Cohen's d for English vs. low-resource comparison\n5. **Significance level**: α = 0.05, with Bonferroni correction for multiple comparisons\n\n---\n\n## Expected Outcomes\n\n### If H1 (English superiority) is supported:\n- Low-resource language accuracy will be 20-40% lower than English\n- This aligns with prior work (Dong et al., 2024: 0.03 vs 0.15 F1)\n\n### If H2 (resource-level correlation) is supported:\n- Clear monotonic decrease: High > Mid > Low resource accuracy\n- Spearman ρ > 0.7 (strong correlation)\n\n### If H3 (translation helps) is supported:\n- Translated accuracy > Direct accuracy for low-resource languages\n- Partial but not complete closure of gap (based on MWork hypothesis)\n\n### If hypotheses are not supported:\n- Would suggest 2025 models have improved multilingual training\n- Would be an important finding: progress toward multilingual parity\n\n---\n\n## Timeline and Milestones\n\n| Phase | Estimated Duration | Deliverable |\n|-------|-------------------|-------------|\n| Data Preparation | 10 min | Loaded, validated dataset |\n| Model Setup | 10 min | Configured API clients |\n| Direct Evaluation | 60-90 min | Raw accuracy for all models/languages |\n| Translation Baseline | 30-45 min | Translation-based accuracy |\n| Analysis | 30 min | Statistical tests, visualizations |\n| Documentation | 30 min | REPORT.md, README.md |\n| **Total** | **2.5-3.5 hours** | Complete research deliverables |\n\n---\n\n## Potential Challenges\n\n| Challenge | Mitigation |\n|-----------|------------|\n| API rate limits | Implement exponential backoff; batch requests; use async calls |\n| API costs | Sample 500 questions per language instead of full 12,338 |\n| Model response parsing | Use regex patterns; log failures for manual review |\n| Translation quality | Use same model (GPT-4o) for consistency; acknowledge as limitation |\n| Non-Latin scripts | Verify tokenization; test with sample before full run |\n\n---\n\n## Success Criteria\n\nThe research will be considered successful if we achieve:\n\n1. **Complete data collection**: Accuracy measurements for all 4 models × 12 languages\n2. **Statistical validity**: >95% response rate, sufficient samples for significance testing\n3. **Reproducibility**: All code, prompts, and raw data documented\n4. **Actionable insights**: Clear ranking of models by multilingual capability\n5. **Novel findings**: Updated 2025 baseline for multilingual LLM performance\n\n---\n\n## File Structure\n\n```\nworkspace/\n├── planning.md              # This file\n├── src/\n│   ├── evaluate.py          # Main evaluation script\n│   ├── analysis.py          # Statistical analysis\n│   └── utils.py             # Helper functions\n├── results/\n│   ├── raw/                 # Raw API responses\n│   ├── metrics.json         # Computed metrics\n│   └── plots/               # Visualizations\n├── REPORT.md                # Final research report\n└── README.md                # Project overview\n```\n\n---\n\n## References\n\n1. Dong, G., et al. (2024). Evaluating and Mitigating Linguistic Discrimination in Large Language Models. arXiv:2404.18534\n2. Zhao, Y., et al. (2024). How do Large Language Models Handle Multilingualism? NeurIPS 2024. arXiv:2402.18815\n3. Han, W., et al. (2025). MuBench: Assessment of Multilingual Capabilities. arXiv:2506.19468\n4. Luo, H., et al. (2025). GlotEval: Massively Multilingual Evaluation. arXiv:2504.04155\n5. Xu, Y., et al. (2024). Survey on Multilingual LLMs. arXiv:2404.00929\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01BY9bYUPPiHA2zgotZyn2rm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Wr3a4HGpeYKpuSAb97vH2o","name":"TodoWrite","input":{"todos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"completed","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"in_progress","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2936,"cache_read_input_tokens":51021,"cache_creation":{"ephemeral_5m_input_tokens":2936,"ephemeral_1h_input_tokens":0},"output_tokens":249,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"329ddeb7-dda7-4638-985f-29c0c05128c9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Wr3a4HGpeYKpuSAb97vH2o","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"925b1a2d-dfea-4b0d-bb8a-4b7ac7909561","tool_use_result":{"oldTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"in_progress","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"pending","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}],"newTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"completed","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"in_progress","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01YBf8Kep8zgfyAzuAoDsXoR","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the directories and implement the evaluation code:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":291,"cache_read_input_tokens":53957,"cache_creation":{"ephemeral_5m_input_tokens":291,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"6c8f9a9e-7535-4421-bfa9-5f9bc43dba06"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01YBf8Kep8zgfyAzuAoDsXoR","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015EP2gdX3Guqoq54jhGmzSV","name":"Bash","input":{"command":"mkdir -p /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/results/raw /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/results/plots && ls -la /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/","description":"Create directory structure"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":291,"cache_read_input_tokens":53957,"cache_creation":{"ephemeral_5m_input_tokens":291,"ephemeral_1h_input_tokens":0},"output_tokens":201,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"bd2c907a-9247-4862-99a3-ee9722695aee"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015EP2gdX3Guqoq54jhGmzSV","type":"tool_result","content":"total 123\ndrwxrwx--- 14 haokunliu haokunliu    21 Jan 18 21:53 .\ndrwxrwx--- 24 haokunliu haokunliu    24 Jan 18 19:37 ..\ndrwxrwx---  2 haokunliu haokunliu     2 Jan 18 19:19 artifacts\ndrwxrwx---  3 haokunliu haokunliu     3 Jan 18 19:19 .claude\ndrwxrwx---  4 haokunliu haokunliu     5 Jan 18 21:49 code\ndrwxrwx---  5 haokunliu haokunliu     7 Jan 18 21:50 datasets\n-rw-rw----  1 haokunliu haokunliu   442 Jan 18 19:23 found_ids.txt\ndrwxrwx---  8 haokunliu haokunliu    15 Jan 18 21:51 .git\n-rw-rw----  1 haokunliu haokunliu  4688 Jan 18 19:19 .gitignore\ndrwxrwx---  2 haokunliu haokunliu     5 Jan 18 19:50 .idea-explorer\n-rw-------  1 haokunliu haokunliu 12943 Jan 18 21:44 literature_review.md\ndrwxrwx---  2 haokunliu haokunliu    11 Jan 18 21:51 logs\ndrwxrwx---  2 haokunliu haokunliu     8 Jan 18 19:23 papers\n-rw-------  1 haokunliu haokunliu 10688 Jan 18 21:53 planning.md\n-rw-rw----  1 haokunliu haokunliu   490 Jan 18 21:51 pyproject.toml\n-rw-rw----  1 haokunliu haokunliu  1240 Jan 18 21:50 .resource_finder_complete\n-rw-------  1 haokunliu haokunliu  9999 Jan 18 21:50 resources.md\ndrwxrwx---  4 haokunliu haokunliu     4 Jan 18 21:53 results\ndrwxrwx---  2 haokunliu haokunliu    10 Jan 18 19:48 scripts\ndrwxrwx---  2 haokunliu haokunliu     2 Jan 18 21:53 src\ndrwxrwx---  5 haokunliu haokunliu    10 Jan 18 21:51 .venv","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"337db36e-d97e-4eb8-b877-40644bfe7eff","tool_use_result":{"stdout":"total 123\ndrwxrwx--- 14 haokunliu haokunliu    21 Jan 18 21:53 .\ndrwxrwx--- 24 haokunliu haokunliu    24 Jan 18 19:37 ..\ndrwxrwx---  2 haokunliu haokunliu     2 Jan 18 19:19 artifacts\ndrwxrwx---  3 haokunliu haokunliu     3 Jan 18 19:19 .claude\ndrwxrwx---  4 haokunliu haokunliu     5 Jan 18 21:49 code\ndrwxrwx---  5 haokunliu haokunliu     7 Jan 18 21:50 datasets\n-rw-rw----  1 haokunliu haokunliu   442 Jan 18 19:23 found_ids.txt\ndrwxrwx---  8 haokunliu haokunliu    15 Jan 18 21:51 .git\n-rw-rw----  1 haokunliu haokunliu  4688 Jan 18 19:19 .gitignore\ndrwxrwx---  2 haokunliu haokunliu     5 Jan 18 19:50 .idea-explorer\n-rw-------  1 haokunliu haokunliu 12943 Jan 18 21:44 literature_review.md\ndrwxrwx---  2 haokunliu haokunliu    11 Jan 18 21:51 logs\ndrwxrwx---  2 haokunliu haokunliu     8 Jan 18 19:23 papers\n-rw-------  1 haokunliu haokunliu 10688 Jan 18 21:53 planning.md\n-rw-rw----  1 haokunliu haokunliu   490 Jan 18 21:51 pyproject.toml\n-rw-rw----  1 haokunliu haokunliu  1240 Jan 18 21:50 .resource_finder_complete\n-rw-------  1 haokunliu haokunliu  9999 Jan 18 21:50 resources.md\ndrwxrwx---  4 haokunliu haokunliu     4 Jan 18 21:53 results\ndrwxrwx---  2 haokunliu haokunliu    10 Jan 18 19:48 scripts\ndrwxrwx---  2 haokunliu haokunliu     2 Jan 18 21:53 src\ndrwxrwx---  5 haokunliu haokunliu    10 Jan 18 21:51 .venv","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01DkbJ1HdvdLQS7mWd7fFkm9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MxPRYDLynoJwabhHhBNLDr","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","content":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":936,"cache_read_input_tokens":54248,"cache_creation":{"ephemeral_5m_input_tokens":936,"ephemeral_1h_input_tokens":0},"output_tokens":4050,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"bde182f7-6b60-4e51-88f3-e1af5a22c084"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MxPRYDLynoJwabhHhBNLDr","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"7fcb943d-1cbd-496c-b125-c521726e0590","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","content":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Ltkwq68ETsRtK5mDdhCNXU","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create a test script to verify the setup works before running the full evaluation:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3981,"cache_read_input_tokens":55184,"cache_creation":{"ephemeral_5m_input_tokens":3981,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"4a3f388b-6fde-4906-920d-3a64220b6f79"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Ltkwq68ETsRtK5mDdhCNXU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QRBiCoh96HZxxUZQR9ezzV","name":"Write","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/test_setup.py","content":"#!/usr/bin/env python3\n\"\"\"\nTest script to verify the evaluation setup works correctly.\nTests dataset loading and API calls before running the full evaluation.\n\"\"\"\n\nimport os\nimport sys\nimport json\nfrom pathlib import Path\n\n# Add parent directory to path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\ndef test_dataset_loading():\n    \"\"\"Test loading a sample from MuBench.\"\"\"\n    print(\"=\" * 60)\n    print(\"Testing Dataset Loading\")\n    print(\"=\" * 60)\n\n    from datasets import load_dataset\n\n    # Test loading English\n    print(\"\\n1. Loading English dataset...\")\n    try:\n        ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_en\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds)} questions\")\n        print(f\"   Sample question:\\n   {ds[0]['prompt'][:200]}...\")\n        print(f\"   Label: {ds[0]['label']}, Choices: {ds[0]['choices']}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    # Test loading a non-English language (Chinese)\n    print(\"\\n2. Loading Chinese dataset...\")\n    try:\n        ds_zh = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds_zh)} questions\")\n        print(f\"   Sample question:\\n   {ds_zh[0]['prompt'][:200]}...\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    # Test loading a low-resource language (Bengali)\n    print(\"\\n3. Loading Bengali dataset...\")\n    try:\n        ds_bn = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_bn\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds_bn)} questions\")\n        print(f\"   Sample question:\\n   {ds_bn[0]['prompt'][:200]}...\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    return True\n\n\ndef test_openai_api():\n    \"\"\"Test OpenAI API call.\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Testing OpenAI API\")\n    print(\"=\" * 60)\n\n    import openai\n\n    api_key = os.environ.get('OPENAI_API_KEY')\n    if not api_key:\n        print(\"   OPENAI_API_KEY not set\")\n        return False\n\n    client = openai.OpenAI()\n\n    # Test simple call\n    print(\"\\n1. Testing GPT-4o...\")\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            temperature=0,\n            max_tokens=10\n        )\n        answer = response.choices[0].message.content.strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    return True\n\n\ndef test_openrouter_api():\n    \"\"\"Test OpenRouter API call.\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Testing OpenRouter API\")\n    print(\"=\" * 60)\n\n    import requests\n\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        print(\"   OPENROUTER_API_KEY not set\")\n        return False\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Test with Claude\n    print(\"\\n1. Testing Claude Sonnet via OpenRouter...\")\n    try:\n        data = {\n            \"model\": \"anthropic/claude-sonnet-4\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            \"temperature\": 0,\n            \"max_tokens\": 10\n        }\n\n        response = requests.post(\n            \"https://openrouter.ai/api/v1/chat/completions\",\n            headers=headers,\n            json=data,\n            timeout=30\n        )\n        response.raise_for_status()\n        result = response.json()\n        answer = result['choices'][0]['message']['content'].strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        # Don't fail completely, OpenRouter might have different model availability\n        print(\"   Note: This error may be due to model availability. Will try alternatives.\")\n\n    # Test with Gemini\n    print(\"\\n2. Testing Gemini 2.5 Pro via OpenRouter...\")\n    try:\n        data = {\n            \"model\": \"google/gemini-2.5-pro-preview\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            \"temperature\": 0,\n            \"max_tokens\": 10\n        }\n\n        response = requests.post(\n            \"https://openrouter.ai/api/v1/chat/completions\",\n            headers=headers,\n            json=data,\n            timeout=30\n        )\n        response.raise_for_status()\n        result = response.json()\n        answer = result['choices'][0]['message']['content'].strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n\n    return True\n\n\ndef main():\n    \"\"\"Run all tests.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"MULTILINGUAL LLM EVALUATION - SETUP TEST\")\n    print(\"=\" * 70)\n\n    tests = [\n        (\"Dataset Loading\", test_dataset_loading),\n        (\"OpenAI API\", test_openai_api),\n        (\"OpenRouter API\", test_openrouter_api),\n    ]\n\n    results = {}\n    for name, test_fn in tests:\n        try:\n            results[name] = test_fn()\n        except Exception as e:\n            print(f\"\\nTest {name} failed with exception: {e}\")\n            results[name] = False\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"TEST SUMMARY\")\n    print(\"=\" * 70)\n    for name, passed in results.items():\n        status = \"PASS\" if passed else \"FAIL\"\n        print(f\"  {name}: {status}\")\n\n    all_passed = all(results.values())\n    print(\"\\n\" + (\"All tests passed!\" if all_passed else \"Some tests failed.\"))\n\n    return all_passed\n\n\nif __name__ == \"__main__\":\n    success = main()\n    sys.exit(0 if success else 1)\n"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3981,"cache_read_input_tokens":55184,"cache_creation":{"ephemeral_5m_input_tokens":3981,"ephemeral_1h_input_tokens":0},"output_tokens":2021,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"7d56e774-f001-4a18-bc9d-7de5ecfbf015"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QRBiCoh96HZxxUZQR9ezzV","type":"tool_result","content":"File created successfully at: /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/test_setup.py"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"9ab79929-d029-4259-ae6d-3226febf098a","tool_use_result":{"type":"create","filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/test_setup.py","content":"#!/usr/bin/env python3\n\"\"\"\nTest script to verify the evaluation setup works correctly.\nTests dataset loading and API calls before running the full evaluation.\n\"\"\"\n\nimport os\nimport sys\nimport json\nfrom pathlib import Path\n\n# Add parent directory to path\nsys.path.insert(0, str(Path(__file__).parent.parent))\n\ndef test_dataset_loading():\n    \"\"\"Test loading a sample from MuBench.\"\"\"\n    print(\"=\" * 60)\n    print(\"Testing Dataset Loading\")\n    print(\"=\" * 60)\n\n    from datasets import load_dataset\n\n    # Test loading English\n    print(\"\\n1. Loading English dataset...\")\n    try:\n        ds = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_en\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds)} questions\")\n        print(f\"   Sample question:\\n   {ds[0]['prompt'][:200]}...\")\n        print(f\"   Label: {ds[0]['label']}, Choices: {ds[0]['choices']}\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    # Test loading a non-English language (Chinese)\n    print(\"\\n2. Loading Chinese dataset...\")\n    try:\n        ds_zh = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_zh\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds_zh)} questions\")\n        print(f\"   Sample question:\\n   {ds_zh[0]['prompt'][:200]}...\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    # Test loading a low-resource language (Bengali)\n    print(\"\\n3. Loading Bengali dataset...\")\n    try:\n        ds_bn = load_dataset(\"aialt/MuBench\", \"MMLUDataset_en_template_bn\", split=\"test\")\n        print(f\"   Success! Loaded {len(ds_bn)} questions\")\n        print(f\"   Sample question:\\n   {ds_bn[0]['prompt'][:200]}...\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    return True\n\n\ndef test_openai_api():\n    \"\"\"Test OpenAI API call.\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Testing OpenAI API\")\n    print(\"=\" * 60)\n\n    import openai\n\n    api_key = os.environ.get('OPENAI_API_KEY')\n    if not api_key:\n        print(\"   OPENAI_API_KEY not set\")\n        return False\n\n    client = openai.OpenAI()\n\n    # Test simple call\n    print(\"\\n1. Testing GPT-4o...\")\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            temperature=0,\n            max_tokens=10\n        )\n        answer = response.choices[0].message.content.strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        return False\n\n    return True\n\n\ndef test_openrouter_api():\n    \"\"\"Test OpenRouter API call.\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Testing OpenRouter API\")\n    print(\"=\" * 60)\n\n    import requests\n\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        print(\"   OPENROUTER_API_KEY not set\")\n        return False\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Test with Claude\n    print(\"\\n1. Testing Claude Sonnet via OpenRouter...\")\n    try:\n        data = {\n            \"model\": \"anthropic/claude-sonnet-4\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            \"temperature\": 0,\n            \"max_tokens\": 10\n        }\n\n        response = requests.post(\n            \"https://openrouter.ai/api/v1/chat/completions\",\n            headers=headers,\n            json=data,\n            timeout=30\n        )\n        response.raise_for_status()\n        result = response.json()\n        answer = result['choices'][0]['message']['content'].strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n        # Don't fail completely, OpenRouter might have different model availability\n        print(\"   Note: This error may be due to model availability. Will try alternatives.\")\n\n    # Test with Gemini\n    print(\"\\n2. Testing Gemini 2.5 Pro via OpenRouter...\")\n    try:\n        data = {\n            \"model\": \"google/gemini-2.5-pro-preview\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"Answer with only the letter (A, B, C, or D).\"},\n                {\"role\": \"user\", \"content\": \"What is 2+2? A: 3 B: 4 C: 5 D: 6\"}\n            ],\n            \"temperature\": 0,\n            \"max_tokens\": 10\n        }\n\n        response = requests.post(\n            \"https://openrouter.ai/api/v1/chat/completions\",\n            headers=headers,\n            json=data,\n            timeout=30\n        )\n        response.raise_for_status()\n        result = response.json()\n        answer = result['choices'][0]['message']['content'].strip()\n        print(f\"   Response: '{answer}'\")\n        print(f\"   Success! (Expected: B)\")\n    except Exception as e:\n        print(f\"   Error: {e}\")\n\n    return True\n\n\ndef main():\n    \"\"\"Run all tests.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"MULTILINGUAL LLM EVALUATION - SETUP TEST\")\n    print(\"=\" * 70)\n\n    tests = [\n        (\"Dataset Loading\", test_dataset_loading),\n        (\"OpenAI API\", test_openai_api),\n        (\"OpenRouter API\", test_openrouter_api),\n    ]\n\n    results = {}\n    for name, test_fn in tests:\n        try:\n            results[name] = test_fn()\n        except Exception as e:\n            print(f\"\\nTest {name} failed with exception: {e}\")\n            results[name] = False\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"TEST SUMMARY\")\n    print(\"=\" * 70)\n    for name, passed in results.items():\n        status = \"PASS\" if passed else \"FAIL\"\n        print(f\"  {name}: {status}\")\n\n    all_passed = all(results.values())\n    print(\"\\n\" + (\"All tests passed!\" if all_passed else \"Some tests failed.\"))\n\n    return all_passed\n\n\nif __name__ == \"__main__\":\n    success = main()\n    sys.exit(0 if success else 1)\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01XmvLs5pVf5Vp5GuBhXZ41Q","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017QxPZsodmdkCHXZfTsnPwD","name":"Bash","input":{"command":"source .venv/bin/activate && python src/test_setup.py 2>&1","description":"Run setup test to verify APIs and datasets","timeout":120000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2071,"cache_read_input_tokens":59165,"cache_creation":{"ephemeral_5m_input_tokens":2071,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"9502ce1f-01b1-48f7-819e-b5f9e172f21b"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017QxPZsodmdkCHXZfTsnPwD","type":"tool_result","content":"======================================================================\nMULTILINGUAL LLM EVALUATION - SETUP TEST\n======================================================================\n============================================================\nTesting Dataset Loading\n============================================================\n\n1. Loading English dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n   Label: 1, Choices: ['A', 'B', 'C', 'D']\n\n2. Loading Chinese dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: 找到给定域扩展 Q(√2, √3, √18) 相对于 Q 的次数。\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n\n3. Loading Bengali dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: প্রদত্ত ক্ষেত্র সম্প্রসারণ Q(sqrt(2), sqrt(3), sqrt(18)) এর জন্য Q এর উপর ডিগ্রি খুঁজুন।\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n\n============================================================\nTesting OpenAI API\n============================================================\n\n1. Testing GPT-4o...\n   Response: 'B'\n   Success! (Expected: B)\n\n============================================================\nTesting OpenRouter API\n============================================================\n\n1. Testing Claude Sonnet via OpenRouter...\n   Response: 'B'\n   Success! (Expected: B)\n\n2. Testing Gemini 2.5 Pro via OpenRouter...\n   Response: ''\n   Success! (Expected: B)\n\n======================================================================\nTEST SUMMARY\n======================================================================\n  Dataset Loading: PASS\n  OpenAI API: PASS\n  OpenRouter API: PASS\n\nAll tests passed!","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"be59df37-08da-47ca-bc50-d7be2be67586","tool_use_result":{"stdout":"======================================================================\nMULTILINGUAL LLM EVALUATION - SETUP TEST\n======================================================================\n============================================================\nTesting Dataset Loading\n============================================================\n\n1. Loading English dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n   Label: 1, Choices: ['A', 'B', 'C', 'D']\n\n2. Loading Chinese dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: 找到给定域扩展 Q(√2, √3, √18) 相对于 Q 的次数。\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n\n3. Loading Bengali dataset...\n   Success! Loaded 12338 questions\n   Sample question:\n   Question: প্রদত্ত ক্ষেত্র সম্প্রসারণ Q(sqrt(2), sqrt(3), sqrt(18)) এর জন্য Q এর উপর ডিগ্রি খুঁজুন।\nChoice A: 0\nChoice B: 4\nChoice C: 2\nChoice D: 6\nAnswer with A, B, C or D:\nAnswer:...\n\n============================================================\nTesting OpenAI API\n============================================================\n\n1. Testing GPT-4o...\n   Response: 'B'\n   Success! (Expected: B)\n\n============================================================\nTesting OpenRouter API\n============================================================\n\n1. Testing Claude Sonnet via OpenRouter...\n   Response: 'B'\n   Success! (Expected: B)\n\n2. Testing Gemini 2.5 Pro via OpenRouter...\n   Response: ''\n   Success! (Expected: B)\n\n======================================================================\nTEST SUMMARY\n======================================================================\n  Dataset Loading: PASS\n  OpenAI API: PASS\n  OpenRouter API: PASS\n\nAll tests passed!","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01PbRPBoG4SEqXTkBSdLXn1Y","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! All tests passed. I notice that Gemini returned an empty response, which might be an issue. Let me check the available models on OpenRouter and adjust accordingly. Let me also create a more robust evaluation script:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":868,"cache_read_input_tokens":61236,"cache_creation":{"ephemeral_5m_input_tokens":868,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"40619a85-144a-4c7d-a7cd-517cb69a5eb1"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01PbRPBoG4SEqXTkBSdLXn1Y","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ayq8wDBGN7qHftEGY6FHEP","name":"Bash","input":{"command":"source .venv/bin/activate && python << 'EOF'\nimport os\nimport requests\n\napi_key = os.environ.get('OPENROUTER_API_KEY')\nheaders = {\"Authorization\": f\"Bearer {api_key}\"}\n\n# List available models\nresponse = requests.get(\n    \"https://openrouter.ai/api/v1/models\",\n    headers=headers\n)\n\nmodels = response.json().get('data', [])\n# Filter for relevant models\nrelevant = [m for m in models if any(x in m['id'].lower() for x in ['claude', 'gemini', 'gpt'])]\n\nprint(\"Available relevant models on OpenRouter:\")\nfor m in relevant[:20]:  # Limit output\n    print(f\"  {m['id']}\")\nEOF\n","description":"Check available models on OpenRouter"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":868,"cache_read_input_tokens":61236,"cache_creation":{"ephemeral_5m_input_tokens":868,"ephemeral_1h_input_tokens":0},"output_tokens":309,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"3bd61769-1258-4b48-aece-fd12911c90a2"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ayq8wDBGN7qHftEGY6FHEP","type":"tool_result","content":"Available relevant models on OpenRouter:\n  openai/gpt-5.2-codex\n  google/gemini-3-flash-preview\n  openai/gpt-5.2-chat\n  openai/gpt-5.2-pro\n  openai/gpt-5.2\n  openai/gpt-5.1-codex-max\n  anthropic/claude-opus-4.5\n  google/gemini-3-pro-image-preview\n  google/gemini-3-pro-preview\n  openai/gpt-5.1\n  openai/gpt-5.1-chat\n  openai/gpt-5.1-codex\n  openai/gpt-5.1-codex-mini\n  openai/gpt-oss-safeguard-20b\n  openai/gpt-5-image-mini\n  anthropic/claude-haiku-4.5\n  openai/gpt-5-image\n  google/gemini-2.5-flash-image\n  openai/gpt-5-pro\n  anthropic/claude-sonnet-4.5","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"db0a50dc-11bd-41be-9f69-083264ffbf23","tool_use_result":{"stdout":"Available relevant models on OpenRouter:\n  openai/gpt-5.2-codex\n  google/gemini-3-flash-preview\n  openai/gpt-5.2-chat\n  openai/gpt-5.2-pro\n  openai/gpt-5.2\n  openai/gpt-5.1-codex-max\n  anthropic/claude-opus-4.5\n  google/gemini-3-pro-image-preview\n  google/gemini-3-pro-preview\n  openai/gpt-5.1\n  openai/gpt-5.1-chat\n  openai/gpt-5.1-codex\n  openai/gpt-5.1-codex-mini\n  openai/gpt-oss-safeguard-20b\n  openai/gpt-5-image-mini\n  anthropic/claude-haiku-4.5\n  openai/gpt-5-image\n  google/gemini-2.5-flash-image\n  openai/gpt-5-pro\n  anthropic/claude-sonnet-4.5","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01D4zj735yqQGSrwW1nEdWgm","type":"message","role":"assistant","content":[{"type":"text","text":"I see the models available. Let me update the evaluation script with the correct model IDs:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":591,"cache_read_input_tokens":62104,"cache_creation":{"ephemeral_5m_input_tokens":591,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"b544274a-8790-496a-9d1e-95ea8f964924"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01D4zj735yqQGSrwW1nEdWgm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DshKFvDj8o44VFSxTr3ZRL","name":"Read","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":591,"cache_read_input_tokens":62104,"cache_creation":{"ephemeral_5m_input_tokens":591,"ephemeral_1h_input_tokens":0},"output_tokens":103,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"16cba0f4-2b37-4a92-8c97-ab9862b85702"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DshKFvDj8o44VFSxTr3ZRL","type":"tool_result","content":"     1→#!/usr/bin/env python3\n     2→\"\"\"\n     3→Multilingual LLM Evaluation Script\n     4→\n     5→This script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\n     6→It measures accuracy and performance gaps across high, mid, and low-resource languages.\n     7→\"\"\"\n     8→\n     9→import os\n    10→import json\n    11→import time\n    12→import random\n    13→import asyncio\n    14→import logging\n    15→from datetime import datetime\n    16→from typing import Dict, List, Tuple, Optional\n    17→from dataclasses import dataclass, asdict\n    18→from pathlib import Path\n    19→\n    20→import numpy as np\n    21→import pandas as pd\n    22→from datasets import load_dataset\n    23→from tqdm import tqdm\n    24→import openai\n    25→import requests\n    26→\n    27→# Set random seed for reproducibility\n    28→SEED = 42\n    29→random.seed(SEED)\n    30→np.random.seed(SEED)\n    31→\n    32→# Configure logging\n    33→logging.basicConfig(\n    34→    level=logging.INFO,\n    35→    format='%(asctime)s - %(levelname)s - %(message)s',\n    36→    handlers=[\n    37→        logging.FileHandler('results/evaluation.log'),\n    38→        logging.StreamHandler()\n    39→    ]\n    40→)\n    41→logger = logging.getLogger(__name__)\n    42→\n    43→# Language configurations\n    44→LANGUAGES = {\n    45→    'high': ['en', 'zh', 'es', 'fr'],\n    46→    'mid': ['ar', 'ko', 'vi', 'id'],\n    47→    'low': ['bn', 'te', 'sw', 'ta']\n    48→}\n    49→\n    50→ALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n    51→\n    52→# Model configurations\n    53→MODELS = {\n    54→    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    55→    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    56→    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    57→    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n    58→}\n    59→\n    60→# Evaluation parameters\n    61→SAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\n    62→MAX_RETRIES = 3\n    63→RETRY_DELAY = 5\n    64→\n    65→\n    66→@dataclass\n    67→class EvaluationResult:\n    68→    \"\"\"Store results for a single evaluation run.\"\"\"\n    69→    model: str\n    70→    language: str\n    71→    resource_level: str\n    72→    total_questions: int\n    73→    correct: int\n    74→    accuracy: float\n    75→    responses: List[Dict]\n    76→    timestamp: str\n    77→\n    78→\n    79→def get_resource_level(lang: str) -> str:\n    80→    \"\"\"Get resource level for a language.\"\"\"\n    81→    for level, langs in LANGUAGES.items():\n    82→        if lang in langs:\n    83→            return level\n    84→    return 'unknown'\n    85→\n    86→\n    87→def load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    88→    \"\"\"\n    89→    Load MuBench MMLU dataset for a specific language.\n    90→\n    91→    Args:\n    92→        language: Language code (e.g., 'en', 'zh', 'ar')\n    93→        sample_size: Number of questions to sample\n    94→\n    95→    Returns:\n    96→        List of question dictionaries\n    97→    \"\"\"\n    98→    config_name = f\"MMLUDataset_en_template_{language}\"\n    99→    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n   100→\n   101→    try:\n   102→        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n   103→\n   104→        # Sample questions\n   105→        total_size = len(dataset)\n   106→        indices = random.sample(range(total_size), min(sample_size, total_size))\n   107→        samples = [dataset[i] for i in indices]\n   108→\n   109→        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n   110→        return samples\n   111→\n   112→    except Exception as e:\n   113→        logger.error(f\"Failed to load dataset for {language}: {e}\")\n   114→        raise\n   115→\n   116→\n   117→def format_prompt(question_data: Dict) -> str:\n   118→    \"\"\"\n   119→    Format a question for LLM evaluation.\n   120→\n   121→    The MuBench dataset already has formatted prompts, so we use them directly.\n   122→    \"\"\"\n   123→    # MuBench format already includes the question and choices\n   124→    prompt = question_data['prompt']\n   125→    return prompt\n   126→\n   127→\n   128→def parse_answer(response: str) -> Optional[str]:\n   129→    \"\"\"\n   130→    Parse the model's response to extract the answer letter.\n   131→\n   132→    Args:\n   133→        response: Raw model response\n   134→\n   135→    Returns:\n   136→        Answer letter (A, B, C, or D) or None if unparseable\n   137→    \"\"\"\n   138→    response = response.strip().upper()\n   139→\n   140→    # Direct answer\n   141→    if response in ['A', 'B', 'C', 'D']:\n   142→        return response\n   143→\n   144→    # Common patterns\n   145→    patterns = [\n   146→        r'^([ABCD])\\.',\n   147→        r'^([ABCD])\\)',\n   148→        r'^([ABCD]):',\n   149→        r'^([ABCD])\\s',\n   150→        r'answer\\s*(?:is\\s*)?([ABCD])',\n   151→        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n   152→    ]\n   153→\n   154→    import re\n   155→    for pattern in patterns:\n   156→        match = re.search(pattern, response, re.IGNORECASE)\n   157→        if match:\n   158→            return match.group(1).upper()\n   159→\n   160→    # First letter if it's A, B, C, or D\n   161→    if response and response[0] in ['A', 'B', 'C', 'D']:\n   162→        return response[0]\n   163→\n   164→    return None\n   165→\n   166→\n   167→def call_openai(prompt: str, model_id: str) -> str:\n   168→    \"\"\"Call OpenAI API.\"\"\"\n   169→    client = openai.OpenAI()\n   170→\n   171→    for attempt in range(MAX_RETRIES):\n   172→        try:\n   173→            response = client.chat.completions.create(\n   174→                model=model_id,\n   175→                messages=[\n   176→                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n   177→                    {\"role\": \"user\", \"content\": prompt}\n   178→                ],\n   179→                temperature=0,\n   180→                max_tokens=10\n   181→            )\n   182→            return response.choices[0].message.content.strip()\n   183→        except Exception as e:\n   184→            if attempt < MAX_RETRIES - 1:\n   185→                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n   186→                time.sleep(RETRY_DELAY * (attempt + 1))\n   187→            else:\n   188→                raise\n   189→\n   190→\n   191→def call_openrouter(prompt: str, model_id: str) -> str:\n   192→    \"\"\"Call OpenRouter API.\"\"\"\n   193→    api_key = os.environ.get('OPENROUTER_API_KEY')\n   194→    if not api_key:\n   195→        raise ValueError(\"OPENROUTER_API_KEY not set\")\n   196→\n   197→    headers = {\n   198→        \"Authorization\": f\"Bearer {api_key}\",\n   199→        \"Content-Type\": \"application/json\"\n   200→    }\n   201→\n   202→    data = {\n   203→        \"model\": model_id,\n   204→        \"messages\": [\n   205→            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n   206→            {\"role\": \"user\", \"content\": prompt}\n   207→        ],\n   208→        \"temperature\": 0,\n   209→        \"max_tokens\": 10\n   210→    }\n   211→\n   212→    for attempt in range(MAX_RETRIES):\n   213→        try:\n   214→            response = requests.post(\n   215→                \"https://openrouter.ai/api/v1/chat/completions\",\n   216→                headers=headers,\n   217→                json=data,\n   218→                timeout=60\n   219→            )\n   220→            response.raise_for_status()\n   221→            result = response.json()\n   222→            return result['choices'][0]['message']['content'].strip()\n   223→        except Exception as e:\n   224→            if attempt < MAX_RETRIES - 1:\n   225→                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n   226→                time.sleep(RETRY_DELAY * (attempt + 1))\n   227→            else:\n   228→                raise\n   229→\n   230→\n   231→def evaluate_model_on_language(\n   232→    model_name: str,\n   233→    model_config: Dict,\n   234→    questions: List[Dict],\n   235→    language: str,\n   236→    progress_bar: Optional[tqdm] = None\n   237→) -> EvaluationResult:\n   238→    \"\"\"\n   239→    Evaluate a single model on questions in a specific language.\n   240→\n   241→    Args:\n   242→        model_name: Name of the model\n   243→        model_config: Model configuration dict\n   244→        questions: List of question dictionaries\n   245→        language: Language code\n   246→        progress_bar: Optional progress bar to update\n   247→\n   248→    Returns:\n   249→        EvaluationResult with accuracy and detailed responses\n   250→    \"\"\"\n   251→    provider = model_config['provider']\n   252→    model_id = model_config['model_id']\n   253→\n   254→    responses = []\n   255→    correct = 0\n   256→\n   257→    call_fn = call_openai if provider == 'openai' else call_openrouter\n   258→\n   259→    for i, q in enumerate(questions):\n   260→        prompt = format_prompt(q)\n   261→\n   262→        try:\n   263→            raw_response = call_fn(prompt, model_id)\n   264→            parsed_answer = parse_answer(raw_response)\n   265→\n   266→            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n   267→            correct_answer = q['choices'][q['label']]\n   268→            is_correct = parsed_answer == correct_answer\n   269→\n   270→            if is_correct:\n   271→                correct += 1\n   272→\n   273→            responses.append({\n   274→                'question_id': q.get('_id', i),\n   275→                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n   276→                'raw_response': raw_response,\n   277→                'parsed_answer': parsed_answer,\n   278→                'correct_answer': correct_answer,\n   279→                'is_correct': is_correct\n   280→            })\n   281→\n   282→        except Exception as e:\n   283→            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n   284→            responses.append({\n   285→                'question_id': q.get('_id', i),\n   286→                'error': str(e),\n   287→                'is_correct': False\n   288→            })\n   289→\n   290→        if progress_bar:\n   291→            progress_bar.update(1)\n   292→\n   293→        # Small delay to avoid rate limiting\n   294→        time.sleep(0.1)\n   295→\n   296→    accuracy = correct / len(questions) if questions else 0.0\n   297→\n   298→    return EvaluationResult(\n   299→        model=model_name,\n   300→        language=language,\n   301→        resource_level=get_resource_level(language),\n   302→        total_questions=len(questions),\n   303→        correct=correct,\n   304→        accuracy=accuracy,\n   305→        responses=responses,\n   306→        timestamp=datetime.now().isoformat()\n   307→    )\n   308→\n   309→\n   310→def run_evaluation(\n   311→    models: Dict[str, Dict],\n   312→    languages: List[str],\n   313→    sample_size: int = SAMPLE_SIZE,\n   314→    save_path: str = 'results/'\n   315→) -> pd.DataFrame:\n   316→    \"\"\"\n   317→    Run full evaluation across all models and languages.\n   318→\n   319→    Args:\n   320→        models: Dictionary of model configurations\n   321→        languages: List of language codes\n   322→        sample_size: Questions per language\n   323→        save_path: Directory to save results\n   324→\n   325→    Returns:\n   326→        DataFrame with evaluation results\n   327→    \"\"\"\n   328→    # Load all datasets first\n   329→    logger.info(\"Loading datasets...\")\n   330→    datasets = {}\n   331→    for lang in languages:\n   332→        try:\n   333→            datasets[lang] = load_mubench_data(lang, sample_size)\n   334→        except Exception as e:\n   335→            logger.error(f\"Skipping language {lang}: {e}\")\n   336→            continue\n   337→\n   338→    # Calculate total iterations for progress bar\n   339→    total_iterations = sum(\n   340→        len(datasets.get(lang, []))\n   341→        for lang in languages\n   342→        for _ in models\n   343→    )\n   344→\n   345→    results = []\n   346→\n   347→    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n   348→        for model_name, model_config in models.items():\n   349→            logger.info(f\"\\nEvaluating model: {model_name}\")\n   350→\n   351→            for lang in languages:\n   352→                if lang not in datasets:\n   353→                    continue\n   354→\n   355→                logger.info(f\"  Language: {lang}\")\n   356→\n   357→                try:\n   358→                    result = evaluate_model_on_language(\n   359→                        model_name,\n   360→                        model_config,\n   361→                        datasets[lang],\n   362→                        lang,\n   363→                        pbar\n   364→                    )\n   365→                    results.append(result)\n   366→\n   367→                    # Save intermediate results\n   368→                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n   369→                    with open(result_path, 'w') as f:\n   370→                        json.dump(asdict(result), f, indent=2)\n   371→\n   372→                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n   373→\n   374→                except Exception as e:\n   375→                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n   376→\n   377→    # Convert to DataFrame\n   378→    df = pd.DataFrame([{\n   379→        'model': r.model,\n   380→        'language': r.language,\n   381→        'resource_level': r.resource_level,\n   382→        'accuracy': r.accuracy,\n   383→        'correct': r.correct,\n   384→        'total': r.total_questions\n   385→    } for r in results])\n   386→\n   387→    # Save summary\n   388→    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n   389→\n   390→    return df\n   391→\n   392→\n   393→def main():\n   394→    \"\"\"Main entry point.\"\"\"\n   395→    logger.info(\"=\"*60)\n   396→    logger.info(\"Multilingual LLM Evaluation Starting\")\n   397→    logger.info(f\"Seed: {SEED}\")\n   398→    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n   399→    logger.info(f\"Models: {list(MODELS.keys())}\")\n   400→    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n   401→    logger.info(\"=\"*60)\n   402→\n   403→    # Ensure results directory exists\n   404→    Path('results/raw').mkdir(parents=True, exist_ok=True)\n   405→\n   406→    # Run evaluation\n   407→    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n   408→\n   409→    # Log summary\n   410→    logger.info(\"\\n\" + \"=\"*60)\n   411→    logger.info(\"Evaluation Complete - Summary\")\n   412→    logger.info(\"=\"*60)\n   413→\n   414→    # Summary by model\n   415→    logger.info(\"\\nAccuracy by Model:\")\n   416→    for model in results_df['model'].unique():\n   417→        model_df = results_df[results_df['model'] == model]\n   418→        avg_acc = model_df['accuracy'].mean()\n   419→        logger.info(f\"  {model}: {avg_acc:.2%}\")\n   420→\n   421→    # Summary by resource level\n   422→    logger.info(\"\\nAccuracy by Resource Level:\")\n   423→    for level in ['high', 'mid', 'low']:\n   424→        level_df = results_df[results_df['resource_level'] == level]\n   425→        avg_acc = level_df['accuracy'].mean()\n   426→        logger.info(f\"  {level}: {avg_acc:.2%}\")\n   427→\n   428→    # English vs average\n   429→    en_df = results_df[results_df['language'] == 'en']\n   430→    en_avg = en_df['accuracy'].mean()\n   431→    other_df = results_df[results_df['language'] != 'en']\n   432→    other_avg = other_df['accuracy'].mean()\n   433→    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n   434→    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n   435→    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n   436→\n   437→    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n   438→\n   439→    return results_df\n   440→\n   441→\n   442→if __name__ == \"__main__\":\n   443→    main()\n   444→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"de51f735-92e1-4867-bce0-9de8bd0e80a2","tool_use_result":{"type":"text","file":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","content":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n","numLines":444,"startLine":1,"totalLines":444}}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_017N6PR7FrwJMN3KHQKHZsTZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JDPJjLso3cpzeLZi1Jsni2","name":"Edit","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","old_string":"# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}","new_string":"# Model configurations - using available models from OpenRouter\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n}"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5660,"cache_read_input_tokens":62695,"cache_creation":{"ephemeral_5m_input_tokens":5660,"ephemeral_1h_input_tokens":0},"output_tokens":395,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"2e0e3115-609b-4328-81a8-74d32fcfe416"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JDPJjLso3cpzeLZi1Jsni2","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n    48→}\n    49→\n    50→ALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n    51→\n    52→# Model configurations - using available models from OpenRouter\n    53→MODELS = {\n    54→    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    55→    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    56→    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n    57→}\n    58→\n    59→# Evaluation parameters\n    60→SAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\n    61→MAX_RETRIES = 3"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"a6fdaaa2-81f3-4467-98e3-18ebe2da333a","tool_use_result":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","oldString":"# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}","newString":"# Model configurations - using available models from OpenRouter\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n}","originalFile":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},\n    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},\n    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":49,"oldLines":12,"newStart":49,"newLines":11,"lines":[" "," ALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']"," ","-# Model configurations","+# Model configurations - using available models from OpenRouter"," MODELS = {","     'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},","-    'gpt-4.1': {'provider': 'openai', 'model_id': 'gpt-4.1'},","-    'claude-sonnet': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4'},","-    'gemini-2.5-pro': {'provider': 'openrouter', 'model_id': 'google/gemini-2.5-pro-preview'}","+    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},","+    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}"," }"," "," # Evaluation parameters"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01FhFD2ihhm6nrbckJQ22ssv","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me also handle the potential issue with empty responses from models:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":694,"cache_read_input_tokens":68355,"cache_creation":{"ephemeral_5m_input_tokens":694,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"0dda01f0-cd1d-4e93-b89b-be1fa9014c1f"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01FhFD2ihhm6nrbckJQ22ssv","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YDgSupL6au921QspyFu8b5","name":"Edit","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","old_string":"def call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise","new_string":"def call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 20  # Increased slightly to ensure we get a response\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            content = result['choices'][0]['message']['content']\n            # Handle None or empty content\n            if content is None:\n                content = \"\"\n            return content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":694,"cache_read_input_tokens":68355,"cache_creation":{"ephemeral_5m_input_tokens":694,"ephemeral_1h_input_tokens":0},"output_tokens":923,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c832db8f-db13-4c62-a96e-d2cb22c62a5f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YDgSupL6au921QspyFu8b5","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n   186→            else:\n   187→                raise\n   188→\n   189→\n   190→def call_openrouter(prompt: str, model_id: str) -> str:\n   191→    \"\"\"Call OpenRouter API.\"\"\"\n   192→    api_key = os.environ.get('OPENROUTER_API_KEY')\n   193→    if not api_key:\n   194→        raise ValueError(\"OPENROUTER_API_KEY not set\")\n   195→\n   196→    headers = {\n   197→        \"Authorization\": f\"Bearer {api_key}\",\n   198→        \"Content-Type\": \"application/json\"\n   199→    }\n   200→\n   201→    data = {\n   202→        \"model\": model_id,\n   203→        \"messages\": [\n   204→            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n   205→            {\"role\": \"user\", \"content\": prompt}\n   206→        ],\n   207→        \"temperature\": 0,\n   208→        \"max_tokens\": 20  # Increased slightly to ensure we get a response\n   209→    }\n   210→\n   211→    for attempt in range(MAX_RETRIES):\n   212→        try:\n   213→            response = requests.post(\n   214→                \"https://openrouter.ai/api/v1/chat/completions\",\n   215→                headers=headers,\n   216→                json=data,\n   217→                timeout=60\n   218→            )\n   219→            response.raise_for_status()\n   220→            result = response.json()\n   221→            content = result['choices'][0]['message']['content']\n   222→            # Handle None or empty content\n   223→            if content is None:\n   224→                content = \"\"\n   225→            return content.strip()\n   226→        except Exception as e:\n   227→            if attempt < MAX_RETRIES - 1:\n   228→                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n   229→                time.sleep(RETRY_DELAY * (attempt + 1))\n   230→            else:\n   231→                raise\n   232→\n   233→\n   234→def evaluate_model_on_language(\n   235→    model_name: str,"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"d33a8cac-0c6d-45f8-a49d-95ed12f8b3a5","tool_use_result":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","oldString":"def call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise","newString":"def call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 20  # Increased slightly to ensure we get a response\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            content = result['choices'][0]['message']['content']\n            # Handle None or empty content\n            if content is None:\n                content = \"\"\n            return content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise","originalFile":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations - using available models from OpenRouter\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 10\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result['choices'][0]['message']['content'].strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":205,"oldLines":7,"newStart":205,"newLines":7,"lines":["             {\"role\": \"user\", \"content\": prompt}","         ],","         \"temperature\": 0,","-        \"max_tokens\": 10","+        \"max_tokens\": 20  # Increased slightly to ensure we get a response","     }"," ","     for attempt in range(MAX_RETRIES):"]},{"oldStart":218,"oldLines":7,"newStart":218,"newLines":11,"lines":["             )","             response.raise_for_status()","             result = response.json()","-            return result['choices'][0]['message']['content'].strip()","+            content = result['choices'][0]['message']['content']","+            # Handle None or empty content","+            if content is None:","+                content = \"\"","+            return content.strip()","         except Exception as e:","             if attempt < MAX_RETRIES - 1:","                 logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_013ACd8EAGXN3mMThpeuYPBB","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me update the todo and run the full evaluation:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1803,"cache_read_input_tokens":69049,"cache_creation":{"ephemeral_5m_input_tokens":1803,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"8ad5a96a-1ca3-4477-9bf2-039ea772590e"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_013ACd8EAGXN3mMThpeuYPBB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011BqYLbhQ8b7AN9w2g2gAzG","name":"TodoWrite","input":{"todos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"completed","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"completed","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 12 languages with 3 LLMs","status":"in_progress","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1803,"cache_read_input_tokens":69049,"cache_creation":{"ephemeral_5m_input_tokens":1803,"ephemeral_1h_input_tokens":0},"output_tokens":264,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"db183dcc-f1b4-482f-9c6a-98e866eeabf2"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011BqYLbhQ8b7AN9w2g2gAzG","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"0897e0da-481c-4fb1-8184-df685b54968c","tool_use_result":{"oldTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"completed","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"in_progress","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 15 languages with multiple LLMs","status":"pending","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}],"newTodos":[{"content":"Set up isolated virtual environment and install dependencies","status":"completed","activeForm":"Setting up virtual environment"},{"content":"Write planning.md with motivation, novelty assessment, and experimental design","status":"completed","activeForm":"Writing research plan"},{"content":"Implement multilingual evaluation code (load datasets, API calls)","status":"completed","activeForm":"Implementing evaluation code"},{"content":"Run experiments across 12 languages with 3 LLMs","status":"in_progress","activeForm":"Running multilingual experiments"},{"content":"Analyze results and create visualizations","status":"pending","activeForm":"Analyzing results and creating visualizations"},{"content":"Write REPORT.md with comprehensive findings","status":"pending","activeForm":"Writing final research report"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_013VXbDtqupP7W8vdAjL5Jnw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Roy5iZNqDLTmVY25qjTSpv","name":"Bash","input":{"command":"source .venv/bin/activate && python src/evaluate.py 2>&1","description":"Run full multilingual evaluation","timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":306,"cache_read_input_tokens":70852,"cache_creation":{"ephemeral_5m_input_tokens":306,"ephemeral_1h_input_tokens":0},"output_tokens":136,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"6dd48d13-f455-4f1d-a189-5831602aff5b"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Roy5iZNqDLTmVY25qjTSpv","type":"tool_result","content":"Command running in background with ID: b525325. Output is being written to: /tmp/claude/-data-hypogenicai-workspaces-llm-linguistic-eval-62f9-gemini/tasks/b525325.output","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"5c931b3b-0b32-4ef4-b0ec-cf3ebafc351e","tool_use_result":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"backgroundTaskId":"b525325"}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_019dJ6Vrjcb641XHJ6dhhFch","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WSovT6QvQRX3nKLtBqyM6d","name":"Bash","input":{"command":"tail -100 /tmp/claude/-data-hypogenicai-workspaces-llm-linguistic-eval-62f9-gemini/tasks/b525325.output","description":"Check evaluation progress"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":58734,"cache_read_input_tokens":12671,"cache_creation":{"ephemeral_5m_input_tokens":58734,"ephemeral_1h_input_tokens":0},"output_tokens":111,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"35460dc1-19ba-4599-8383-3ce074e0c256"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WSovT6QvQRX3nKLtBqyM6d","type":"tool_result","content":"\rEvaluating:  11%|█         | 1208/10800 [08:56<1:16:25,  2.09it/s]2026-01-18 22:04:38,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1209/10800 [08:56<1:19:39,  2.01it/s]2026-01-18 22:04:38,730 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1210/10800 [08:57<1:14:59,  2.13it/s]2026-01-18 22:04:39,111 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1211/10800 [08:57<1:10:33,  2.27it/s]2026-01-18 22:04:39,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1212/10800 [08:57<1:06:51,  2.39it/s]2026-01-18 22:04:39,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1213/10800 [08:58<1:09:14,  2.31it/s]2026-01-18 22:04:40,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1214/10800 [08:58<1:08:54,  2.32it/s]2026-01-18 22:04:40,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1215/10800 [08:59<1:09:06,  2.31it/s]2026-01-18 22:04:41,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1216/10800 [08:59<1:07:26,  2.37it/s]2026-01-18 22:04:41,631 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1217/10800 [08:59<1:07:42,  2.36it/s]2026-01-18 22:04:42,129 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1218/10800 [09:00<1:11:18,  2.24it/s]2026-01-18 22:04:42,575 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1219/10800 [09:00<1:11:40,  2.23it/s]2026-01-18 22:04:43,024 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1220/10800 [09:01<1:11:31,  2.23it/s]2026-01-18 22:04:43,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1221/10800 [09:01<1:09:18,  2.30it/s]2026-01-18 22:04:43,813 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1222/10800 [09:02<1:06:47,  2.39it/s]2026-01-18 22:04:44,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1223/10800 [09:02<1:07:27,  2.37it/s]2026-01-18 22:04:44,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1224/10800 [09:02<1:08:49,  2.32it/s]2026-01-18 22:04:45,188 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1225/10800 [09:03<1:11:43,  2.23it/s]2026-01-18 22:04:45,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1226/10800 [09:03<1:08:14,  2.34it/s]2026-01-18 22:04:45,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1227/10800 [09:04<1:08:36,  2.33it/s]2026-01-18 22:04:46,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1228/10800 [09:04<1:06:10,  2.41it/s]2026-01-18 22:04:46,819 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1229/10800 [09:05<1:07:18,  2.37it/s]2026-01-18 22:04:47,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1230/10800 [09:05<1:07:56,  2.35it/s]2026-01-18 22:04:47,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1231/10800 [09:05<1:06:25,  2.40it/s]2026-01-18 22:04:48,119 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1232/10800 [09:06<1:08:54,  2.31it/s]2026-01-18 22:04:48,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1233/10800 [09:06<1:08:47,  2.32it/s]2026-01-18 22:04:48,993 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1234/10800 [09:07<1:09:31,  2.29it/s]2026-01-18 22:04:49,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1235/10800 [09:07<1:13:43,  2.16it/s]2026-01-18 22:04:49,894 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1236/10800 [09:08<1:09:34,  2.29it/s]2026-01-18 22:04:50,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1237/10800 [09:08<1:11:51,  2.22it/s]2026-01-18 22:04:50,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1238/10800 [09:09<1:10:30,  2.26it/s]2026-01-18 22:04:51,236 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1239/10800 [09:09<1:10:10,  2.27it/s]2026-01-18 22:04:51,654 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1240/10800 [09:09<1:09:22,  2.30it/s]2026-01-18 22:04:52,095 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1241/10800 [09:10<1:09:28,  2.29it/s]2026-01-18 22:04:52,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1242/10800 [09:10<1:11:06,  2.24it/s]2026-01-18 22:04:53,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1243/10800 [09:11<1:13:41,  2.16it/s]2026-01-18 22:04:53,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1244/10800 [09:11<1:09:02,  2.31it/s]2026-01-18 22:04:53,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1245/10800 [09:12<1:05:59,  2.41it/s]2026-01-18 22:04:54,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1246/10800 [09:12<1:04:15,  2.48it/s]2026-01-18 22:04:54,643 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1247/10800 [09:12<1:06:53,  2.38it/s]2026-01-18 22:04:55,122 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1248/10800 [09:13<1:09:56,  2.28it/s]2026-01-18 22:04:55,478 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1249/10800 [09:13<1:05:46,  2.42it/s]2026-01-18 22:04:55,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1250/10800 [09:14<1:06:00,  2.41it/s]2026-01-18 22:04:56,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1251/10800 [09:14<1:04:34,  2.46it/s]2026-01-18 22:04:56,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1252/10800 [09:14<1:01:24,  2.59it/s]2026-01-18 22:04:57,029 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1253/10800 [09:15<1:02:29,  2.55it/s]2026-01-18 22:04:57,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1254/10800 [09:15<1:04:55,  2.45it/s]2026-01-18 22:04:57,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1255/10800 [09:16<1:05:58,  2.41it/s]2026-01-18 22:04:58,360 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1256/10800 [09:16<1:07:52,  2.34it/s]2026-01-18 22:04:58,906 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1257/10800 [09:17<1:13:46,  2.16it/s]2026-01-18 22:04:59,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1258/10800 [09:17<1:10:23,  2.26it/s]2026-01-18 22:04:59,701 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1259/10800 [09:17<1:08:39,  2.32it/s]2026-01-18 22:05:00,372 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1260/10800 [09:18<1:19:48,  1.99it/s]2026-01-18 22:05:00,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1261/10800 [09:19<1:18:52,  2.02it/s]2026-01-18 22:05:01,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1262/10800 [09:19<1:16:53,  2.07it/s]2026-01-18 22:05:01,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1263/10800 [09:20<1:17:05,  2.06it/s]2026-01-18 22:05:02,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1264/10800 [09:20<1:15:21,  2.11it/s]2026-01-18 22:05:02,647 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1265/10800 [09:20<1:11:42,  2.22it/s]2026-01-18 22:05:03,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1266/10800 [09:21<1:10:04,  2.27it/s]2026-01-18 22:05:03,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1267/10800 [09:21<1:09:17,  2.29it/s]2026-01-18 22:05:04,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1268/10800 [09:22<1:15:24,  2.11it/s]2026-01-18 22:05:04,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1269/10800 [09:22<1:18:26,  2.03it/s]2026-01-18 22:05:05,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1270/10800 [09:23<1:15:11,  2.11it/s]2026-01-18 22:05:05,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1271/10800 [09:23<1:13:14,  2.17it/s]2026-01-18 22:05:05,908 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1272/10800 [09:24<1:13:02,  2.17it/s]2026-01-18 22:05:06,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1273/10800 [09:24<1:09:22,  2.29it/s]2026-01-18 22:05:06,707 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1274/10800 [09:24<1:08:32,  2.32it/s]2026-01-18 22:05:07,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1275/10800 [09:25<1:07:47,  2.34it/s]2026-01-18 22:05:07,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1276/10800 [09:25<1:13:53,  2.15it/s]2026-01-18 22:05:08,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1277/10800 [09:26<1:10:03,  2.27it/s]2026-01-18 22:05:08,489 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1278/10800 [09:26<1:09:12,  2.29it/s]2026-01-18 22:05:08,966 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1279/10800 [09:27<1:11:06,  2.23it/s]2026-01-18 22:05:09,365 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1280/10800 [09:27<1:09:00,  2.30it/s]2026-01-18 22:05:09,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1281/10800 [09:28<1:06:08,  2.40it/s]2026-01-18 22:05:10,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1282/10800 [09:28<1:03:28,  2.50it/s]2026-01-18 22:05:10,647 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1283/10800 [09:28<1:10:16,  2.26it/s]2026-01-18 22:05:11,045 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1284/10800 [09:29<1:08:01,  2.33it/s]2026-01-18 22:05:11,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1285/10800 [09:29<1:08:10,  2.33it/s]2026-01-18 22:05:11,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1286/10800 [09:30<1:06:01,  2.40it/s]2026-01-18 22:05:12,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1287/10800 [09:30<1:04:41,  2.45it/s]2026-01-18 22:05:12,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1288/10800 [09:30<1:04:06,  2.47it/s]2026-01-18 22:05:13,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1289/10800 [09:31<1:04:50,  2.44it/s]2026-01-18 22:05:13,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1290/10800 [09:31<1:06:25,  2.39it/s]2026-01-18 22:05:13,916 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1291/10800 [09:32<1:05:57,  2.40it/s]2026-01-18 22:05:14,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1292/10800 [09:32<1:09:13,  2.29it/s]2026-01-18 22:05:14,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1293/10800 [09:33<1:06:35,  2.38it/s]2026-01-18 22:05:15,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1294/10800 [09:33<1:07:11,  2.36it/s]2026-01-18 22:05:15,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1295/10800 [09:33<1:05:21,  2.42it/s]2026-01-18 22:05:16,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1296/10800 [09:34<1:09:32,  2.28it/s]2026-01-18 22:05:16,478 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1297/10800 [09:34<1:06:33,  2.38it/s]2026-01-18 22:05:16,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1298/10800 [09:35<1:10:34,  2.24it/s]2026-01-18 22:05:17,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1299/10800 [09:35<1:06:54,  2.37it/s]2026-01-18 22:05:17,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1300/10800 [09:36<1:05:47,  2.41it/s]2026-01-18 22:05:18,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1301/10800 [09:36<1:04:41,  2.45it/s]2026-01-18 22:05:18,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1302/10800 [09:36<1:03:01,  2.51it/s]2026-01-18 22:05:18,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1303/10800 [09:37<1:01:57,  2.55it/s]2026-01-18 22:05:19,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1304/10800 [09:37<1:03:03,  2.51it/s]2026-01-18 22:05:19,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1305/10800 [09:38<1:05:30,  2.42it/s]2026-01-18 22:05:20,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1306/10800 [09:38<1:07:18,  2.35it/s]2026-01-18 22:05:20,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1307/10800 [09:39<1:19:08,  2.00it/s]","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"3d7a042f-c069-4665-8dd2-f97c32aa98d8","tool_use_result":{"stdout":"\rEvaluating:  11%|█         | 1208/10800 [08:56<1:16:25,  2.09it/s]2026-01-18 22:04:38,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1209/10800 [08:56<1:19:39,  2.01it/s]2026-01-18 22:04:38,730 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1210/10800 [08:57<1:14:59,  2.13it/s]2026-01-18 22:04:39,111 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1211/10800 [08:57<1:10:33,  2.27it/s]2026-01-18 22:04:39,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1212/10800 [08:57<1:06:51,  2.39it/s]2026-01-18 22:04:39,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1213/10800 [08:58<1:09:14,  2.31it/s]2026-01-18 22:04:40,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 1214/10800 [08:58<1:08:54,  2.32it/s]2026-01-18 22:04:40,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1215/10800 [08:59<1:09:06,  2.31it/s]2026-01-18 22:04:41,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1216/10800 [08:59<1:07:26,  2.37it/s]2026-01-18 22:04:41,631 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1217/10800 [08:59<1:07:42,  2.36it/s]2026-01-18 22:04:42,129 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1218/10800 [09:00<1:11:18,  2.24it/s]2026-01-18 22:04:42,575 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1219/10800 [09:00<1:11:40,  2.23it/s]2026-01-18 22:04:43,024 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1220/10800 [09:01<1:11:31,  2.23it/s]2026-01-18 22:04:43,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1221/10800 [09:01<1:09:18,  2.30it/s]2026-01-18 22:04:43,813 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1222/10800 [09:02<1:06:47,  2.39it/s]2026-01-18 22:04:44,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1223/10800 [09:02<1:07:27,  2.37it/s]2026-01-18 22:04:44,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1224/10800 [09:02<1:08:49,  2.32it/s]2026-01-18 22:04:45,188 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1225/10800 [09:03<1:11:43,  2.23it/s]2026-01-18 22:04:45,566 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1226/10800 [09:03<1:08:14,  2.34it/s]2026-01-18 22:04:45,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1227/10800 [09:04<1:08:36,  2.33it/s]2026-01-18 22:04:46,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1228/10800 [09:04<1:06:10,  2.41it/s]2026-01-18 22:04:46,819 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1229/10800 [09:05<1:07:18,  2.37it/s]2026-01-18 22:04:47,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1230/10800 [09:05<1:07:56,  2.35it/s]2026-01-18 22:04:47,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1231/10800 [09:05<1:06:25,  2.40it/s]2026-01-18 22:04:48,119 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1232/10800 [09:06<1:08:54,  2.31it/s]2026-01-18 22:04:48,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1233/10800 [09:06<1:08:47,  2.32it/s]2026-01-18 22:04:48,993 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1234/10800 [09:07<1:09:31,  2.29it/s]2026-01-18 22:04:49,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1235/10800 [09:07<1:13:43,  2.16it/s]2026-01-18 22:04:49,894 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1236/10800 [09:08<1:09:34,  2.29it/s]2026-01-18 22:04:50,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1237/10800 [09:08<1:11:51,  2.22it/s]2026-01-18 22:04:50,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1238/10800 [09:09<1:10:30,  2.26it/s]2026-01-18 22:04:51,236 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1239/10800 [09:09<1:10:10,  2.27it/s]2026-01-18 22:04:51,654 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1240/10800 [09:09<1:09:22,  2.30it/s]2026-01-18 22:04:52,095 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 1241/10800 [09:10<1:09:28,  2.29it/s]2026-01-18 22:04:52,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1242/10800 [09:10<1:11:06,  2.24it/s]2026-01-18 22:04:53,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1243/10800 [09:11<1:13:41,  2.16it/s]2026-01-18 22:04:53,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1244/10800 [09:11<1:09:02,  2.31it/s]2026-01-18 22:04:53,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1245/10800 [09:12<1:05:59,  2.41it/s]2026-01-18 22:04:54,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1246/10800 [09:12<1:04:15,  2.48it/s]2026-01-18 22:04:54,643 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1247/10800 [09:12<1:06:53,  2.38it/s]2026-01-18 22:04:55,122 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1248/10800 [09:13<1:09:56,  2.28it/s]2026-01-18 22:04:55,478 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1249/10800 [09:13<1:05:46,  2.42it/s]2026-01-18 22:04:55,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1250/10800 [09:14<1:06:00,  2.41it/s]2026-01-18 22:04:56,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1251/10800 [09:14<1:04:34,  2.46it/s]2026-01-18 22:04:56,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1252/10800 [09:14<1:01:24,  2.59it/s]2026-01-18 22:04:57,029 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1253/10800 [09:15<1:02:29,  2.55it/s]2026-01-18 22:04:57,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1254/10800 [09:15<1:04:55,  2.45it/s]2026-01-18 22:04:57,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1255/10800 [09:16<1:05:58,  2.41it/s]2026-01-18 22:04:58,360 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1256/10800 [09:16<1:07:52,  2.34it/s]2026-01-18 22:04:58,906 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1257/10800 [09:17<1:13:46,  2.16it/s]2026-01-18 22:04:59,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1258/10800 [09:17<1:10:23,  2.26it/s]2026-01-18 22:04:59,701 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1259/10800 [09:17<1:08:39,  2.32it/s]2026-01-18 22:05:00,372 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1260/10800 [09:18<1:19:48,  1.99it/s]2026-01-18 22:05:00,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1261/10800 [09:19<1:18:52,  2.02it/s]2026-01-18 22:05:01,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1262/10800 [09:19<1:16:53,  2.07it/s]2026-01-18 22:05:01,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1263/10800 [09:20<1:17:05,  2.06it/s]2026-01-18 22:05:02,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1264/10800 [09:20<1:15:21,  2.11it/s]2026-01-18 22:05:02,647 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1265/10800 [09:20<1:11:42,  2.22it/s]2026-01-18 22:05:03,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1266/10800 [09:21<1:10:04,  2.27it/s]2026-01-18 22:05:03,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1267/10800 [09:21<1:09:17,  2.29it/s]2026-01-18 22:05:04,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1268/10800 [09:22<1:15:24,  2.11it/s]2026-01-18 22:05:04,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1269/10800 [09:22<1:18:26,  2.03it/s]2026-01-18 22:05:05,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1270/10800 [09:23<1:15:11,  2.11it/s]2026-01-18 22:05:05,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1271/10800 [09:23<1:13:14,  2.17it/s]2026-01-18 22:05:05,908 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1272/10800 [09:24<1:13:02,  2.17it/s]2026-01-18 22:05:06,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1273/10800 [09:24<1:09:22,  2.29it/s]2026-01-18 22:05:06,707 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1274/10800 [09:24<1:08:32,  2.32it/s]2026-01-18 22:05:07,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1275/10800 [09:25<1:07:47,  2.34it/s]2026-01-18 22:05:07,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1276/10800 [09:25<1:13:53,  2.15it/s]2026-01-18 22:05:08,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1277/10800 [09:26<1:10:03,  2.27it/s]2026-01-18 22:05:08,489 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1278/10800 [09:26<1:09:12,  2.29it/s]2026-01-18 22:05:08,966 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1279/10800 [09:27<1:11:06,  2.23it/s]2026-01-18 22:05:09,365 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1280/10800 [09:27<1:09:00,  2.30it/s]2026-01-18 22:05:09,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1281/10800 [09:28<1:06:08,  2.40it/s]2026-01-18 22:05:10,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1282/10800 [09:28<1:03:28,  2.50it/s]2026-01-18 22:05:10,647 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1283/10800 [09:28<1:10:16,  2.26it/s]2026-01-18 22:05:11,045 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1284/10800 [09:29<1:08:01,  2.33it/s]2026-01-18 22:05:11,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1285/10800 [09:29<1:08:10,  2.33it/s]2026-01-18 22:05:11,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1286/10800 [09:30<1:06:01,  2.40it/s]2026-01-18 22:05:12,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1287/10800 [09:30<1:04:41,  2.45it/s]2026-01-18 22:05:12,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1288/10800 [09:30<1:04:06,  2.47it/s]2026-01-18 22:05:13,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1289/10800 [09:31<1:04:50,  2.44it/s]2026-01-18 22:05:13,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1290/10800 [09:31<1:06:25,  2.39it/s]2026-01-18 22:05:13,916 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1291/10800 [09:32<1:05:57,  2.40it/s]2026-01-18 22:05:14,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1292/10800 [09:32<1:09:13,  2.29it/s]2026-01-18 22:05:14,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1293/10800 [09:33<1:06:35,  2.38it/s]2026-01-18 22:05:15,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1294/10800 [09:33<1:07:11,  2.36it/s]2026-01-18 22:05:15,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1295/10800 [09:33<1:05:21,  2.42it/s]2026-01-18 22:05:16,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1296/10800 [09:34<1:09:32,  2.28it/s]2026-01-18 22:05:16,478 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1297/10800 [09:34<1:06:33,  2.38it/s]2026-01-18 22:05:16,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1298/10800 [09:35<1:10:34,  2.24it/s]2026-01-18 22:05:17,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1299/10800 [09:35<1:06:54,  2.37it/s]2026-01-18 22:05:17,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1300/10800 [09:36<1:05:47,  2.41it/s]2026-01-18 22:05:18,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1301/10800 [09:36<1:04:41,  2.45it/s]2026-01-18 22:05:18,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1302/10800 [09:36<1:03:01,  2.51it/s]2026-01-18 22:05:18,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1303/10800 [09:37<1:01:57,  2.55it/s]2026-01-18 22:05:19,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1304/10800 [09:37<1:03:03,  2.51it/s]2026-01-18 22:05:19,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1305/10800 [09:38<1:05:30,  2.42it/s]2026-01-18 22:05:20,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1306/10800 [09:38<1:07:18,  2.35it/s]2026-01-18 22:05:20,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 1307/10800 [09:39<1:19:08,  2.00it/s]","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_019foR55ijxHaQqQkABEDBb1","type":"message","role":"assistant","content":[{"type":"text","text":"The evaluation is running. It will take some time since we have 3 models × 12 languages × 300 questions = 10,800 API calls. Given the ~1 hour+ estimate, let me reduce the sample size to get results faster. Let me check how much progress we've made:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8959,"cache_read_input_tokens":71405,"cache_creation":{"ephemeral_5m_input_tokens":8959,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"fb987842-16f8-4dcf-9b15-847efa488627"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_019foR55ijxHaQqQkABEDBb1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TJMbEp3oTU2DZLJtqGQX5C","name":"Bash","input":{"command":"ls -la results/raw/ 2>/dev/null | head -20","description":"Check saved results so far"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8959,"cache_read_input_tokens":71405,"cache_creation":{"ephemeral_5m_input_tokens":8959,"ephemeral_1h_input_tokens":0},"output_tokens":156,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"76a0f9b8-c8a6-4882-b398-2d65b97fe1e3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TJMbEp3oTU2DZLJtqGQX5C","type":"tool_result","content":"total 223\ndrwxrwx--- 2 haokunliu haokunliu      6 Jan 18 22:04 .\ndrwxrwx--- 4 haokunliu haokunliu      5 Jan 18 21:55 ..\n-rw-rw---- 1 haokunliu haokunliu 114091 Jan 18 21:57 gpt-4o_en.json\n-rw-rw---- 1 haokunliu haokunliu 119769 Jan 18 22:02 gpt-4o_es.json\n-rw-rw---- 1 haokunliu haokunliu 121796 Jan 18 22:04 gpt-4o_fr.json\n-rw-rw---- 1 haokunliu haokunliu 223484 Jan 18 22:00 gpt-4o_zh.json","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c85359a5-e00f-42d9-8d70-b8e04595784b","tool_use_result":{"stdout":"total 223\ndrwxrwx--- 2 haokunliu haokunliu      6 Jan 18 22:04 .\ndrwxrwx--- 4 haokunliu haokunliu      5 Jan 18 21:55 ..\n-rw-rw---- 1 haokunliu haokunliu 114091 Jan 18 21:57 gpt-4o_en.json\n-rw-rw---- 1 haokunliu haokunliu 119769 Jan 18 22:02 gpt-4o_es.json\n-rw-rw---- 1 haokunliu haokunliu 121796 Jan 18 22:04 gpt-4o_fr.json\n-rw-rw---- 1 haokunliu haokunliu 223484 Jan 18 22:00 gpt-4o_zh.json","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_011jQ8TpxvgfyMG3YmFWQmU4","type":"message","role":"assistant","content":[{"type":"text","text":"Good, we already have results for 4 languages with GPT-4o (English, Chinese, Spanish, French). The process is running. Given time constraints, let me kill this process and run with a smaller sample size to ensure we can complete the evaluation within a reasonable timeframe:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":80364,"cache_creation":{"ephemeral_5m_input_tokens":476,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"e8e2ce34-e898-40bf-972c-9d68579ef917"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_011jQ8TpxvgfyMG3YmFWQmU4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018TvAynwV9kmudREQqtrVUV","name":"KillShell","input":{"shell_id":"b525325"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":476,"cache_read_input_tokens":80364,"cache_creation":{"ephemeral_5m_input_tokens":476,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"f25c510b-cfd5-492a-b844-2271ab6a3896"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018TvAynwV9kmudREQqtrVUV","type":"tool_result","content":"{\"message\":\"Successfully killed shell: b525325 (source .venv/bin/activate && python src/evaluate.py 2>&1)\",\"shell_id\":\"b525325\"}"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"ceab27b8-f3ff-41a6-955b-e88206c56d40","tool_use_result":{"message":"Successfully killed shell: b525325 (source .venv/bin/activate && python src/evaluate.py 2>&1)","shell_id":"b525325"}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Sk7vX5uEvZJGnRHihFNK1o","type":"message","role":"assistant","content":[{"type":"text","text":"Let me read the results we have so far and then run a reduced experiment with fewer samples:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":390,"cache_read_input_tokens":80840,"cache_creation":{"ephemeral_5m_input_tokens":390,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"f25079a7-bc2b-4bb2-a847-3938c961bff3"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01Sk7vX5uEvZJGnRHihFNK1o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GUG3PbHgnuRAxkLMoWvENL","name":"Bash","input":{"command":"source .venv/bin/activate && python << 'EOF'\nimport json\nfrom pathlib import Path\n\nresults_dir = Path(\"results/raw\")\nfor f in sorted(results_dir.glob(\"*.json\")):\n    with open(f) as fh:\n        data = json.load(fh)\n    print(f\"{data['model']} / {data['language']}: {data['accuracy']:.2%} ({data['correct']}/{data['total_questions']})\")\nEOF\n","description":"Check collected results so far"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":390,"cache_read_input_tokens":80840,"cache_creation":{"ephemeral_5m_input_tokens":390,"ephemeral_1h_input_tokens":0},"output_tokens":209,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"a5bfb2f5-18fe-4d18-a709-0a147509308f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GUG3PbHgnuRAxkLMoWvENL","type":"tool_result","content":"gpt-4o / en: 84.67% (254/300)\ngpt-4o / es: 79.67% (239/300)\ngpt-4o / fr: 82.67% (248/300)\ngpt-4o / zh: 83.33% (250/300)","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"e674c580-2ced-47a4-839c-f73ffeaea97c","tool_use_result":{"stdout":"gpt-4o / en: 84.67% (254/300)\ngpt-4o / es: 79.67% (239/300)\ngpt-4o / fr: 82.67% (248/300)\ngpt-4o / zh: 83.33% (250/300)","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_019CaWm6X6nX2psn5nMQdVWt","type":"message","role":"assistant","content":[{"type":"text","text":"We have results for the first 4 languages with GPT-4o. Let me update the evaluation script to use 100 samples per language (instead of 300) and run the remaining evaluations:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":295,"cache_read_input_tokens":81230,"cache_creation":{"ephemeral_5m_input_tokens":295,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"8c0ce336-c1ad-482c-a5fc-978a403f09bd"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_019CaWm6X6nX2psn5nMQdVWt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QamNEBcXtvKyRpCJBMH1iP","name":"Edit","input":{"file_path":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","old_string":"# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5","new_string":"# Evaluation parameters\nSAMPLE_SIZE = 100  # Questions per language (reduced for faster completion)\nMAX_RETRIES = 3\nRETRY_DELAY = 5"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":295,"cache_read_input_tokens":81230,"cache_creation":{"ephemeral_5m_input_tokens":295,"ephemeral_1h_input_tokens":0},"output_tokens":246,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"99a14f8a-386c-4deb-9fae-eaa5160a6f58"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QamNEBcXtvKyRpCJBMH1iP","type":"tool_result","content":"The file /data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n    55→    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    56→    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n    57→}\n    58→\n    59→# Evaluation parameters\n    60→SAMPLE_SIZE = 100  # Questions per language (reduced for faster completion)\n    61→MAX_RETRIES = 3\n    62→RETRY_DELAY = 5\n    63→\n    64→\n    65→@dataclass\n    66→class EvaluationResult:"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"a2301180-46a4-4098-9072-5d47882f7743","tool_use_result":{"filePath":"/data/hypogenicai/workspaces/llm-linguistic-eval-62f9-gemini/src/evaluate.py","oldString":"# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5","newString":"# Evaluation parameters\nSAMPLE_SIZE = 100  # Questions per language (reduced for faster completion)\nMAX_RETRIES = 3\nRETRY_DELAY = 5","originalFile":"#!/usr/bin/env python3\n\"\"\"\nMultilingual LLM Evaluation Script\n\nThis script evaluates multiple LLMs across different languages using the MuBench MMLU dataset.\nIt measures accuracy and performance gaps across high, mid, and low-resource languages.\n\"\"\"\n\nimport os\nimport json\nimport time\nimport random\nimport asyncio\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nimport openai\nimport requests\n\n# Set random seed for reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('results/evaluation.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Language configurations\nLANGUAGES = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nALL_LANGUAGES = LANGUAGES['high'] + LANGUAGES['mid'] + LANGUAGES['low']\n\n# Model configurations - using available models from OpenRouter\nMODELS = {\n    'gpt-4o': {'provider': 'openai', 'model_id': 'gpt-4o'},\n    'claude-sonnet-4.5': {'provider': 'openrouter', 'model_id': 'anthropic/claude-sonnet-4.5'},\n    'gemini-3-flash': {'provider': 'openrouter', 'model_id': 'google/gemini-3-flash-preview'}\n}\n\n# Evaluation parameters\nSAMPLE_SIZE = 300  # Questions per language (reduced for cost management)\nMAX_RETRIES = 3\nRETRY_DELAY = 5\n\n\n@dataclass\nclass EvaluationResult:\n    \"\"\"Store results for a single evaluation run.\"\"\"\n    model: str\n    language: str\n    resource_level: str\n    total_questions: int\n    correct: int\n    accuracy: float\n    responses: List[Dict]\n    timestamp: str\n\n\ndef get_resource_level(lang: str) -> str:\n    \"\"\"Get resource level for a language.\"\"\"\n    for level, langs in LANGUAGES.items():\n        if lang in langs:\n            return level\n    return 'unknown'\n\n\ndef load_mubench_data(language: str, sample_size: int = SAMPLE_SIZE) -> List[Dict]:\n    \"\"\"\n    Load MuBench MMLU dataset for a specific language.\n\n    Args:\n        language: Language code (e.g., 'en', 'zh', 'ar')\n        sample_size: Number of questions to sample\n\n    Returns:\n        List of question dictionaries\n    \"\"\"\n    config_name = f\"MMLUDataset_en_template_{language}\"\n    logger.info(f\"Loading MuBench MMLU for language: {language} (config: {config_name})\")\n\n    try:\n        dataset = load_dataset(\"aialt/MuBench\", config_name, split=\"test\")\n\n        # Sample questions\n        total_size = len(dataset)\n        indices = random.sample(range(total_size), min(sample_size, total_size))\n        samples = [dataset[i] for i in indices]\n\n        logger.info(f\"Loaded {len(samples)} questions for {language} (from {total_size} total)\")\n        return samples\n\n    except Exception as e:\n        logger.error(f\"Failed to load dataset for {language}: {e}\")\n        raise\n\n\ndef format_prompt(question_data: Dict) -> str:\n    \"\"\"\n    Format a question for LLM evaluation.\n\n    The MuBench dataset already has formatted prompts, so we use them directly.\n    \"\"\"\n    # MuBench format already includes the question and choices\n    prompt = question_data['prompt']\n    return prompt\n\n\ndef parse_answer(response: str) -> Optional[str]:\n    \"\"\"\n    Parse the model's response to extract the answer letter.\n\n    Args:\n        response: Raw model response\n\n    Returns:\n        Answer letter (A, B, C, or D) or None if unparseable\n    \"\"\"\n    response = response.strip().upper()\n\n    # Direct answer\n    if response in ['A', 'B', 'C', 'D']:\n        return response\n\n    # Common patterns\n    patterns = [\n        r'^([ABCD])\\.',\n        r'^([ABCD])\\)',\n        r'^([ABCD]):',\n        r'^([ABCD])\\s',\n        r'answer\\s*(?:is\\s*)?([ABCD])',\n        r'(?:^|\\s)([ABCD])(?:\\s|$|\\.)',\n    ]\n\n    import re\n    for pattern in patterns:\n        match = re.search(pattern, response, re.IGNORECASE)\n        if match:\n            return match.group(1).upper()\n\n    # First letter if it's A, B, C, or D\n    if response and response[0] in ['A', 'B', 'C', 'D']:\n        return response[0]\n\n    return None\n\n\ndef call_openai(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenAI API.\"\"\"\n    client = openai.OpenAI()\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = client.chat.completions.create(\n                model=model_id,\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0,\n                max_tokens=10\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenAI API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef call_openrouter(prompt: str, model_id: str) -> str:\n    \"\"\"Call OpenRouter API.\"\"\"\n    api_key = os.environ.get('OPENROUTER_API_KEY')\n    if not api_key:\n        raise ValueError(\"OPENROUTER_API_KEY not set\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {api_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"model\": model_id,\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant taking a multiple choice test. Answer with only the letter (A, B, C, or D) of the correct answer.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        \"temperature\": 0,\n        \"max_tokens\": 20  # Increased slightly to ensure we get a response\n    }\n\n    for attempt in range(MAX_RETRIES):\n        try:\n            response = requests.post(\n                \"https://openrouter.ai/api/v1/chat/completions\",\n                headers=headers,\n                json=data,\n                timeout=60\n            )\n            response.raise_for_status()\n            result = response.json()\n            content = result['choices'][0]['message']['content']\n            # Handle None or empty content\n            if content is None:\n                content = \"\"\n            return content.strip()\n        except Exception as e:\n            if attempt < MAX_RETRIES - 1:\n                logger.warning(f\"OpenRouter API error (attempt {attempt + 1}): {e}\")\n                time.sleep(RETRY_DELAY * (attempt + 1))\n            else:\n                raise\n\n\ndef evaluate_model_on_language(\n    model_name: str,\n    model_config: Dict,\n    questions: List[Dict],\n    language: str,\n    progress_bar: Optional[tqdm] = None\n) -> EvaluationResult:\n    \"\"\"\n    Evaluate a single model on questions in a specific language.\n\n    Args:\n        model_name: Name of the model\n        model_config: Model configuration dict\n        questions: List of question dictionaries\n        language: Language code\n        progress_bar: Optional progress bar to update\n\n    Returns:\n        EvaluationResult with accuracy and detailed responses\n    \"\"\"\n    provider = model_config['provider']\n    model_id = model_config['model_id']\n\n    responses = []\n    correct = 0\n\n    call_fn = call_openai if provider == 'openai' else call_openrouter\n\n    for i, q in enumerate(questions):\n        prompt = format_prompt(q)\n\n        try:\n            raw_response = call_fn(prompt, model_id)\n            parsed_answer = parse_answer(raw_response)\n\n            # MuBench uses 0-indexed label, choices are [\"A\", \"B\", \"C\", \"D\"]\n            correct_answer = q['choices'][q['label']]\n            is_correct = parsed_answer == correct_answer\n\n            if is_correct:\n                correct += 1\n\n            responses.append({\n                'question_id': q.get('_id', i),\n                'prompt': prompt[:200] + '...' if len(prompt) > 200 else prompt,\n                'raw_response': raw_response,\n                'parsed_answer': parsed_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct\n            })\n\n        except Exception as e:\n            logger.error(f\"Error evaluating question {i} for {model_name}/{language}: {e}\")\n            responses.append({\n                'question_id': q.get('_id', i),\n                'error': str(e),\n                'is_correct': False\n            })\n\n        if progress_bar:\n            progress_bar.update(1)\n\n        # Small delay to avoid rate limiting\n        time.sleep(0.1)\n\n    accuracy = correct / len(questions) if questions else 0.0\n\n    return EvaluationResult(\n        model=model_name,\n        language=language,\n        resource_level=get_resource_level(language),\n        total_questions=len(questions),\n        correct=correct,\n        accuracy=accuracy,\n        responses=responses,\n        timestamp=datetime.now().isoformat()\n    )\n\n\ndef run_evaluation(\n    models: Dict[str, Dict],\n    languages: List[str],\n    sample_size: int = SAMPLE_SIZE,\n    save_path: str = 'results/'\n) -> pd.DataFrame:\n    \"\"\"\n    Run full evaluation across all models and languages.\n\n    Args:\n        models: Dictionary of model configurations\n        languages: List of language codes\n        sample_size: Questions per language\n        save_path: Directory to save results\n\n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Load all datasets first\n    logger.info(\"Loading datasets...\")\n    datasets = {}\n    for lang in languages:\n        try:\n            datasets[lang] = load_mubench_data(lang, sample_size)\n        except Exception as e:\n            logger.error(f\"Skipping language {lang}: {e}\")\n            continue\n\n    # Calculate total iterations for progress bar\n    total_iterations = sum(\n        len(datasets.get(lang, []))\n        for lang in languages\n        for _ in models\n    )\n\n    results = []\n\n    with tqdm(total=total_iterations, desc=\"Evaluating\") as pbar:\n        for model_name, model_config in models.items():\n            logger.info(f\"\\nEvaluating model: {model_name}\")\n\n            for lang in languages:\n                if lang not in datasets:\n                    continue\n\n                logger.info(f\"  Language: {lang}\")\n\n                try:\n                    result = evaluate_model_on_language(\n                        model_name,\n                        model_config,\n                        datasets[lang],\n                        lang,\n                        pbar\n                    )\n                    results.append(result)\n\n                    # Save intermediate results\n                    result_path = Path(save_path) / 'raw' / f'{model_name}_{lang}.json'\n                    with open(result_path, 'w') as f:\n                        json.dump(asdict(result), f, indent=2)\n\n                    logger.info(f\"    Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total_questions})\")\n\n                except Exception as e:\n                    logger.error(f\"  Failed to evaluate {model_name} on {lang}: {e}\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([{\n        'model': r.model,\n        'language': r.language,\n        'resource_level': r.resource_level,\n        'accuracy': r.accuracy,\n        'correct': r.correct,\n        'total': r.total_questions\n    } for r in results])\n\n    # Save summary\n    df.to_csv(Path(save_path) / 'evaluation_results.csv', index=False)\n\n    return df\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    logger.info(\"=\"*60)\n    logger.info(\"Multilingual LLM Evaluation Starting\")\n    logger.info(f\"Seed: {SEED}\")\n    logger.info(f\"Languages: {ALL_LANGUAGES}\")\n    logger.info(f\"Models: {list(MODELS.keys())}\")\n    logger.info(f\"Sample size per language: {SAMPLE_SIZE}\")\n    logger.info(\"=\"*60)\n\n    # Ensure results directory exists\n    Path('results/raw').mkdir(parents=True, exist_ok=True)\n\n    # Run evaluation\n    results_df = run_evaluation(MODELS, ALL_LANGUAGES)\n\n    # Log summary\n    logger.info(\"\\n\" + \"=\"*60)\n    logger.info(\"Evaluation Complete - Summary\")\n    logger.info(\"=\"*60)\n\n    # Summary by model\n    logger.info(\"\\nAccuracy by Model:\")\n    for model in results_df['model'].unique():\n        model_df = results_df[results_df['model'] == model]\n        avg_acc = model_df['accuracy'].mean()\n        logger.info(f\"  {model}: {avg_acc:.2%}\")\n\n    # Summary by resource level\n    logger.info(\"\\nAccuracy by Resource Level:\")\n    for level in ['high', 'mid', 'low']:\n        level_df = results_df[results_df['resource_level'] == level]\n        avg_acc = level_df['accuracy'].mean()\n        logger.info(f\"  {level}: {avg_acc:.2%}\")\n\n    # English vs average\n    en_df = results_df[results_df['language'] == 'en']\n    en_avg = en_df['accuracy'].mean()\n    other_df = results_df[results_df['language'] != 'en']\n    other_avg = other_df['accuracy'].mean()\n    logger.info(f\"\\nEnglish avg: {en_avg:.2%}\")\n    logger.info(f\"Non-English avg: {other_avg:.2%}\")\n    logger.info(f\"Performance gap: {(en_avg - other_avg) / en_avg:.2%}\")\n\n    logger.info(\"\\nResults saved to results/evaluation_results.csv\")\n\n    return results_df\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":57,"oldLines":7,"newStart":57,"newLines":7,"lines":[" }"," "," # Evaluation parameters","-SAMPLE_SIZE = 300  # Questions per language (reduced for cost management)","+SAMPLE_SIZE = 100  # Questions per language (reduced for faster completion)"," MAX_RETRIES = 3"," RETRY_DELAY = 5"," "]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QMna2me4e7m8z4t2NSFcxY","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me clear the existing results and run a fresh evaluation with 100 samples per language:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":706,"cache_read_input_tokens":81525,"cache_creation":{"ephemeral_5m_input_tokens":706,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"034408d2-2f72-4bfa-b6fe-351cde235086"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01QMna2me4e7m8z4t2NSFcxY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RhBoKYKZjQxiHrrtzNxv7g","name":"Bash","input":{"command":"rm -rf results/raw/*.json && ls results/raw/","description":"Clear previous results"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":706,"cache_read_input_tokens":81525,"cache_creation":{"ephemeral_5m_input_tokens":706,"ephemeral_1h_input_tokens":0},"output_tokens":105,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"aa7cec76-21f6-48a6-880d-d377c6f985f2"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RhBoKYKZjQxiHrrtzNxv7g","type":"tool_result","content":"","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"227f3564-aff9-4e00-8092-916b9cdfa19b","tool_use_result":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_013vJD4Hr3mG25ZXsukSCJYa","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ks2L1fDRQ1UaynxhzyakXG","name":"Bash","input":{"command":"source .venv/bin/activate && python src/evaluate.py 2>&1","description":"Run evaluation with reduced sample size","timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":131,"cache_read_input_tokens":82231,"cache_creation":{"ephemeral_5m_input_tokens":131,"ephemeral_1h_input_tokens":0},"output_tokens":110,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"59321a14-a782-4f22-a8c9-e39bb49dba8c"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ks2L1fDRQ1UaynxhzyakXG","type":"tool_result","content":"Command running in background with ID: b035253. Output is being written to: /tmp/claude/-data-hypogenicai-workspaces-llm-linguistic-eval-62f9-gemini/tasks/b035253.output","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"b5e5254a-2009-49f1-8d6c-aa719477c642","tool_use_result":{"stdout":"","stderr":"","interrupted":false,"isImage":false,"backgroundTaskId":"b035253"}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CgL6k6DvvZcqaqGRXS28tL","type":"message","role":"assistant","content":[{"type":"text","text":"Let me monitor the progress:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":70158,"cache_read_input_tokens":12671,"cache_creation":{"ephemeral_5m_input_tokens":70158,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"916e3e07-50ff-40a2-b74a-0bb2d9b00feb"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01CgL6k6DvvZcqaqGRXS28tL","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CPUQQ9CGBBD9Lg1Hj2MiHY","name":"Bash","input":{"command":"tail -30 /tmp/claude/-data-hypogenicai-workspaces-llm-linguistic-eval-62f9-gemini/tasks/b035253.output 2>/dev/null","description":"Check progress"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":70158,"cache_read_input_tokens":12671,"cache_creation":{"ephemeral_5m_input_tokens":70158,"ephemeral_1h_input_tokens":0},"output_tokens":123,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"23becffa-eb97-44c1-93ca-3dba8d75f816"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CPUQQ9CGBBD9Lg1Hj2MiHY","type":"tool_result","content":"\rEvaluating:  33%|███▎      | 1175/3600 [08:59<19:24,  2.08it/s]2026-01-18 22:15:12,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1176/3600 [09:00<20:52,  1.94it/s]2026-01-18 22:15:13,030 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1177/3600 [09:00<21:41,  1.86it/s]2026-01-18 22:15:13,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1178/3600 [09:01<21:03,  1.92it/s]2026-01-18 22:15:13,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1179/3600 [09:01<19:41,  2.05it/s]2026-01-18 22:15:14,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1180/3600 [09:02<19:17,  2.09it/s]2026-01-18 22:15:14,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1181/3600 [09:02<18:41,  2.16it/s]2026-01-18 22:15:15,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1182/3600 [09:02<17:51,  2.26it/s]2026-01-18 22:15:15,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1183/3600 [09:03<17:22,  2.32it/s]2026-01-18 22:15:15,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1184/3600 [09:03<16:50,  2.39it/s]2026-01-18 22:15:16,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"9f736c5d-ed88-462b-9b87-167fe732cf8f","tool_use_result":{"stdout":"\rEvaluating:  33%|███▎      | 1175/3600 [08:59<19:24,  2.08it/s]2026-01-18 22:15:12,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1176/3600 [09:00<20:52,  1.94it/s]2026-01-18 22:15:13,030 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1177/3600 [09:00<21:41,  1.86it/s]2026-01-18 22:15:13,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1178/3600 [09:01<21:03,  1.92it/s]2026-01-18 22:15:13,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1179/3600 [09:01<19:41,  2.05it/s]2026-01-18 22:15:14,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1180/3600 [09:02<19:17,  2.09it/s]2026-01-18 22:15:14,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1181/3600 [09:02<18:41,  2.16it/s]2026-01-18 22:15:15,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1182/3600 [09:02<17:51,  2.26it/s]2026-01-18 22:15:15,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1183/3600 [09:03<17:22,  2.32it/s]2026-01-18 22:15:15,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1184/3600 [09:03<16:50,  2.39it/s]2026-01-18 22:15:16,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_015hhPNRdMoM9d49MMXP7xVf","type":"message","role":"assistant","content":[{"type":"text","text":"The evaluation is progressing. It's now on Claude Sonnet 4.5 after completing GPT-4o for all 12 languages. Let me check the results so far:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3048,"cache_read_input_tokens":82829,"cache_creation":{"ephemeral_5m_input_tokens":3048,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"1edb792c-bbbc-4627-a447-ccccd93cda81"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_015hhPNRdMoM9d49MMXP7xVf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011Wh38RWQ98TPS53EDfukA9","name":"Bash","input":{"command":"ls -la results/raw/*.json 2>/dev/null | head -20","description":"List result files"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":3048,"cache_read_input_tokens":82829,"cache_creation":{"ephemeral_5m_input_tokens":3048,"ephemeral_1h_input_tokens":0},"output_tokens":130,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"05d2a7f9-8239-40cb-82a8-d0e7afb0cf2e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011Wh38RWQ98TPS53EDfukA9","type":"tool_result","content":"-rw-rw---- 1 haokunliu haokunliu  97735 Jan 18 22:09 results/raw/gpt-4o_ar.json\n-rw-rw---- 1 haokunliu haokunliu 104306 Jan 18 22:13 results/raw/gpt-4o_bn.json\n-rw-rw---- 1 haokunliu haokunliu  38043 Jan 18 22:06 results/raw/gpt-4o_en.json\n-rw-rw---- 1 haokunliu haokunliu  40106 Jan 18 22:08 results/raw/gpt-4o_es.json\n-rw-rw---- 1 haokunliu haokunliu  40398 Jan 18 22:09 results/raw/gpt-4o_fr.json\n-rw-rw---- 1 haokunliu haokunliu  38225 Jan 18 22:12 results/raw/gpt-4o_id.json\n-rw-rw---- 1 haokunliu haokunliu  78420 Jan 18 22:10 results/raw/gpt-4o_ko.json\n-rw-rw---- 1 haokunliu haokunliu  38133 Jan 18 22:14 results/raw/gpt-4o_sw.json\n-rw-rw---- 1 haokunliu haokunliu 108035 Jan 18 22:15 results/raw/gpt-4o_ta.json\n-rw-rw---- 1 haokunliu haokunliu 104931 Jan 18 22:13 results/raw/gpt-4o_te.json\n-rw-rw---- 1 haokunliu haokunliu  54935 Jan 18 22:11 results/raw/gpt-4o_vi.json\n-rw-rw---- 1 haokunliu haokunliu  77624 Jan 18 22:07 results/raw/gpt-4o_zh.json","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"a4d0d328-45ed-4463-9811-0dece1f95a59","tool_use_result":{"stdout":"-rw-rw---- 1 haokunliu haokunliu  97735 Jan 18 22:09 results/raw/gpt-4o_ar.json\n-rw-rw---- 1 haokunliu haokunliu 104306 Jan 18 22:13 results/raw/gpt-4o_bn.json\n-rw-rw---- 1 haokunliu haokunliu  38043 Jan 18 22:06 results/raw/gpt-4o_en.json\n-rw-rw---- 1 haokunliu haokunliu  40106 Jan 18 22:08 results/raw/gpt-4o_es.json\n-rw-rw---- 1 haokunliu haokunliu  40398 Jan 18 22:09 results/raw/gpt-4o_fr.json\n-rw-rw---- 1 haokunliu haokunliu  38225 Jan 18 22:12 results/raw/gpt-4o_id.json\n-rw-rw---- 1 haokunliu haokunliu  78420 Jan 18 22:10 results/raw/gpt-4o_ko.json\n-rw-rw---- 1 haokunliu haokunliu  38133 Jan 18 22:14 results/raw/gpt-4o_sw.json\n-rw-rw---- 1 haokunliu haokunliu 108035 Jan 18 22:15 results/raw/gpt-4o_ta.json\n-rw-rw---- 1 haokunliu haokunliu 104931 Jan 18 22:13 results/raw/gpt-4o_te.json\n-rw-rw---- 1 haokunliu haokunliu  54935 Jan 18 22:11 results/raw/gpt-4o_vi.json\n-rw-rw---- 1 haokunliu haokunliu  77624 Jan 18 22:07 results/raw/gpt-4o_zh.json","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_012X8RMYy3sopKa5nFs3KFsb","type":"message","role":"assistant","content":[{"type":"text","text":"GPT-4o evaluation is complete for all 12 languages. Let me check the GPT-4o results while waiting for the other models:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":983,"cache_read_input_tokens":85877,"cache_creation":{"ephemeral_5m_input_tokens":983,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"5b19baea-b0c4-4968-9051-3f8f30d4b4a8"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_012X8RMYy3sopKa5nFs3KFsb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0123MZTMjCbUmQshLojzF17Y","name":"Bash","input":{"command":"source .venv/bin/activate && python << 'EOF'\nimport json\nfrom pathlib import Path\n\nresults_dir = Path(\"results/raw\")\nprint(\"GPT-4o Results:\")\nprint(\"=\" * 50)\n\n# Organize by resource level\nlevels = {\n    'high': ['en', 'zh', 'es', 'fr'],\n    'mid': ['ar', 'ko', 'vi', 'id'],\n    'low': ['bn', 'te', 'sw', 'ta']\n}\n\nfor level, langs in levels.items():\n    print(f\"\\n{level.upper()} RESOURCE:\")\n    for lang in langs:\n        f = results_dir / f\"gpt-4o_{lang}.json\"\n        if f.exists():\n            with open(f) as fh:\n                data = json.load(fh)\n            print(f\"  {lang}: {data['accuracy']:.2%} ({data['correct']}/{data['total_questions']})\")\n        else:\n            print(f\"  {lang}: (not yet complete)\")\n\n# Calculate summary stats\naccuracies = {'high': [], 'mid': [], 'low': []}\nfor level, langs in levels.items():\n    for lang in langs:\n        f = results_dir / f\"gpt-4o_{lang}.json\"\n        if f.exists():\n            with open(f) as fh:\n                data = json.load(fh)\n            accuracies[level].append(data['accuracy'])\n\nprint(\"\\nSUMMARY:\")\nfor level in ['high', 'mid', 'low']:\n    if accuracies[level]:\n        avg = sum(accuracies[level]) / len(accuracies[level])\n        print(f\"  {level}: {avg:.2%}\")\n        \nen_acc = None\nall_non_en = []\nfor level, langs in levels.items():\n    for lang in langs:\n        f = results_dir / f\"gpt-4o_{lang}.json\"\n        if f.exists():\n            with open(f) as fh:\n                data = json.load(fh)\n            if lang == 'en':\n                en_acc = data['accuracy']\n            else:\n                all_non_en.append(data['accuracy'])\n\nif en_acc and all_non_en:\n    non_en_avg = sum(all_non_en) / len(all_non_en)\n    gap = (en_acc - non_en_avg) / en_acc * 100\n    print(f\"\\nEnglish: {en_acc:.2%}\")\n    print(f\"Non-English avg: {non_en_avg:.2%}\")\n    print(f\"Performance Gap: {gap:.1f}%\")\nEOF\n","description":"Check GPT-4o results summary"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":983,"cache_read_input_tokens":85877,"cache_creation":{"ephemeral_5m_input_tokens":983,"ephemeral_1h_input_tokens":0},"output_tokens":782,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"d1fe767d-c265-404a-aa12-554b566a92c3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0123MZTMjCbUmQshLojzF17Y","type":"tool_result","content":"GPT-4o Results:\n==================================================\n\nHIGH RESOURCE:\n  en: 86.00% (86/100)\n  zh: 75.00% (75/100)\n  es: 82.00% (82/100)\n  fr: 82.00% (82/100)\n\nMID RESOURCE:\n  ar: 85.00% (85/100)\n  ko: 84.00% (84/100)\n  vi: 78.00% (78/100)\n  id: 81.00% (81/100)\n\nLOW RESOURCE:\n  bn: 76.00% (76/100)\n  te: 69.00% (69/100)\n  sw: 79.00% (79/100)\n  ta: 74.00% (74/100)\n\nSUMMARY:\n  high: 81.25%\n  mid: 82.00%\n  low: 74.50%\n\nEnglish: 86.00%\nNon-English avg: 78.64%\nPerformance Gap: 8.6%","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"5c156db8-61f3-4af9-b235-162a19dfeaab","tool_use_result":{"stdout":"GPT-4o Results:\n==================================================\n\nHIGH RESOURCE:\n  en: 86.00% (86/100)\n  zh: 75.00% (75/100)\n  es: 82.00% (82/100)\n  fr: 82.00% (82/100)\n\nMID RESOURCE:\n  ar: 85.00% (85/100)\n  ko: 84.00% (84/100)\n  vi: 78.00% (78/100)\n  id: 81.00% (81/100)\n\nLOW RESOURCE:\n  bn: 76.00% (76/100)\n  te: 69.00% (69/100)\n  sw: 79.00% (79/100)\n  ta: 74.00% (74/100)\n\nSUMMARY:\n  high: 81.25%\n  mid: 82.00%\n  low: 74.50%\n\nEnglish: 86.00%\nNon-English avg: 78.64%\nPerformance Gap: 8.6%","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VD1yrRQxvXiUYcVzo1Qa1D","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! The GPT-4o results show a clear pattern. Let me wait for the evaluation to complete. Let me check the progress again:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1047,"cache_read_input_tokens":86860,"cache_creation":{"ephemeral_5m_input_tokens":1047,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"8bce468d-28d0-4601-85d1-e72010c74a8b"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_01VD1yrRQxvXiUYcVzo1Qa1D","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0159CU3w2xxpZXrxvVYJKUsL","name":"Bash","input":{"command":"tail -20 /tmp/claude/-data-hypogenicai-workspaces-llm-linguistic-eval-62f9-gemini/tasks/b035253.output 2>/dev/null","description":"Check current progress"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1047,"cache_read_input_tokens":86860,"cache_creation":{"ephemeral_5m_input_tokens":1047,"ephemeral_1h_input_tokens":0},"output_tokens":149,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"42edcc3a-dc86-4e4e-820a-607d791d0cd2"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0159CU3w2xxpZXrxvVYJKUsL","type":"tool_result","content":"\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]\rEvaluating:  34%|███▍      | 1217/3600 [09:40<1:18:00,  1.96s/it]\rEvaluating:  34%|███▍      | 1218/3600 [09:42<1:11:35,  1.80s/it]\rEvaluating:  34%|███▍      | 1219/3600 [09:44<1:13:39,  1.86s/it]\rEvaluating:  34%|███▍      | 1220/3600 [09:45<1:06:39,  1.68s/it]\rEvaluating:  34%|███▍      | 1221/3600 [09:47<1:08:41,  1.73s/it]\rEvaluating:  34%|███▍      | 1222/3600 [09:49<1:18:09,  1.97s/it]\rEvaluating:  34%|███▍      | 1223/3600 [09:51<1:11:54,  1.82s/it]\rEvaluating:  34%|███▍      | 1224/3600 [09:52<1:11:49,  1.81s/it]\rEvaluating:  34%|███▍      | 1225/3600 [09:54<1:11:48,  1.81s/it]\rEvaluating:  34%|███▍      | 1226/3600 [09:56<1:08:02,  1.72s/it]\rEvaluating:  34%|███▍      | 1227/3600 [09:57<1:01:24,  1.55s/it]","is_error":false}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"fe21903c-55a3-44de-8792-4da9bb051ef9","tool_use_result":{"stdout":"\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]\rEvaluating:  34%|███▍      | 1217/3600 [09:40<1:18:00,  1.96s/it]\rEvaluating:  34%|███▍      | 1218/3600 [09:42<1:11:35,  1.80s/it]\rEvaluating:  34%|███▍      | 1219/3600 [09:44<1:13:39,  1.86s/it]\rEvaluating:  34%|███▍      | 1220/3600 [09:45<1:06:39,  1.68s/it]\rEvaluating:  34%|███▍      | 1221/3600 [09:47<1:08:41,  1.73s/it]\rEvaluating:  34%|███▍      | 1222/3600 [09:49<1:18:09,  1.97s/it]\rEvaluating:  34%|███▍      | 1223/3600 [09:51<1:11:54,  1.82s/it]\rEvaluating:  34%|███▍      | 1224/3600 [09:52<1:11:49,  1.81s/it]\rEvaluating:  34%|███▍      | 1225/3600 [09:54<1:11:48,  1.81s/it]\rEvaluating:  34%|███▍      | 1226/3600 [09:56<1:08:02,  1.72s/it]\rEvaluating:  34%|███▍      | 1227/3600 [09:57<1:01:24,  1.55s/it]","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_017yKHcJxJmURR9c54P5rHjV","type":"message","role":"assistant","content":[{"type":"text","text":"The evaluation is continuing with Claude Sonnet 4.5. Claude is taking longer per request (~1.5-2s per call vs ~0.5s for GPT-4o). Let me wait for the evaluation to complete. I'll use blocking mode to wait:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2923,"cache_read_input_tokens":87907,"cache_creation":{"ephemeral_5m_input_tokens":2923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"c42ba5c7-9cfb-4123-9632-d711dcba8a1a"}
{"type":"assistant","message":{"model":"claude-opus-4-5-20251101","id":"msg_017yKHcJxJmURR9c54P5rHjV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01C1YwhAxhbsKAdqaEeG9hS6","name":"TaskOutput","input":{"task_id":"b035253","block":true,"timeout":600000}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2923,"cache_read_input_tokens":87907,"cache_creation":{"ephemeral_5m_input_tokens":2923,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"},"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"3c7886ba-404b-43db-ae7f-f70c32a70f33"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01C1YwhAxhbsKAdqaEeG9hS6","type":"tool_result","content":"<retrieval_status>timeout</retrieval_status>\n\n<task_id>b035253</task_id>\n\n<task_type>local_bash</task_type>\n\n<status>running</status>\n\n<output>\n2026-01-18 22:05:48,144 - INFO - ============================================================\n2026-01-18 22:05:48,144 - INFO - Multilingual LLM Evaluation Starting\n2026-01-18 22:05:48,144 - INFO - Seed: 42\n2026-01-18 22:05:48,144 - INFO - Languages: ['en', 'zh', 'es', 'fr', 'ar', 'ko', 'vi', 'id', 'bn', 'te', 'sw', 'ta']\n2026-01-18 22:05:48,144 - INFO - Models: ['gpt-4o', 'claude-sonnet-4.5', 'gemini-3-flash']\n2026-01-18 22:05:48,145 - INFO - Sample size per language: 100\n2026-01-18 22:05:48,145 - INFO - ============================================================\n2026-01-18 22:05:48,145 - INFO - Loading datasets...\n2026-01-18 22:05:48,145 - INFO - Loading MuBench MMLU for language: en (config: MMLUDataset_en_template_en)\n2026-01-18 22:05:48,287 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:48,294 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:48,338 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:48,424 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:49,399 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/revision/b59e353548c14c68701ec8eb56137aa7a8678d46 \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:49,546 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:50,126 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,539 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/tree/b59e353548c14c68701ec8eb56137aa7a8678d46/SNLIDataset?recursive=false&expand=false \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,684 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:50,840 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/tree/b59e353548c14c68701ec8eb56137aa7a8678d46/MMLUDataset?recursive=false&expand=false \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,869 - INFO - Loaded 100 questions for en (from 12338 total)\n2026-01-18 22:05:50,870 - INFO - Loading MuBench MMLU for language: zh (config: MMLUDataset_en_template_zh)\n2026-01-18 22:05:51,003 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:51,011 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:51,054 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:51,082 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,020 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,550 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:52,794 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,814 - INFO - Loaded 100 questions for zh (from 12338 total)\n2026-01-18 22:05:52,815 - INFO - Loading MuBench MMLU for language: es (config: MMLUDataset_en_template_es)\n2026-01-18 22:05:52,852 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:52,860 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:52,898 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,925 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:53,865 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,354 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:54,596 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,617 - INFO - Loaded 100 questions for es (from 12338 total)\n2026-01-18 22:05:54,618 - INFO - Loading MuBench MMLU for language: fr (config: MMLUDataset_en_template_fr)\n2026-01-18 22:05:54,658 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:54,664 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:54,715 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,743 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:55,698 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,218 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:56,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,482 - INFO - Loaded 100 questions for fr (from 12338 total)\n2026-01-18 22:05:56,483 - INFO - Loading MuBench MMLU for language: ar (config: MMLUDataset_en_template_ar)\n2026-01-18 22:05:56,521 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:56,529 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:56,567 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,596 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:57,579 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,104 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:58,362 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,382 - INFO - Loaded 100 questions for ar (from 12338 total)\n2026-01-18 22:05:58,383 - INFO - Loading MuBench MMLU for language: ko (config: MMLUDataset_en_template_ko)\n2026-01-18 22:05:58,422 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:58,429 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:58,466 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,494 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:59,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:59,988 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:00,295 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:00,320 - INFO - Loaded 100 questions for ko (from 12338 total)\n2026-01-18 22:06:00,320 - INFO - Loading MuBench MMLU for language: vi (config: MMLUDataset_en_template_vi)\n2026-01-18 22:06:00,362 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:00,369 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:00,404 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:00,433 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:01,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:02,027 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:02,373 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-01-18 22:06:02,374 - WARNING - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-01-18 22:06:02,398 - INFO - Loaded 100 questions for vi (from 12338 total)\n2026-01-18 22:06:02,398 - INFO - Loading MuBench MMLU for language: id (config: MMLUDataset_en_template_id)\n2026-01-18 22:06:02,438 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:02,445 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:02,482 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:02,509 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:03,562 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,073 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:04,417 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,439 - INFO - Loaded 100 questions for id (from 12338 total)\n2026-01-18 22:06:04,440 - INFO - Loading MuBench MMLU for language: bn (config: MMLUDataset_en_template_bn)\n2026-01-18 22:06:04,476 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:04,483 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:04,520 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,550 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:05,588 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,073 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:06,258 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,282 - INFO - Loaded 100 questions for bn (from 12338 total)\n2026-01-18 22:06:06,283 - INFO - Loading MuBench MMLU for language: te (config: MMLUDataset_en_template_te)\n2026-01-18 22:06:06,325 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:06,333 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:06,374 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,402 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:07,586 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,130 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:08,309 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,331 - INFO - Loaded 100 questions for te (from 12338 total)\n2026-01-18 22:06:08,332 - INFO - Loading MuBench MMLU for language: sw (config: MMLUDataset_en_template_sw)\n2026-01-18 22:06:08,370 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:08,378 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:08,417 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,445 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:09,476 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,005 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:10,319 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,341 - INFO - Loaded 100 questions for sw (from 12338 total)\n2026-01-18 22:06:10,342 - INFO - Loading MuBench MMLU for language: ta (config: MMLUDataset_en_template_ta)\n2026-01-18 22:06:10,379 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:10,387 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:10,426 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,454 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:11,452 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:11,958 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:12,249 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:12,271 - INFO - Loaded 100 questions for ta (from 12338 total)\n\rEvaluating:   0%|          | 0/3600 [00:00<?, ?it/s]2026-01-18 22:06:12,273 - INFO - \nEvaluating model: gpt-4o\n2026-01-18 22:06:12,273 - INFO -   Language: en\n2026-01-18 22:06:12,761 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 1/3600 [00:00<29:41,  2.02it/s]2026-01-18 22:06:13,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 2/3600 [00:00<26:21,  2.27it/s]2026-01-18 22:06:13,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 3/3600 [00:01<27:27,  2.18it/s]2026-01-18 22:06:13,984 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 4/3600 [00:01<24:40,  2.43it/s]2026-01-18 22:06:14,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 5/3600 [00:02<24:17,  2.47it/s]2026-01-18 22:06:14,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 6/3600 [00:02<24:18,  2.46it/s]2026-01-18 22:06:15,199 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 7/3600 [00:02<24:22,  2.46it/s]2026-01-18 22:06:15,627 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 8/3600 [00:03<24:45,  2.42it/s]2026-01-18 22:06:16,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 9/3600 [00:03<24:08,  2.48it/s]2026-01-18 22:06:16,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 10/3600 [00:04<23:20,  2.56it/s]2026-01-18 22:06:16,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 11/3600 [00:04<23:09,  2.58it/s]2026-01-18 22:06:17,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 12/3600 [00:04<23:49,  2.51it/s]2026-01-18 22:06:17,653 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 13/3600 [00:05<25:22,  2.36it/s]2026-01-18 22:06:18,097 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 14/3600 [00:05<25:39,  2.33it/s]2026-01-18 22:06:18,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 15/3600 [00:06<25:36,  2.33it/s]2026-01-18 22:06:18,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 16/3600 [00:06<25:24,  2.35it/s]2026-01-18 22:06:19,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 17/3600 [00:07<26:31,  2.25it/s]2026-01-18 22:06:19,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 18/3600 [00:07<25:02,  2.38it/s]2026-01-18 22:06:20,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 19/3600 [00:07<25:01,  2.38it/s]2026-01-18 22:06:20,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 20/3600 [00:08<24:03,  2.48it/s]2026-01-18 22:06:20,984 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 21/3600 [00:08<24:08,  2.47it/s]2026-01-18 22:06:21,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 22/3600 [00:09<24:29,  2.43it/s]2026-01-18 22:06:21,914 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 23/3600 [00:09<26:10,  2.28it/s]2026-01-18 22:06:22,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 24/3600 [00:10<25:11,  2.37it/s]2026-01-18 22:06:22,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 25/3600 [00:10<23:35,  2.53it/s]2026-01-18 22:06:23,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 26/3600 [00:11<28:20,  2.10it/s]2026-01-18 22:06:23,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 27/3600 [00:11<27:32,  2.16it/s]2026-01-18 22:06:24,214 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 28/3600 [00:11<27:59,  2.13it/s]2026-01-18 22:06:24,678 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 29/3600 [00:12<27:56,  2.13it/s]2026-01-18 22:06:25,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 30/3600 [00:12<26:28,  2.25it/s]2026-01-18 22:06:25,466 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 31/3600 [00:13<25:40,  2.32it/s]2026-01-18 22:06:25,945 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 32/3600 [00:13<26:26,  2.25it/s]2026-01-18 22:06:26,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 33/3600 [00:14<25:22,  2.34it/s]2026-01-18 22:06:26,680 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 34/3600 [00:14<24:00,  2.47it/s]2026-01-18 22:06:27,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 35/3600 [00:14<26:59,  2.20it/s]2026-01-18 22:06:27,699 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 36/3600 [00:15<26:50,  2.21it/s]2026-01-18 22:06:28,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 37/3600 [00:15<27:39,  2.15it/s]2026-01-18 22:06:28,619 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 38/3600 [00:16<26:53,  2.21it/s]2026-01-18 22:06:29,014 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 39/3600 [00:16<25:58,  2.28it/s]2026-01-18 22:06:29,493 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 40/3600 [00:17<26:43,  2.22it/s]2026-01-18 22:06:29,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 41/3600 [00:17<25:38,  2.31it/s]2026-01-18 22:06:30,288 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 42/3600 [00:18<25:03,  2.37it/s]2026-01-18 22:06:30,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 43/3600 [00:18<25:34,  2.32it/s]2026-01-18 22:06:31,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 44/3600 [00:18<26:14,  2.26it/s]2026-01-18 22:06:31,635 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 45/3600 [00:19<25:58,  2.28it/s]2026-01-18 22:06:32,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 46/3600 [00:19<25:22,  2.33it/s]2026-01-18 22:06:32,459 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 47/3600 [00:20<25:04,  2.36it/s]2026-01-18 22:06:32,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 48/3600 [00:20<25:03,  2.36it/s]2026-01-18 22:06:33,371 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 49/3600 [00:21<26:16,  2.25it/s]2026-01-18 22:06:33,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 50/3600 [00:21<25:02,  2.36it/s]2026-01-18 22:06:34,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 51/3600 [00:21<25:05,  2.36it/s]2026-01-18 22:06:34,536 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 52/3600 [00:22<23:56,  2.47it/s]2026-01-18 22:06:35,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 53/3600 [00:22<26:00,  2.27it/s]2026-01-18 22:06:35,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 54/3600 [00:23<25:15,  2.34it/s]2026-01-18 22:06:35,892 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 55/3600 [00:23<25:27,  2.32it/s]2026-01-18 22:06:36,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 56/3600 [00:24<26:30,  2.23it/s]2026-01-18 22:06:36,768 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 57/3600 [00:24<25:24,  2.32it/s]2026-01-18 22:06:37,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 58/3600 [00:24<26:17,  2.24it/s]2026-01-18 22:06:37,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 59/3600 [00:25<27:41,  2.13it/s]2026-01-18 22:06:38,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 60/3600 [00:25<27:23,  2.15it/s]2026-01-18 22:06:38,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 61/3600 [00:26<25:49,  2.28it/s]2026-01-18 22:06:38,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 62/3600 [00:26<24:52,  2.37it/s]2026-01-18 22:06:39,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 63/3600 [00:27<25:13,  2.34it/s]2026-01-18 22:06:39,865 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 64/3600 [00:27<25:17,  2.33it/s]2026-01-18 22:06:40,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 65/3600 [00:27<24:37,  2.39it/s]2026-01-18 22:06:40,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 66/3600 [00:28<23:55,  2.46it/s]2026-01-18 22:06:41,010 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 67/3600 [00:28<23:32,  2.50it/s]2026-01-18 22:06:41,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 68/3600 [00:29<24:32,  2.40it/s]2026-01-18 22:06:41,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 69/3600 [00:29<25:51,  2.28it/s]2026-01-18 22:06:42,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 70/3600 [00:30<25:37,  2.30it/s]2026-01-18 22:06:42,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 71/3600 [00:30<25:59,  2.26it/s]2026-01-18 22:06:43,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 72/3600 [00:31<27:24,  2.15it/s]2026-01-18 22:06:43,817 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 73/3600 [00:31<26:59,  2.18it/s]2026-01-18 22:06:44,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 74/3600 [00:31<26:12,  2.24it/s]2026-01-18 22:06:44,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 75/3600 [00:32<25:28,  2.31it/s]2026-01-18 22:06:45,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 76/3600 [00:32<24:37,  2.38it/s]2026-01-18 22:06:45,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 77/3600 [00:33<27:03,  2.17it/s]2026-01-18 22:06:45,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 78/3600 [00:33<25:39,  2.29it/s]2026-01-18 22:06:46,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 79/3600 [00:34<24:23,  2.41it/s]2026-01-18 22:06:46,716 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 80/3600 [00:34<23:52,  2.46it/s]2026-01-18 22:06:47,105 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 81/3600 [00:34<23:35,  2.49it/s]2026-01-18 22:06:47,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 82/3600 [00:35<23:05,  2.54it/s]2026-01-18 22:06:47,834 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 83/3600 [00:35<22:25,  2.61it/s]2026-01-18 22:06:48,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 84/3600 [00:35<22:29,  2.61it/s]2026-01-18 22:06:48,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 85/3600 [00:36<23:53,  2.45it/s]2026-01-18 22:06:49,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 86/3600 [00:36<26:11,  2.24it/s]2026-01-18 22:06:49,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 87/3600 [00:37<25:49,  2.27it/s]2026-01-18 22:06:50,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 88/3600 [00:37<25:40,  2.28it/s]2026-01-18 22:06:50,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 89/3600 [00:38<25:35,  2.29it/s]2026-01-18 22:06:50,903 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▎         | 90/3600 [00:38<24:44,  2.36it/s]2026-01-18 22:06:51,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 91/3600 [00:39<23:41,  2.47it/s]2026-01-18 22:06:51,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 92/3600 [00:39<24:36,  2.38it/s]2026-01-18 22:06:52,137 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 93/3600 [00:39<24:21,  2.40it/s]2026-01-18 22:06:52,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 94/3600 [00:40<23:33,  2.48it/s]2026-01-18 22:06:52,968 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 95/3600 [00:40<24:33,  2.38it/s]2026-01-18 22:06:53,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 96/3600 [00:41<24:51,  2.35it/s]2026-01-18 22:06:53,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 97/3600 [00:41<25:43,  2.27it/s]2026-01-18 22:06:54,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 98/3600 [00:42<25:03,  2.33it/s]2026-01-18 22:06:54,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 99/3600 [00:42<25:13,  2.31it/s]2026-01-18 22:06:55,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 100/3600 [00:43<27:24,  2.13it/s]2026-01-18 22:06:55,389 - INFO -     Accuracy: 86.00% (86/100)\n2026-01-18 22:06:55,389 - INFO -   Language: zh\n2026-01-18 22:06:55,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 101/3600 [00:43<26:40,  2.19it/s]2026-01-18 22:06:56,161 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 102/3600 [00:43<26:30,  2.20it/s]2026-01-18 22:06:56,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 103/3600 [00:44<27:54,  2.09it/s]2026-01-18 22:06:57,169 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 104/3600 [00:44<27:51,  2.09it/s]2026-01-18 22:06:57,536 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 105/3600 [00:45<25:53,  2.25it/s]2026-01-18 22:06:57,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 106/3600 [00:45<25:49,  2.25it/s]2026-01-18 22:06:58,417 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 107/3600 [00:46<25:45,  2.26it/s]2026-01-18 22:06:58,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 108/3600 [00:46<24:05,  2.42it/s]2026-01-18 22:06:59,200 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 109/3600 [00:46<24:34,  2.37it/s]2026-01-18 22:06:59,635 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 110/3600 [00:47<24:54,  2.34it/s]2026-01-18 22:07:00,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 111/3600 [00:47<25:55,  2.24it/s]2026-01-18 22:07:00,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 112/3600 [00:48<24:49,  2.34it/s]2026-01-18 22:07:00,931 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 113/3600 [00:48<24:36,  2.36it/s]2026-01-18 22:07:01,295 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 114/3600 [00:49<23:33,  2.47it/s]2026-01-18 22:07:01,711 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 115/3600 [00:49<23:47,  2.44it/s]2026-01-18 22:07:02,136 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 116/3600 [00:49<24:00,  2.42it/s]2026-01-18 22:07:02,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 117/3600 [00:50<24:33,  2.36it/s]2026-01-18 22:07:02,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 118/3600 [00:50<23:36,  2.46it/s]2026-01-18 22:07:03,356 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 119/3600 [00:51<23:29,  2.47it/s]2026-01-18 22:07:03,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 120/3600 [00:51<24:34,  2.36it/s]2026-01-18 22:07:04,203 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 121/3600 [00:51<23:52,  2.43it/s]2026-01-18 22:07:04,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 122/3600 [00:52<23:26,  2.47it/s]2026-01-18 22:07:04,981 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 123/3600 [00:52<23:10,  2.50it/s]2026-01-18 22:07:05,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 124/3600 [00:53<25:09,  2.30it/s]2026-01-18 22:07:05,973 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 125/3600 [00:53<26:15,  2.21it/s]2026-01-18 22:07:06,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 126/3600 [00:54<24:47,  2.34it/s]2026-01-18 22:07:06,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 127/3600 [00:54<24:39,  2.35it/s]2026-01-18 22:07:07,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 128/3600 [00:54<24:49,  2.33it/s]2026-01-18 22:07:07,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 129/3600 [00:55<24:44,  2.34it/s]2026-01-18 22:07:08,103 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 130/3600 [00:55<25:13,  2.29it/s]2026-01-18 22:07:08,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 131/3600 [00:56<24:54,  2.32it/s]2026-01-18 22:07:08,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 132/3600 [00:56<23:01,  2.51it/s]2026-01-18 22:07:09,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 133/3600 [00:56<23:14,  2.49it/s]2026-01-18 22:07:10,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 134/3600 [00:57<31:06,  1.86it/s]2026-01-18 22:07:10,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 135/3600 [00:58<30:56,  1.87it/s]2026-01-18 22:07:11,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 136/3600 [00:58<28:08,  2.05it/s]2026-01-18 22:07:11,424 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 137/3600 [00:59<26:51,  2.15it/s]2026-01-18 22:07:11,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 138/3600 [00:59<25:31,  2.26it/s]2026-01-18 22:07:12,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 139/3600 [00:59<24:55,  2.31it/s]2026-01-18 22:07:12,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 140/3600 [01:00<24:25,  2.36it/s]2026-01-18 22:07:13,090 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 141/3600 [01:00<25:05,  2.30it/s]2026-01-18 22:07:13,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 142/3600 [01:01<24:21,  2.37it/s]2026-01-18 22:07:13,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 143/3600 [01:01<25:41,  2.24it/s]2026-01-18 22:07:14,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 144/3600 [01:02<25:59,  2.22it/s]2026-01-18 22:07:14,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 145/3600 [01:02<26:21,  2.18it/s]2026-01-18 22:07:15,351 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 146/3600 [01:03<25:53,  2.22it/s]2026-01-18 22:07:15,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 147/3600 [01:03<24:51,  2.31it/s]2026-01-18 22:07:16,236 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 148/3600 [01:03<25:57,  2.22it/s]2026-01-18 22:07:16,610 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 149/3600 [01:04<24:32,  2.34it/s]2026-01-18 22:07:16,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 150/3600 [01:04<23:29,  2.45it/s]2026-01-18 22:07:17,553 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 151/3600 [01:05<26:26,  2.17it/s]2026-01-18 22:07:17,939 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 152/3600 [01:05<25:08,  2.29it/s]2026-01-18 22:07:18,359 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 153/3600 [01:06<24:47,  2.32it/s]2026-01-18 22:07:18,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 154/3600 [01:06<25:24,  2.26it/s]2026-01-18 22:07:19,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 155/3600 [01:07<27:06,  2.12it/s]2026-01-18 22:07:19,773 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 156/3600 [01:07<25:59,  2.21it/s]2026-01-18 22:07:20,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 157/3600 [01:07<26:18,  2.18it/s]2026-01-18 22:07:20,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 158/3600 [01:08<25:34,  2.24it/s]2026-01-18 22:07:21,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 159/3600 [01:08<24:21,  2.35it/s]2026-01-18 22:07:21,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 160/3600 [01:09<23:57,  2.39it/s]2026-01-18 22:07:21,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 161/3600 [01:09<23:36,  2.43it/s]2026-01-18 22:07:22,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 162/3600 [01:10<25:52,  2.21it/s]2026-01-18 22:07:22,846 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 163/3600 [01:10<26:09,  2.19it/s]2026-01-18 22:07:23,243 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 164/3600 [01:10<25:04,  2.28it/s]2026-01-18 22:07:23,709 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 165/3600 [01:11<25:33,  2.24it/s]2026-01-18 22:07:24,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 166/3600 [01:11<23:53,  2.40it/s]2026-01-18 22:07:24,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 167/3600 [01:12<23:57,  2.39it/s]2026-01-18 22:07:24,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 168/3600 [01:12<22:56,  2.49it/s]2026-01-18 22:07:25,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 169/3600 [01:13<24:15,  2.36it/s]2026-01-18 22:07:25,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 170/3600 [01:13<24:40,  2.32it/s]2026-01-18 22:07:26,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 171/3600 [01:13<24:14,  2.36it/s]2026-01-18 22:07:26,644 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 172/3600 [01:14<25:05,  2.28it/s]2026-01-18 22:07:27,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 173/3600 [01:14<23:50,  2.40it/s]2026-01-18 22:07:27,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 174/3600 [01:15<24:20,  2.35it/s]2026-01-18 22:07:27,929 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 175/3600 [01:15<25:08,  2.27it/s]2026-01-18 22:07:28,397 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 176/3600 [01:16<25:31,  2.24it/s]2026-01-18 22:07:28,780 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 177/3600 [01:16<24:21,  2.34it/s]2026-01-18 22:07:29,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 178/3600 [01:16<25:02,  2.28it/s]2026-01-18 22:07:29,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 179/3600 [01:17<25:39,  2.22it/s]2026-01-18 22:07:30,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 180/3600 [01:17<24:50,  2.29it/s]2026-01-18 22:07:30,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 181/3600 [01:18<23:53,  2.38it/s]2026-01-18 22:07:30,886 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 182/3600 [01:18<23:12,  2.45it/s]2026-01-18 22:07:31,298 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 183/3600 [01:19<23:15,  2.45it/s]2026-01-18 22:07:31,799 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 184/3600 [01:19<24:52,  2.29it/s]2026-01-18 22:07:32,267 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 185/3600 [01:20<25:35,  2.22it/s]2026-01-18 22:07:32,907 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 186/3600 [01:20<28:35,  1.99it/s]2026-01-18 22:07:33,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 187/3600 [01:21<26:58,  2.11it/s]2026-01-18 22:07:33,832 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 188/3600 [01:21<27:45,  2.05it/s]2026-01-18 22:07:34,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 189/3600 [01:21<26:19,  2.16it/s]2026-01-18 22:07:34,690 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 190/3600 [01:22<26:07,  2.18it/s]2026-01-18 22:07:35,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 191/3600 [01:22<27:17,  2.08it/s]2026-01-18 22:07:35,640 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 192/3600 [01:23<26:17,  2.16it/s]2026-01-18 22:07:36,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 193/3600 [01:23<24:50,  2.29it/s]2026-01-18 22:07:36,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 194/3600 [01:24<24:32,  2.31it/s]2026-01-18 22:07:36,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 195/3600 [01:24<23:26,  2.42it/s]2026-01-18 22:07:37,232 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 196/3600 [01:24<23:36,  2.40it/s]2026-01-18 22:07:37,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 197/3600 [01:25<25:55,  2.19it/s]2026-01-18 22:07:38,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 198/3600 [01:25<26:13,  2.16it/s]2026-01-18 22:07:38,707 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 199/3600 [01:26<26:00,  2.18it/s]2026-01-18 22:07:39,141 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 200/3600 [01:26<25:30,  2.22it/s]2026-01-18 22:07:39,246 - INFO -     Accuracy: 75.00% (75/100)\n2026-01-18 22:07:39,246 - INFO -   Language: es\n2026-01-18 22:07:39,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 201/3600 [01:27<25:48,  2.19it/s]2026-01-18 22:07:40,049 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 202/3600 [01:27<25:32,  2.22it/s]2026-01-18 22:07:40,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 203/3600 [01:28<24:11,  2.34it/s]2026-01-18 22:07:40,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 204/3600 [01:28<23:47,  2.38it/s]2026-01-18 22:07:41,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 205/3600 [01:29<24:22,  2.32it/s]2026-01-18 22:07:41,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 206/3600 [01:29<26:02,  2.17it/s]2026-01-18 22:07:42,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 207/3600 [01:30<27:16,  2.07it/s]2026-01-18 22:07:42,800 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 208/3600 [01:30<26:55,  2.10it/s]2026-01-18 22:07:43,188 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 209/3600 [01:30<25:22,  2.23it/s]2026-01-18 22:07:43,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 210/3600 [01:31<24:20,  2.32it/s]2026-01-18 22:07:43,975 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 211/3600 [01:31<23:46,  2.38it/s]2026-01-18 22:07:44,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 212/3600 [01:32<25:13,  2.24it/s]2026-01-18 22:07:44,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 213/3600 [01:32<23:59,  2.35it/s]2026-01-18 22:07:45,313 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 214/3600 [01:33<24:29,  2.30it/s]2026-01-18 22:07:45,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 215/3600 [01:33<23:36,  2.39it/s]2026-01-18 22:07:46,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 216/3600 [01:33<23:25,  2.41it/s]2026-01-18 22:07:46,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 217/3600 [01:34<24:29,  2.30it/s]2026-01-18 22:07:46,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 218/3600 [01:34<23:08,  2.44it/s]2026-01-18 22:07:47,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 219/3600 [01:35<23:01,  2.45it/s]2026-01-18 22:07:47,759 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 220/3600 [01:35<23:13,  2.43it/s]2026-01-18 22:07:48,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 221/3600 [01:36<25:05,  2.24it/s]2026-01-18 22:07:48,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 222/3600 [01:36<23:29,  2.40it/s]2026-01-18 22:07:49,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 223/3600 [01:36<23:31,  2.39it/s]2026-01-18 22:07:49,554 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 224/3600 [01:37<24:57,  2.25it/s]2026-01-18 22:07:49,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 225/3600 [01:37<24:00,  2.34it/s]2026-01-18 22:07:50,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 226/3600 [01:38<23:49,  2.36it/s]2026-01-18 22:07:50,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 227/3600 [01:38<24:39,  2.28it/s]2026-01-18 22:07:51,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 228/3600 [01:38<23:47,  2.36it/s]2026-01-18 22:07:51,718 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 229/3600 [01:39<25:01,  2.24it/s]2026-01-18 22:07:52,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 230/3600 [01:39<23:57,  2.34it/s]2026-01-18 22:07:52,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 231/3600 [01:40<25:10,  2.23it/s]2026-01-18 22:07:52,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 232/3600 [01:40<24:03,  2.33it/s]2026-01-18 22:07:53,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 233/3600 [01:41<23:25,  2.40it/s]2026-01-18 22:07:53,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 234/3600 [01:41<22:59,  2.44it/s]2026-01-18 22:07:54,133 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 235/3600 [01:41<22:19,  2.51it/s]2026-01-18 22:07:54,555 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 236/3600 [01:42<22:36,  2.48it/s]2026-01-18 22:07:54,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 237/3600 [01:42<23:12,  2.42it/s]2026-01-18 22:07:55,366 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 238/3600 [01:43<22:33,  2.48it/s]2026-01-18 22:07:55,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 239/3600 [01:43<23:26,  2.39it/s]2026-01-18 22:07:56,233 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 240/3600 [01:43<23:17,  2.40it/s]2026-01-18 22:07:56,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 241/3600 [01:44<23:10,  2.42it/s]2026-01-18 22:07:57,130 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 242/3600 [01:44<24:29,  2.28it/s]2026-01-18 22:07:57,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 243/3600 [01:45<23:48,  2.35it/s]2026-01-18 22:07:57,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 244/3600 [01:45<23:09,  2.41it/s]2026-01-18 22:07:58,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 245/3600 [01:46<24:44,  2.26it/s]2026-01-18 22:07:58,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 246/3600 [01:46<26:00,  2.15it/s]2026-01-18 22:07:59,542 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 247/3600 [01:47<28:11,  1.98it/s]2026-01-18 22:07:59,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 248/3600 [01:47<26:22,  2.12it/s]2026-01-18 22:08:00,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 249/3600 [01:48<25:21,  2.20it/s]2026-01-18 22:08:00,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 250/3600 [01:48<25:42,  2.17it/s]2026-01-18 22:08:01,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 251/3600 [01:48<25:21,  2.20it/s]2026-01-18 22:08:01,702 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 252/3600 [01:49<25:08,  2.22it/s]2026-01-18 22:08:02,194 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 253/3600 [01:49<25:47,  2.16it/s]2026-01-18 22:08:02,695 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 254/3600 [01:50<26:22,  2.11it/s]2026-01-18 22:08:03,130 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 255/3600 [01:50<25:43,  2.17it/s]2026-01-18 22:08:03,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 256/3600 [01:51<24:19,  2.29it/s]2026-01-18 22:08:04,010 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 257/3600 [01:51<25:26,  2.19it/s]2026-01-18 22:08:04,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 258/3600 [01:52<25:10,  2.21it/s]2026-01-18 22:08:05,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 259/3600 [01:52<26:44,  2.08it/s]2026-01-18 22:08:05,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 260/3600 [01:53<26:21,  2.11it/s]2026-01-18 22:08:05,888 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 261/3600 [01:53<25:42,  2.16it/s]2026-01-18 22:08:06,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 262/3600 [01:54<25:57,  2.14it/s]2026-01-18 22:08:06,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 263/3600 [01:54<25:38,  2.17it/s]2026-01-18 22:08:07,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 264/3600 [01:55<25:44,  2.16it/s]2026-01-18 22:08:07,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 265/3600 [01:55<25:16,  2.20it/s]2026-01-18 22:08:08,145 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 266/3600 [01:55<24:45,  2.24it/s]2026-01-18 22:08:08,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 267/3600 [01:56<24:59,  2.22it/s]2026-01-18 22:08:08,983 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 268/3600 [01:56<23:55,  2.32it/s]2026-01-18 22:08:09,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 269/3600 [01:57<23:42,  2.34it/s]2026-01-18 22:08:10,167 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 270/3600 [01:57<29:09,  1.90it/s]2026-01-18 22:08:10,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 271/3600 [01:58<26:32,  2.09it/s]2026-01-18 22:08:11,005 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 272/3600 [01:58<26:32,  2.09it/s]2026-01-18 22:08:11,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 273/3600 [01:59<24:58,  2.22it/s]2026-01-18 22:08:11,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 274/3600 [01:59<25:49,  2.15it/s]2026-01-18 22:08:12,336 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 275/3600 [02:00<25:19,  2.19it/s]2026-01-18 22:08:12,837 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 276/3600 [02:00<26:03,  2.13it/s]2026-01-18 22:08:13,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 277/3600 [02:01<25:50,  2.14it/s]2026-01-18 22:08:13,781 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 278/3600 [02:01<26:11,  2.11it/s]2026-01-18 22:08:14,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 279/3600 [02:02<26:25,  2.09it/s]2026-01-18 22:08:14,674 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 280/3600 [02:02<25:12,  2.20it/s]2026-01-18 22:08:15,099 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 281/3600 [02:02<24:39,  2.24it/s]2026-01-18 22:08:15,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 282/3600 [02:03<24:19,  2.27it/s]2026-01-18 22:08:15,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 283/3600 [02:03<23:52,  2.32it/s]2026-01-18 22:08:16,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 284/3600 [02:04<23:44,  2.33it/s]2026-01-18 22:08:16,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 285/3600 [02:04<22:38,  2.44it/s]2026-01-18 22:08:17,103 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 286/3600 [02:04<22:04,  2.50it/s]2026-01-18 22:08:17,573 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 287/3600 [02:05<23:19,  2.37it/s]2026-01-18 22:08:18,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 288/3600 [02:05<27:10,  2.03it/s]2026-01-18 22:08:18,628 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 289/3600 [02:06<25:31,  2.16it/s]2026-01-18 22:08:19,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 290/3600 [02:06<27:16,  2.02it/s]2026-01-18 22:08:19,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 291/3600 [02:07<26:33,  2.08it/s]2026-01-18 22:08:20,027 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 292/3600 [02:07<24:50,  2.22it/s]2026-01-18 22:08:20,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 293/3600 [02:08<25:09,  2.19it/s]2026-01-18 22:08:20,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 294/3600 [02:08<25:40,  2.15it/s]2026-01-18 22:08:21,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 295/3600 [02:09<26:32,  2.07it/s]2026-01-18 22:08:22,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 296/3600 [02:09<28:01,  1.97it/s]2026-01-18 22:08:22,498 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 297/3600 [02:10<26:37,  2.07it/s]2026-01-18 22:08:22,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 298/3600 [02:10<25:10,  2.19it/s]2026-01-18 22:08:23,434 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 299/3600 [02:11<26:43,  2.06it/s]2026-01-18 22:08:23,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 300/3600 [02:11<25:04,  2.19it/s]2026-01-18 22:08:23,940 - INFO -     Accuracy: 82.00% (82/100)\n2026-01-18 22:08:23,940 - INFO -   Language: fr\n2026-01-18 22:08:24,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 301/3600 [02:11<23:50,  2.31it/s]2026-01-18 22:08:24,625 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 302/3600 [02:12<23:27,  2.34it/s]2026-01-18 22:08:25,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 303/3600 [02:12<22:39,  2.43it/s]2026-01-18 22:08:25,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 304/3600 [02:13<23:12,  2.37it/s]2026-01-18 22:08:26,025 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 305/3600 [02:13<25:48,  2.13it/s]2026-01-18 22:08:26,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 306/3600 [02:14<26:29,  2.07it/s]2026-01-18 22:08:26,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 307/3600 [02:14<25:46,  2.13it/s]2026-01-18 22:08:27,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 308/3600 [02:15<23:58,  2.29it/s]2026-01-18 22:08:27,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 309/3600 [02:15<25:21,  2.16it/s]2026-01-18 22:08:28,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 310/3600 [02:16<28:40,  1.91it/s]2026-01-18 22:08:28,901 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 311/3600 [02:16<26:11,  2.09it/s]2026-01-18 22:08:29,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 312/3600 [02:17<25:08,  2.18it/s]2026-01-18 22:08:29,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 313/3600 [02:17<24:15,  2.26it/s]2026-01-18 22:08:30,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 314/3600 [02:17<24:09,  2.27it/s]2026-01-18 22:08:30,681 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 315/3600 [02:18<25:26,  2.15it/s]2026-01-18 22:08:31,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 316/3600 [02:19<30:27,  1.80it/s]2026-01-18 22:08:31,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 317/3600 [02:19<28:04,  1.95it/s]2026-01-18 22:08:32,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 318/3600 [02:20<29:27,  1.86it/s]2026-01-18 22:08:32,856 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 319/3600 [02:20<27:06,  2.02it/s]2026-01-18 22:08:33,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 320/3600 [02:21<26:53,  2.03it/s]2026-01-18 22:08:33,762 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 321/3600 [02:21<25:46,  2.12it/s]2026-01-18 22:08:34,156 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 322/3600 [02:21<24:31,  2.23it/s]2026-01-18 22:08:34,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 323/3600 [02:22<25:38,  2.13it/s]2026-01-18 22:08:35,114 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 324/3600 [02:22<25:05,  2.18it/s]2026-01-18 22:08:35,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 325/3600 [02:23<24:47,  2.20it/s]2026-01-18 22:08:35,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 326/3600 [02:23<23:27,  2.33it/s]2026-01-18 22:08:36,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 327/3600 [02:24<22:43,  2.40it/s]2026-01-18 22:08:36,732 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 328/3600 [02:24<22:45,  2.40it/s]2026-01-18 22:08:37,176 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 329/3600 [02:24<23:10,  2.35it/s]2026-01-18 22:08:37,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 330/3600 [02:25<23:56,  2.28it/s]2026-01-18 22:08:38,093 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 331/3600 [02:25<24:00,  2.27it/s]2026-01-18 22:08:38,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 332/3600 [02:26<26:01,  2.09it/s]2026-01-18 22:08:39,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 333/3600 [02:26<24:55,  2.19it/s]2026-01-18 22:08:39,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 334/3600 [02:27<24:42,  2.20it/s]2026-01-18 22:08:39,876 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 335/3600 [02:27<23:14,  2.34it/s]2026-01-18 22:08:40,283 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 336/3600 [02:28<22:56,  2.37it/s]2026-01-18 22:08:40,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 337/3600 [02:28<23:10,  2.35it/s]2026-01-18 22:08:41,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 338/3600 [02:28<24:35,  2.21it/s]2026-01-18 22:08:41,637 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 339/3600 [02:29<23:48,  2.28it/s]2026-01-18 22:08:42,080 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 340/3600 [02:29<23:49,  2.28it/s]2026-01-18 22:08:42,716 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 341/3600 [02:30<27:00,  2.01it/s]2026-01-18 22:08:43,183 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 342/3600 [02:30<26:31,  2.05it/s]2026-01-18 22:08:43,618 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 343/3600 [02:31<25:40,  2.11it/s]2026-01-18 22:08:44,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 344/3600 [02:31<25:30,  2.13it/s]2026-01-18 22:08:44,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 345/3600 [02:32<24:44,  2.19it/s]2026-01-18 22:08:45,034 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 346/3600 [02:32<25:54,  2.09it/s]2026-01-18 22:08:45,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 347/3600 [02:33<24:30,  2.21it/s]2026-01-18 22:08:45,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 348/3600 [02:33<23:51,  2.27it/s]2026-01-18 22:08:46,223 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 349/3600 [02:33<22:54,  2.37it/s]2026-01-18 22:08:46,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 350/3600 [02:34<23:23,  2.32it/s]2026-01-18 22:08:47,145 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 351/3600 [02:34<24:00,  2.26it/s]2026-01-18 22:08:47,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 352/3600 [02:35<24:13,  2.23it/s]2026-01-18 22:08:48,009 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 353/3600 [02:35<23:32,  2.30it/s]2026-01-18 22:08:48,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 354/3600 [02:36<24:35,  2.20it/s]2026-01-18 22:08:48,928 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 355/3600 [02:36<24:07,  2.24it/s]2026-01-18 22:08:49,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 356/3600 [02:37<22:46,  2.37it/s]2026-01-18 22:08:49,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 357/3600 [02:37<23:48,  2.27it/s]2026-01-18 22:08:50,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 358/3600 [02:37<23:42,  2.28it/s]2026-01-18 22:08:50,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 359/3600 [02:38<24:37,  2.19it/s]2026-01-18 22:08:51,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 360/3600 [02:38<24:05,  2.24it/s]2026-01-18 22:08:51,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 361/3600 [02:39<23:58,  2.25it/s]2026-01-18 22:08:52,113 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 362/3600 [02:39<25:28,  2.12it/s]2026-01-18 22:08:52,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 363/3600 [02:40<23:56,  2.25it/s]2026-01-18 22:08:52,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 364/3600 [02:40<24:37,  2.19it/s]2026-01-18 22:08:53,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 365/3600 [02:41<25:55,  2.08it/s]2026-01-18 22:08:53,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 366/3600 [02:41<24:41,  2.18it/s]2026-01-18 22:08:54,320 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 367/3600 [02:42<23:43,  2.27it/s]2026-01-18 22:08:54,781 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 368/3600 [02:42<24:06,  2.23it/s]2026-01-18 22:08:55,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 369/3600 [02:43<26:14,  2.05it/s]2026-01-18 22:08:55,804 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 370/3600 [02:43<25:34,  2.11it/s]2026-01-18 22:08:56,207 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 371/3600 [02:43<24:20,  2.21it/s]2026-01-18 22:08:56,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 372/3600 [02:44<25:24,  2.12it/s]2026-01-18 22:08:57,201 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 373/3600 [02:44<25:28,  2.11it/s]2026-01-18 22:08:57,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 374/3600 [02:45<25:27,  2.11it/s]2026-01-18 22:08:58,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 375/3600 [02:45<24:58,  2.15it/s]2026-01-18 22:08:58,549 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 376/3600 [02:46<24:24,  2.20it/s]2026-01-18 22:08:59,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 377/3600 [02:46<27:49,  1.93it/s]2026-01-18 22:08:59,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 378/3600 [02:47<26:57,  1.99it/s]2026-01-18 22:09:00,065 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 379/3600 [02:47<25:00,  2.15it/s]2026-01-18 22:09:00,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 380/3600 [02:48<24:44,  2.17it/s]2026-01-18 22:09:00,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 381/3600 [02:48<24:43,  2.17it/s]2026-01-18 22:09:01,449 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 382/3600 [02:49<24:56,  2.15it/s]2026-01-18 22:09:02,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 383/3600 [02:49<26:26,  2.03it/s]2026-01-18 22:09:02,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 384/3600 [02:50<25:46,  2.08it/s]2026-01-18 22:09:02,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 385/3600 [02:50<24:11,  2.21it/s]2026-01-18 22:09:03,282 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 386/3600 [02:51<24:08,  2.22it/s]2026-01-18 22:09:03,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 387/3600 [02:51<23:25,  2.29it/s]2026-01-18 22:09:04,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 388/3600 [02:51<23:38,  2.26it/s]2026-01-18 22:09:04,555 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 389/3600 [02:52<23:01,  2.32it/s]2026-01-18 22:09:05,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 390/3600 [02:52<24:05,  2.22it/s]2026-01-18 22:09:05,444 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 391/3600 [02:53<23:11,  2.31it/s]2026-01-18 22:09:05,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 392/3600 [02:53<23:15,  2.30it/s]2026-01-18 22:09:06,283 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 393/3600 [02:54<22:41,  2.36it/s]2026-01-18 22:09:06,704 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 394/3600 [02:54<22:38,  2.36it/s]2026-01-18 22:09:07,111 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 395/3600 [02:54<22:25,  2.38it/s]2026-01-18 22:09:07,572 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 396/3600 [02:55<23:02,  2.32it/s]2026-01-18 22:09:07,919 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 397/3600 [02:55<21:37,  2.47it/s]2026-01-18 22:09:08,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 398/3600 [02:56<21:31,  2.48it/s]2026-01-18 22:09:08,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 399/3600 [02:56<22:15,  2.40it/s]2026-01-18 22:09:09,178 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 400/3600 [02:56<22:11,  2.40it/s]2026-01-18 22:09:09,286 - INFO -     Accuracy: 82.00% (82/100)\n2026-01-18 22:09:09,287 - INFO -   Language: ar\n2026-01-18 22:09:09,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 401/3600 [02:57<23:00,  2.32it/s]2026-01-18 22:09:10,041 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 402/3600 [02:57<22:21,  2.38it/s]2026-01-18 22:09:10,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 403/3600 [02:58<21:50,  2.44it/s]2026-01-18 22:09:10,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 404/3600 [02:58<21:41,  2.46it/s]2026-01-18 22:09:11,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 405/3600 [02:59<22:25,  2.37it/s]2026-01-18 22:09:11,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 406/3600 [02:59<22:21,  2.38it/s]2026-01-18 22:09:12,140 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 407/3600 [02:59<22:50,  2.33it/s]2026-01-18 22:09:12,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 408/3600 [03:00<22:02,  2.41it/s]2026-01-18 22:09:13,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 409/3600 [03:01<30:39,  1.74it/s]2026-01-18 22:09:13,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 410/3600 [03:01<28:42,  1.85it/s]2026-01-18 22:09:14,362 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 411/3600 [03:02<26:50,  1.98it/s]2026-01-18 22:09:15,008 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 412/3600 [03:02<29:10,  1.82it/s]2026-01-18 22:09:15,489 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 413/3600 [03:03<27:59,  1.90it/s]2026-01-18 22:09:15,995 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 414/3600 [03:03<27:40,  1.92it/s]2026-01-18 22:09:16,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 415/3600 [03:04<26:28,  2.00it/s]2026-01-18 22:09:17,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 416/3600 [03:04<27:42,  1.92it/s]2026-01-18 22:09:17,416 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 417/3600 [03:05<25:42,  2.06it/s]2026-01-18 22:09:17,904 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 418/3600 [03:05<25:43,  2.06it/s]2026-01-18 22:09:18,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 419/3600 [03:06<25:30,  2.08it/s]2026-01-18 22:09:18,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 420/3600 [03:06<25:55,  2.04it/s]2026-01-18 22:09:19,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 421/3600 [03:07<25:21,  2.09it/s]2026-01-18 22:09:19,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 422/3600 [03:07<25:26,  2.08it/s]2026-01-18 22:09:20,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 423/3600 [03:08<26:40,  1.99it/s]2026-01-18 22:09:20,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 424/3600 [03:08<25:23,  2.08it/s]2026-01-18 22:09:21,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 425/3600 [03:09<25:16,  2.09it/s]2026-01-18 22:09:21,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 426/3600 [03:09<24:22,  2.17it/s]2026-01-18 22:09:22,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 427/3600 [03:09<25:23,  2.08it/s]2026-01-18 22:09:22,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 428/3600 [03:10<23:59,  2.20it/s]2026-01-18 22:09:23,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 429/3600 [03:10<25:18,  2.09it/s]2026-01-18 22:09:23,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 430/3600 [03:11<25:58,  2.03it/s]2026-01-18 22:09:24,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 431/3600 [03:11<25:38,  2.06it/s]2026-01-18 22:09:24,551 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 432/3600 [03:12<24:22,  2.17it/s]2026-01-18 22:09:24,988 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 433/3600 [03:12<23:58,  2.20it/s]2026-01-18 22:09:25,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 434/3600 [03:13<23:01,  2.29it/s]2026-01-18 22:09:25,841 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 435/3600 [03:13<23:23,  2.26it/s]2026-01-18 22:09:26,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 436/3600 [03:13<22:34,  2.34it/s]2026-01-18 22:09:26,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 437/3600 [03:14<22:53,  2.30it/s]2026-01-18 22:09:27,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 438/3600 [03:14<21:51,  2.41it/s]2026-01-18 22:09:27,515 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 439/3600 [03:15<22:39,  2.32it/s]2026-01-18 22:09:27,926 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 440/3600 [03:15<22:19,  2.36it/s]2026-01-18 22:09:28,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 441/3600 [03:16<22:00,  2.39it/s]2026-01-18 22:09:28,787 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 442/3600 [03:16<22:40,  2.32it/s]2026-01-18 22:09:29,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 443/3600 [03:16<22:30,  2.34it/s]2026-01-18 22:09:29,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 444/3600 [03:17<21:22,  2.46it/s]2026-01-18 22:09:29,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 445/3600 [03:17<20:52,  2.52it/s]2026-01-18 22:09:30,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 446/3600 [03:18<22:11,  2.37it/s]2026-01-18 22:09:30,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 447/3600 [03:18<23:51,  2.20it/s]2026-01-18 22:09:31,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 448/3600 [03:19<24:21,  2.16it/s]2026-01-18 22:09:31,947 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 449/3600 [03:19<25:03,  2.10it/s]2026-01-18 22:09:32,488 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▎        | 450/3600 [03:20<26:06,  2.01it/s]2026-01-18 22:09:32,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 451/3600 [03:20<24:25,  2.15it/s]2026-01-18 22:09:33,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 452/3600 [03:20<23:04,  2.27it/s]2026-01-18 22:09:33,708 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 453/3600 [03:21<23:08,  2.27it/s]2026-01-18 22:09:34,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 454/3600 [03:21<22:23,  2.34it/s]2026-01-18 22:09:34,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 455/3600 [03:22<24:02,  2.18it/s]2026-01-18 22:09:35,034 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 456/3600 [03:22<23:03,  2.27it/s]2026-01-18 22:09:35,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 457/3600 [03:23<21:40,  2.42it/s]2026-01-18 22:09:35,835 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 458/3600 [03:23<22:15,  2.35it/s]2026-01-18 22:09:36,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 459/3600 [03:23<22:14,  2.35it/s]2026-01-18 22:09:36,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 460/3600 [03:24<21:59,  2.38it/s]2026-01-18 22:09:37,107 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 461/3600 [03:24<22:13,  2.35it/s]2026-01-18 22:09:37,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 462/3600 [03:25<22:12,  2.36it/s]2026-01-18 22:09:37,954 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 463/3600 [03:25<22:10,  2.36it/s]2026-01-18 22:09:38,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 464/3600 [03:26<22:42,  2.30it/s]2026-01-18 22:09:38,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 465/3600 [03:26<24:03,  2.17it/s]2026-01-18 22:09:39,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 466/3600 [03:27<23:52,  2.19it/s]2026-01-18 22:09:39,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 467/3600 [03:27<23:07,  2.26it/s]2026-01-18 22:09:40,230 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 468/3600 [03:27<23:05,  2.26it/s]2026-01-18 22:09:40,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 469/3600 [03:28<23:03,  2.26it/s]2026-01-18 22:09:41,082 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 470/3600 [03:28<22:32,  2.31it/s]2026-01-18 22:09:41,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 471/3600 [03:29<21:58,  2.37it/s]2026-01-18 22:09:41,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 472/3600 [03:29<23:27,  2.22it/s]2026-01-18 22:09:42,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 473/3600 [03:30<22:51,  2.28it/s]2026-01-18 22:09:42,771 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 474/3600 [03:30<21:41,  2.40it/s]2026-01-18 22:09:43,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 475/3600 [03:30<21:38,  2.41it/s]2026-01-18 22:09:43,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 476/3600 [03:31<21:53,  2.38it/s]2026-01-18 22:09:44,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 477/3600 [03:31<22:01,  2.36it/s]2026-01-18 22:09:44,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 478/3600 [03:32<21:28,  2.42it/s]2026-01-18 22:09:44,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 479/3600 [03:32<20:55,  2.49it/s]2026-01-18 22:09:45,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 480/3600 [03:32<20:34,  2.53it/s]2026-01-18 22:09:45,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 481/3600 [03:33<22:09,  2.35it/s]2026-01-18 22:09:46,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 482/3600 [03:33<21:43,  2.39it/s]2026-01-18 22:09:46,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 483/3600 [03:34<21:59,  2.36it/s]2026-01-18 22:09:46,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 484/3600 [03:34<22:17,  2.33it/s]2026-01-18 22:09:47,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 485/3600 [03:35<22:59,  2.26it/s]2026-01-18 22:09:47,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 486/3600 [03:35<23:03,  2.25it/s]2026-01-18 22:09:48,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 487/3600 [03:36<22:02,  2.35it/s]2026-01-18 22:09:48,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 488/3600 [03:36<22:39,  2.29it/s]2026-01-18 22:09:49,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 489/3600 [03:36<23:15,  2.23it/s]2026-01-18 22:09:49,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 490/3600 [03:37<23:25,  2.21it/s]2026-01-18 22:09:50,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 491/3600 [03:37<22:54,  2.26it/s]2026-01-18 22:09:50,562 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 492/3600 [03:38<23:19,  2.22it/s]2026-01-18 22:09:50,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 493/3600 [03:38<22:28,  2.30it/s]2026-01-18 22:09:51,369 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 494/3600 [03:39<22:07,  2.34it/s]2026-01-18 22:09:51,794 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 495/3600 [03:39<22:07,  2.34it/s]2026-01-18 22:09:52,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 496/3600 [03:40<23:05,  2.24it/s]2026-01-18 22:09:52,718 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 497/3600 [03:40<22:52,  2.26it/s]2026-01-18 22:09:53,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 498/3600 [03:40<22:13,  2.33it/s]2026-01-18 22:09:53,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 499/3600 [03:41<22:36,  2.29it/s]2026-01-18 22:09:53,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 500/3600 [03:41<22:13,  2.32it/s]2026-01-18 22:09:54,094 - INFO -     Accuracy: 85.00% (85/100)\n2026-01-18 22:09:54,094 - INFO -   Language: ko\n2026-01-18 22:09:54,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 501/3600 [03:42<22:39,  2.28it/s]2026-01-18 22:09:54,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 502/3600 [03:42<21:32,  2.40it/s]2026-01-18 22:09:55,205 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 503/3600 [03:42<21:07,  2.44it/s]2026-01-18 22:09:55,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 504/3600 [03:43<20:59,  2.46it/s]2026-01-18 22:09:56,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 505/3600 [03:43<21:11,  2.43it/s]2026-01-18 22:09:56,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 506/3600 [03:44<22:55,  2.25it/s]2026-01-18 22:09:56,948 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 507/3600 [03:44<22:16,  2.32it/s]2026-01-18 22:09:57,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 508/3600 [03:45<23:56,  2.15it/s]2026-01-18 22:09:57,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 509/3600 [03:45<23:24,  2.20it/s]2026-01-18 22:09:58,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 510/3600 [03:46<22:42,  2.27it/s]2026-01-18 22:09:58,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 511/3600 [03:46<24:07,  2.13it/s]2026-01-18 22:09:59,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 512/3600 [03:47<23:09,  2.22it/s]2026-01-18 22:09:59,842 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 513/3600 [03:47<25:03,  2.05it/s]2026-01-18 22:10:00,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 514/3600 [03:48<24:10,  2.13it/s]2026-01-18 22:10:00,665 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 515/3600 [03:48<22:54,  2.24it/s]2026-01-18 22:10:01,134 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 516/3600 [03:48<23:15,  2.21it/s]2026-01-18 22:10:01,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 517/3600 [03:49<22:05,  2.33it/s]2026-01-18 22:10:01,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 518/3600 [03:49<22:21,  2.30it/s]2026-01-18 22:10:02,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 519/3600 [03:50<21:20,  2.41it/s]2026-01-18 22:10:02,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 520/3600 [03:50<23:13,  2.21it/s]2026-01-18 22:10:03,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 521/3600 [03:51<22:46,  2.25it/s]2026-01-18 22:10:03,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 522/3600 [03:51<22:02,  2.33it/s]2026-01-18 22:10:04,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 523/3600 [03:51<21:49,  2.35it/s]2026-01-18 22:10:04,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 524/3600 [03:52<21:37,  2.37it/s]2026-01-18 22:10:05,163 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 525/3600 [03:52<25:06,  2.04it/s]2026-01-18 22:10:05,573 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 526/3600 [03:53<23:53,  2.14it/s]2026-01-18 22:10:06,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 527/3600 [03:53<25:39,  2.00it/s]2026-01-18 22:10:06,607 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 528/3600 [03:54<24:53,  2.06it/s]2026-01-18 22:10:07,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 529/3600 [03:54<24:27,  2.09it/s]2026-01-18 22:10:07,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 530/3600 [03:55<27:13,  1.88it/s]2026-01-18 22:10:08,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 531/3600 [03:55<25:15,  2.03it/s]2026-01-18 22:10:08,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 532/3600 [03:56<23:51,  2.14it/s]2026-01-18 22:10:08,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 533/3600 [03:56<22:34,  2.26it/s]2026-01-18 22:10:09,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 534/3600 [03:57<22:14,  2.30it/s]2026-01-18 22:10:09,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 535/3600 [03:57<22:13,  2.30it/s]2026-01-18 22:10:10,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 536/3600 [03:57<21:54,  2.33it/s]2026-01-18 22:10:10,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 537/3600 [03:58<22:14,  2.29it/s]2026-01-18 22:10:11,021 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 538/3600 [03:58<21:28,  2.38it/s]2026-01-18 22:10:11,486 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 539/3600 [03:59<22:11,  2.30it/s]2026-01-18 22:10:11,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 540/3600 [03:59<21:12,  2.40it/s]2026-01-18 22:10:12,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 541/3600 [04:00<21:26,  2.38it/s]2026-01-18 22:10:12,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 542/3600 [04:00<23:11,  2.20it/s]2026-01-18 22:10:13,325 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 543/3600 [04:01<24:01,  2.12it/s]2026-01-18 22:10:13,766 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 544/3600 [04:01<23:17,  2.19it/s]2026-01-18 22:10:14,267 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 545/3600 [04:01<24:00,  2.12it/s]2026-01-18 22:10:14,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 546/3600 [04:02<23:48,  2.14it/s]2026-01-18 22:10:15,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 547/3600 [04:02<23:42,  2.15it/s]2026-01-18 22:10:15,585 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 548/3600 [04:03<22:38,  2.25it/s]2026-01-18 22:10:16,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 549/3600 [04:03<22:22,  2.27it/s]2026-01-18 22:10:16,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 550/3600 [04:04<23:23,  2.17it/s]2026-01-18 22:10:16,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 551/3600 [04:04<22:36,  2.25it/s]2026-01-18 22:10:17,345 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 552/3600 [04:05<22:19,  2.28it/s]2026-01-18 22:10:17,955 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 553/3600 [04:05<24:54,  2.04it/s]2026-01-18 22:10:20,055 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 554/3600 [04:07<49:14,  1.03it/s]2026-01-18 22:10:20,514 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 555/3600 [04:08<41:24,  1.23it/s]2026-01-18 22:10:20,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 556/3600 [04:08<34:31,  1.47it/s]2026-01-18 22:10:21,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 557/3600 [04:09<30:26,  1.67it/s]2026-01-18 22:10:21,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 558/3600 [04:09<28:43,  1.76it/s]2026-01-18 22:10:22,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 559/3600 [04:09<26:01,  1.95it/s]2026-01-18 22:10:22,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 560/3600 [04:10<24:11,  2.09it/s]2026-01-18 22:10:22,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 561/3600 [04:10<23:09,  2.19it/s]2026-01-18 22:10:23,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 562/3600 [04:11<22:29,  2.25it/s]2026-01-18 22:10:23,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 563/3600 [04:11<22:09,  2.28it/s]2026-01-18 22:10:24,246 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 564/3600 [04:11<22:18,  2.27it/s]2026-01-18 22:10:24,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 565/3600 [04:12<21:55,  2.31it/s]2026-01-18 22:10:25,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 566/3600 [04:12<23:17,  2.17it/s]2026-01-18 22:10:25,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 567/3600 [04:13<22:44,  2.22it/s]2026-01-18 22:10:26,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 568/3600 [04:13<24:17,  2.08it/s]2026-01-18 22:10:26,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 569/3600 [04:14<23:01,  2.19it/s]2026-01-18 22:10:27,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 570/3600 [04:14<24:34,  2.06it/s]2026-01-18 22:10:27,584 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 571/3600 [04:15<24:08,  2.09it/s]2026-01-18 22:10:27,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 572/3600 [04:15<22:52,  2.21it/s]2026-01-18 22:10:28,387 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 573/3600 [04:16<22:07,  2.28it/s]2026-01-18 22:10:28,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 574/3600 [04:16<21:11,  2.38it/s]2026-01-18 22:10:29,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 575/3600 [04:16<20:45,  2.43it/s]2026-01-18 22:10:29,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 576/3600 [04:17<20:25,  2.47it/s]2026-01-18 22:10:29,978 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 577/3600 [04:17<20:50,  2.42it/s]2026-01-18 22:10:30,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 578/3600 [04:18<20:24,  2.47it/s]2026-01-18 22:10:30,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 579/3600 [04:18<19:59,  2.52it/s]2026-01-18 22:10:31,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 580/3600 [04:18<19:43,  2.55it/s]2026-01-18 22:10:31,564 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 581/3600 [04:19<20:26,  2.46it/s]2026-01-18 22:10:31,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 582/3600 [04:19<20:51,  2.41it/s]2026-01-18 22:10:32,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 583/3600 [04:20<22:13,  2.26it/s]2026-01-18 22:10:33,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 584/3600 [04:20<23:17,  2.16it/s]2026-01-18 22:10:33,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 585/3600 [04:21<22:15,  2.26it/s]2026-01-18 22:10:33,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 586/3600 [04:21<22:00,  2.28it/s]2026-01-18 22:10:34,275 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 587/3600 [04:22<21:59,  2.28it/s]2026-01-18 22:10:34,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 588/3600 [04:22<22:52,  2.19it/s]2026-01-18 22:10:35,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 589/3600 [04:22<21:33,  2.33it/s]2026-01-18 22:10:35,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 590/3600 [04:23<22:33,  2.22it/s]2026-01-18 22:10:36,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 591/3600 [04:23<22:19,  2.25it/s]2026-01-18 22:10:36,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 592/3600 [04:24<21:26,  2.34it/s]2026-01-18 22:10:36,860 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 593/3600 [04:24<21:03,  2.38it/s]2026-01-18 22:10:37,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 594/3600 [04:25<21:08,  2.37it/s]2026-01-18 22:10:37,721 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 595/3600 [04:25<21:16,  2.35it/s]2026-01-18 22:10:38,183 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 596/3600 [04:25<21:52,  2.29it/s]2026-01-18 22:10:38,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 597/3600 [04:26<22:21,  2.24it/s]2026-01-18 22:10:39,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 598/3600 [04:26<21:54,  2.28it/s]2026-01-18 22:10:39,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 599/3600 [04:27<21:02,  2.38it/s]2026-01-18 22:10:40,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 600/3600 [04:27<23:17,  2.15it/s]2026-01-18 22:10:40,130 - INFO -     Accuracy: 84.00% (84/100)\n2026-01-18 22:10:40,131 - INFO -   Language: vi\n2026-01-18 22:10:40,623 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 601/3600 [04:28<25:22,  1.97it/s]2026-01-18 22:10:41,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 602/3600 [04:28<23:40,  2.11it/s]2026-01-18 22:10:41,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 603/3600 [04:29<24:55,  2.00it/s]2026-01-18 22:10:41,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 604/3600 [04:29<23:05,  2.16it/s]2026-01-18 22:10:42,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 605/3600 [04:30<22:15,  2.24it/s]2026-01-18 22:10:42,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 606/3600 [04:30<22:08,  2.25it/s]2026-01-18 22:10:43,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 607/3600 [04:31<22:32,  2.21it/s]2026-01-18 22:10:43,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 608/3600 [04:31<22:05,  2.26it/s]2026-01-18 22:10:44,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 609/3600 [04:31<21:55,  2.27it/s]2026-01-18 22:10:44,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 610/3600 [04:32<21:02,  2.37it/s]2026-01-18 22:10:45,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 611/3600 [04:32<25:37,  1.94it/s]2026-01-18 22:10:46,112 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 612/3600 [04:33<30:56,  1.61it/s]2026-01-18 22:10:46,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 613/3600 [04:34<28:29,  1.75it/s]2026-01-18 22:10:47,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 614/3600 [04:34<27:11,  1.83it/s]2026-01-18 22:10:47,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 615/3600 [04:35<25:46,  1.93it/s]2026-01-18 22:10:47,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 616/3600 [04:35<23:38,  2.10it/s]2026-01-18 22:10:48,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 617/3600 [04:36<24:00,  2.07it/s]2026-01-18 22:10:48,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 618/3600 [04:36<23:53,  2.08it/s]2026-01-18 22:10:49,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 619/3600 [04:36<21:58,  2.26it/s]2026-01-18 22:10:49,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 620/3600 [04:37<22:22,  2.22it/s]2026-01-18 22:10:50,044 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 621/3600 [04:37<21:02,  2.36it/s]2026-01-18 22:10:50,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 622/3600 [04:38<21:15,  2.33it/s]2026-01-18 22:10:51,062 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 623/3600 [04:38<23:29,  2.11it/s]2026-01-18 22:10:51,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 624/3600 [04:39<21:59,  2.25it/s]2026-01-18 22:10:51,850 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 625/3600 [04:39<21:37,  2.29it/s]2026-01-18 22:10:52,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 626/3600 [04:39<20:54,  2.37it/s]2026-01-18 22:10:52,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 627/3600 [04:40<20:36,  2.40it/s]2026-01-18 22:10:53,109 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 628/3600 [04:40<21:22,  2.32it/s]2026-01-18 22:10:53,600 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 629/3600 [04:41<22:16,  2.22it/s]2026-01-18 22:10:54,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 630/3600 [04:41<22:40,  2.18it/s]2026-01-18 22:10:54,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 631/3600 [04:42<21:22,  2.32it/s]2026-01-18 22:10:55,060 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 632/3600 [04:42<23:57,  2.06it/s]2026-01-18 22:10:55,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 633/3600 [04:43<21:53,  2.26it/s]2026-01-18 22:10:55,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 634/3600 [04:43<22:39,  2.18it/s]2026-01-18 22:10:56,326 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 635/3600 [04:44<22:11,  2.23it/s]2026-01-18 22:10:56,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 636/3600 [04:44<23:04,  2.14it/s]2026-01-18 22:10:57,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 637/3600 [04:45<23:01,  2.14it/s]2026-01-18 22:10:57,651 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 638/3600 [04:45<21:19,  2.32it/s]2026-01-18 22:10:58,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 639/3600 [04:46<24:12,  2.04it/s]2026-01-18 22:10:58,992 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 640/3600 [04:46<27:28,  1.80it/s]2026-01-18 22:10:59,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 641/3600 [04:47<25:33,  1.93it/s]2026-01-18 22:10:59,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 642/3600 [04:47<23:46,  2.07it/s]2026-01-18 22:11:00,192 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 643/3600 [04:47<22:11,  2.22it/s]2026-01-18 22:11:00,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 644/3600 [04:48<21:52,  2.25it/s]2026-01-18 22:11:01,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 645/3600 [04:48<24:19,  2.02it/s]2026-01-18 22:11:01,734 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 646/3600 [04:49<24:32,  2.01it/s]2026-01-18 22:11:02,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 647/3600 [04:49<22:44,  2.16it/s]2026-01-18 22:11:02,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 648/3600 [04:50<22:17,  2.21it/s]2026-01-18 22:11:02,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 649/3600 [04:50<21:32,  2.28it/s]2026-01-18 22:11:03,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 650/3600 [04:51<21:55,  2.24it/s]2026-01-18 22:11:03,809 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 651/3600 [04:51<21:05,  2.33it/s]2026-01-18 22:11:04,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 652/3600 [04:51<20:30,  2.40it/s]2026-01-18 22:11:04,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 653/3600 [04:52<20:00,  2.45it/s]2026-01-18 22:11:05,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 654/3600 [04:52<20:31,  2.39it/s]2026-01-18 22:11:05,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 655/3600 [04:53<19:46,  2.48it/s]2026-01-18 22:11:05,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 656/3600 [04:53<20:27,  2.40it/s]2026-01-18 22:11:06,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 657/3600 [04:54<21:15,  2.31it/s]2026-01-18 22:11:06,715 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 658/3600 [04:54<20:44,  2.36it/s]2026-01-18 22:11:07,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 659/3600 [04:55<26:12,  1.87it/s]2026-01-18 22:11:07,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 660/3600 [04:55<23:43,  2.07it/s]2026-01-18 22:11:08,268 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 661/3600 [04:56<22:26,  2.18it/s]2026-01-18 22:11:08,669 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 662/3600 [04:56<21:35,  2.27it/s]2026-01-18 22:11:09,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 663/3600 [04:56<22:28,  2.18it/s]2026-01-18 22:11:09,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 664/3600 [04:57<22:38,  2.16it/s]2026-01-18 22:11:10,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 665/3600 [04:57<23:19,  2.10it/s]2026-01-18 22:11:10,661 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 666/3600 [04:58<23:45,  2.06it/s]2026-01-18 22:11:11,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 667/3600 [04:58<22:40,  2.16it/s]2026-01-18 22:11:11,492 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 668/3600 [04:59<21:58,  2.22it/s]2026-01-18 22:11:11,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 669/3600 [04:59<22:03,  2.21it/s]2026-01-18 22:11:12,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 670/3600 [05:00<21:51,  2.23it/s]2026-01-18 22:11:12,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 671/3600 [05:00<21:37,  2.26it/s]2026-01-18 22:11:13,457 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 672/3600 [05:01<24:31,  1.99it/s]2026-01-18 22:11:13,888 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 673/3600 [05:01<23:25,  2.08it/s]2026-01-18 22:11:14,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 674/3600 [05:02<22:37,  2.16it/s]2026-01-18 22:11:14,742 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 675/3600 [05:02<22:08,  2.20it/s]2026-01-18 22:11:15,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 676/3600 [05:02<20:46,  2.35it/s]2026-01-18 22:11:15,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 677/3600 [05:03<20:24,  2.39it/s]2026-01-18 22:11:15,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 678/3600 [05:03<21:11,  2.30it/s]2026-01-18 22:11:16,378 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 679/3600 [05:04<20:40,  2.36it/s]2026-01-18 22:11:16,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 680/3600 [05:04<21:51,  2.23it/s]2026-01-18 22:11:17,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 681/3600 [05:05<23:03,  2.11it/s]2026-01-18 22:11:17,835 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 682/3600 [05:05<22:13,  2.19it/s]2026-01-18 22:11:18,430 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 683/3600 [05:06<24:13,  2.01it/s]2026-01-18 22:11:18,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 684/3600 [05:06<24:51,  1.96it/s]2026-01-18 22:11:19,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 685/3600 [05:07<24:27,  1.99it/s]2026-01-18 22:11:19,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 686/3600 [05:07<23:19,  2.08it/s]2026-01-18 22:11:20,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 687/3600 [05:08<24:26,  1.99it/s]2026-01-18 22:11:20,879 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 688/3600 [05:08<23:27,  2.07it/s]2026-01-18 22:11:21,353 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 689/3600 [05:09<23:20,  2.08it/s]2026-01-18 22:11:21,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 690/3600 [05:09<23:24,  2.07it/s]2026-01-18 22:11:22,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 691/3600 [05:09<21:53,  2.21it/s]2026-01-18 22:11:22,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 692/3600 [05:10<20:52,  2.32it/s]2026-01-18 22:11:23,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 693/3600 [05:10<20:49,  2.33it/s]2026-01-18 22:11:23,452 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 694/3600 [05:11<20:47,  2.33it/s]2026-01-18 22:11:23,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 695/3600 [05:11<20:01,  2.42it/s]2026-01-18 22:11:24,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 696/3600 [05:11<20:08,  2.40it/s]2026-01-18 22:11:24,699 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 697/3600 [05:12<20:33,  2.35it/s]2026-01-18 22:11:25,362 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 698/3600 [05:13<24:00,  2.02it/s]2026-01-18 22:11:25,789 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 699/3600 [05:13<22:58,  2.10it/s]2026-01-18 22:11:26,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 700/3600 [05:13<21:47,  2.22it/s]2026-01-18 22:11:26,298 - INFO -     Accuracy: 78.00% (78/100)\n2026-01-18 22:11:26,298 - INFO -   Language: id\n2026-01-18 22:11:26,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 701/3600 [05:14<22:12,  2.18it/s]2026-01-18 22:11:27,078 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 702/3600 [05:14<21:33,  2.24it/s]2026-01-18 22:11:27,528 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 703/3600 [05:15<21:37,  2.23it/s]2026-01-18 22:11:28,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 704/3600 [05:15<21:54,  2.20it/s]2026-01-18 22:11:28,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 705/3600 [05:16<21:09,  2.28it/s]2026-01-18 22:11:38,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n2026-01-18 22:11:38,577 - INFO - Retrying request to /chat/completions in 0.390084 seconds\n2026-01-18 22:11:39,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 706/3600 [05:26<2:52:04,  3.57s/it]2026-01-18 22:11:39,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 707/3600 [05:27<2:06:24,  2.62s/it]2026-01-18 22:11:40,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 708/3600 [05:27<1:34:02,  1.95s/it]2026-01-18 22:11:40,631 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 709/3600 [05:28<1:13:52,  1.53s/it]2026-01-18 22:11:41,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 710/3600 [05:28<57:52,  1.20s/it]  2026-01-18 22:11:41,510 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 711/3600 [05:29<47:05,  1.02it/s]2026-01-18 22:11:41,949 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 712/3600 [05:29<39:15,  1.23it/s]2026-01-18 22:11:42,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 713/3600 [05:30<33:50,  1.42it/s]2026-01-18 22:11:42,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 714/3600 [05:30<29:59,  1.60it/s]2026-01-18 22:11:43,202 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 715/3600 [05:30<26:22,  1.82it/s]2026-01-18 22:11:43,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 716/3600 [05:31<24:09,  1.99it/s]2026-01-18 22:11:44,050 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 717/3600 [05:31<23:28,  2.05it/s]2026-01-18 22:11:44,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 718/3600 [05:32<22:41,  2.12it/s]2026-01-18 22:11:44,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 719/3600 [05:32<21:23,  2.24it/s]2026-01-18 22:11:45,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 720/3600 [05:33<25:06,  1.91it/s]2026-01-18 22:11:46,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 721/3600 [05:33<26:14,  1.83it/s]2026-01-18 22:11:46,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 722/3600 [05:34<25:20,  1.89it/s]2026-01-18 22:11:47,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 723/3600 [05:34<23:49,  2.01it/s]2026-01-18 22:11:47,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 724/3600 [05:35<24:19,  1.97it/s]2026-01-18 22:11:48,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 725/3600 [05:35<22:53,  2.09it/s]2026-01-18 22:11:48,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 726/3600 [05:36<23:16,  2.06it/s]2026-01-18 22:11:48,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 727/3600 [05:36<21:37,  2.21it/s]2026-01-18 22:11:49,359 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 728/3600 [05:37<21:43,  2.20it/s]2026-01-18 22:11:49,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 729/3600 [05:37<21:22,  2.24it/s]2026-01-18 22:11:50,182 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 730/3600 [05:37<20:33,  2.33it/s]2026-01-18 22:11:50,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 731/3600 [05:38<21:43,  2.20it/s]2026-01-18 22:11:51,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 732/3600 [05:38<22:28,  2.13it/s]2026-01-18 22:11:51,713 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 733/3600 [05:39<23:03,  2.07it/s]2026-01-18 22:11:52,315 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 734/3600 [05:40<24:44,  1.93it/s]2026-01-18 22:11:52,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 735/3600 [05:40<24:15,  1.97it/s]2026-01-18 22:11:53,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 736/3600 [05:41<23:50,  2.00it/s]2026-01-18 22:11:53,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 737/3600 [05:41<21:30,  2.22it/s]2026-01-18 22:11:54,091 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 738/3600 [05:41<21:51,  2.18it/s]2026-01-18 22:11:54,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 739/3600 [05:42<21:53,  2.18it/s]2026-01-18 22:11:54,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 740/3600 [05:42<21:05,  2.26it/s]2026-01-18 22:11:55,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 741/3600 [05:43<21:24,  2.23it/s]2026-01-18 22:11:55,844 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 742/3600 [05:43<21:04,  2.26it/s]2026-01-18 22:11:56,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 743/3600 [05:44<24:15,  1.96it/s]2026-01-18 22:11:56,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 744/3600 [05:44<22:50,  2.08it/s]2026-01-18 22:11:57,322 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 745/3600 [05:45<21:43,  2.19it/s]2026-01-18 22:11:57,838 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 746/3600 [05:45<22:32,  2.11it/s]2026-01-18 22:11:58,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 747/3600 [05:46<22:54,  2.08it/s]2026-01-18 22:11:58,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 748/3600 [05:46<22:25,  2.12it/s]2026-01-18 22:11:59,268 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 749/3600 [05:46<22:32,  2.11it/s]2026-01-18 22:11:59,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 750/3600 [05:47<21:39,  2.19it/s]2026-01-18 22:12:00,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 751/3600 [05:47<20:46,  2.29it/s]2026-01-18 22:12:00,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 752/3600 [05:48<20:44,  2.29it/s]2026-01-18 22:12:00,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 753/3600 [05:48<20:58,  2.26it/s]2026-01-18 22:12:01,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 754/3600 [05:49<21:17,  2.23it/s]2026-01-18 22:12:01,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 755/3600 [05:49<21:12,  2.24it/s]2026-01-18 22:12:02,400 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 756/3600 [05:50<22:18,  2.12it/s]2026-01-18 22:12:02,857 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 757/3600 [05:50<22:05,  2.14it/s]2026-01-18 22:12:03,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 758/3600 [05:50<21:02,  2.25it/s]2026-01-18 22:12:03,638 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 759/3600 [05:51<20:17,  2.33it/s]2026-01-18 22:12:04,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 760/3600 [05:51<20:00,  2.37it/s]2026-01-18 22:12:04,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 761/3600 [05:52<19:50,  2.39it/s]2026-01-18 22:12:04,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 762/3600 [05:52<19:46,  2.39it/s]2026-01-18 22:12:05,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 763/3600 [05:53<20:38,  2.29it/s]2026-01-18 22:12:05,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 764/3600 [05:53<21:39,  2.18it/s]2026-01-18 22:12:06,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 765/3600 [05:54<21:36,  2.19it/s]2026-01-18 22:12:06,749 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 766/3600 [05:54<21:10,  2.23it/s]2026-01-18 22:12:07,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 767/3600 [05:54<20:50,  2.27it/s]2026-01-18 22:12:07,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 768/3600 [05:55<20:23,  2.31it/s]2026-01-18 22:12:08,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 769/3600 [05:55<20:56,  2.25it/s]2026-01-18 22:12:08,545 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 770/3600 [05:56<21:36,  2.18it/s]2026-01-18 22:12:09,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 771/3600 [05:56<21:44,  2.17it/s]2026-01-18 22:12:09,465 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 772/3600 [05:57<21:44,  2.17it/s]2026-01-18 22:12:09,924 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 773/3600 [05:57<21:33,  2.18it/s]2026-01-18 22:12:10,408 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 774/3600 [05:58<21:55,  2.15it/s]2026-01-18 22:12:10,828 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 775/3600 [05:58<21:15,  2.22it/s]2026-01-18 22:12:11,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 776/3600 [05:59<21:22,  2.20it/s]2026-01-18 22:12:11,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 777/3600 [05:59<22:13,  2.12it/s]2026-01-18 22:12:12,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 778/3600 [05:59<21:28,  2.19it/s]2026-01-18 22:12:12,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 779/3600 [06:00<21:11,  2.22it/s]2026-01-18 22:12:13,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 780/3600 [06:00<22:09,  2.12it/s]2026-01-18 22:12:13,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 781/3600 [06:01<23:10,  2.03it/s]2026-01-18 22:12:14,096 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 782/3600 [06:01<21:29,  2.19it/s]2026-01-18 22:12:14,548 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 783/3600 [06:02<21:22,  2.20it/s]2026-01-18 22:12:15,033 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 784/3600 [06:02<21:52,  2.15it/s]2026-01-18 22:12:15,705 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 785/3600 [06:03<24:41,  1.90it/s]2026-01-18 22:12:16,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 786/3600 [06:03<22:39,  2.07it/s]2026-01-18 22:12:16,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 787/3600 [06:04<22:44,  2.06it/s]2026-01-18 22:12:17,042 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 788/3600 [06:04<22:29,  2.08it/s]2026-01-18 22:12:17,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 789/3600 [06:05<22:30,  2.08it/s]2026-01-18 22:12:17,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 790/3600 [06:05<22:08,  2.12it/s]2026-01-18 22:12:18,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 791/3600 [06:06<22:46,  2.06it/s]2026-01-18 22:12:20,251 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 792/3600 [06:07<40:32,  1.15it/s]2026-01-18 22:12:20,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 793/3600 [06:08<34:30,  1.36it/s]2026-01-18 22:12:21,177 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 794/3600 [06:08<31:02,  1.51it/s]2026-01-18 22:12:21,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 795/3600 [06:09<28:09,  1.66it/s]2026-01-18 22:12:22,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 796/3600 [06:09<27:08,  1.72it/s]2026-01-18 22:12:22,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 797/3600 [06:10<28:41,  1.63it/s]2026-01-18 22:12:23,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 798/3600 [06:10<25:24,  1.84it/s]2026-01-18 22:12:23,609 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 799/3600 [06:11<22:56,  2.04it/s]2026-01-18 22:12:24,013 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 800/3600 [06:11<21:40,  2.15it/s]2026-01-18 22:12:24,120 - INFO -     Accuracy: 81.00% (81/100)\n2026-01-18 22:12:24,120 - INFO -   Language: bn\n2026-01-18 22:12:24,446 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 801/3600 [06:12<21:14,  2.20it/s]2026-01-18 22:12:24,859 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 802/3600 [06:12<20:37,  2.26it/s]2026-01-18 22:12:25,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 803/3600 [06:12<20:05,  2.32it/s]2026-01-18 22:12:25,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 804/3600 [06:13<20:27,  2.28it/s]2026-01-18 22:12:26,113 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 805/3600 [06:13<19:47,  2.35it/s]2026-01-18 22:12:26,645 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 806/3600 [06:14<21:20,  2.18it/s]2026-01-18 22:12:27,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 807/3600 [06:14<20:25,  2.28it/s]2026-01-18 22:12:27,462 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 808/3600 [06:15<20:09,  2.31it/s]2026-01-18 22:12:27,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 809/3600 [06:15<19:39,  2.37it/s]2026-01-18 22:12:28,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▎       | 810/3600 [06:16<19:49,  2.35it/s]2026-01-18 22:12:28,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 811/3600 [06:16<19:04,  2.44it/s]2026-01-18 22:12:29,045 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 812/3600 [06:16<18:34,  2.50it/s]2026-01-18 22:12:29,459 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 813/3600 [06:17<18:48,  2.47it/s]2026-01-18 22:12:30,162 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 814/3600 [06:17<22:57,  2.02it/s]2026-01-18 22:12:30,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 815/3600 [06:18<21:19,  2.18it/s]2026-01-18 22:12:30,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 816/3600 [06:18<20:13,  2.29it/s]2026-01-18 22:12:31,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 817/3600 [06:19<22:50,  2.03it/s]2026-01-18 22:12:31,910 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 818/3600 [06:19<21:02,  2.20it/s]2026-01-18 22:12:32,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 819/3600 [06:20<20:29,  2.26it/s]2026-01-18 22:12:32,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 820/3600 [06:20<19:55,  2.33it/s]2026-01-18 22:12:33,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 821/3600 [06:20<19:53,  2.33it/s]2026-01-18 22:12:33,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 822/3600 [06:21<19:02,  2.43it/s]2026-01-18 22:12:33,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 823/3600 [06:21<19:35,  2.36it/s]2026-01-18 22:12:34,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 824/3600 [06:22<24:27,  1.89it/s]2026-01-18 22:12:35,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 825/3600 [06:22<22:20,  2.07it/s]2026-01-18 22:12:35,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 826/3600 [06:23<21:22,  2.16it/s]2026-01-18 22:12:35,902 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 827/3600 [06:23<19:57,  2.32it/s]2026-01-18 22:12:36,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 828/3600 [06:24<19:29,  2.37it/s]2026-01-18 22:12:36,848 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 829/3600 [06:24<21:13,  2.18it/s]2026-01-18 22:12:37,246 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 830/3600 [06:24<20:21,  2.27it/s]2026-01-18 22:12:37,762 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 831/3600 [06:25<21:26,  2.15it/s]2026-01-18 22:12:38,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 832/3600 [06:25<20:24,  2.26it/s]2026-01-18 22:12:38,591 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 833/3600 [06:26<20:17,  2.27it/s]2026-01-18 22:12:38,997 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 834/3600 [06:26<19:48,  2.33it/s]2026-01-18 22:12:39,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 835/3600 [06:27<19:49,  2.33it/s]2026-01-18 22:12:39,949 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 836/3600 [06:27<21:05,  2.18it/s]2026-01-18 22:12:40,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 837/3600 [06:28<21:32,  2.14it/s]2026-01-18 22:12:40,892 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 838/3600 [06:28<21:16,  2.16it/s]2026-01-18 22:12:41,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 839/3600 [06:28<19:42,  2.33it/s]2026-01-18 22:12:41,661 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 840/3600 [06:29<19:39,  2.34it/s]2026-01-18 22:12:42,132 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 841/3600 [06:29<20:12,  2.28it/s]2026-01-18 22:12:42,703 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 842/3600 [06:30<22:01,  2.09it/s]2026-01-18 22:12:43,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 843/3600 [06:30<21:47,  2.11it/s]2026-01-18 22:12:43,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 844/3600 [06:31<20:47,  2.21it/s]2026-01-18 22:12:43,966 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 845/3600 [06:31<19:59,  2.30it/s]2026-01-18 22:12:44,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 846/3600 [06:32<20:17,  2.26it/s]2026-01-18 22:12:44,909 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 847/3600 [06:32<20:56,  2.19it/s]2026-01-18 22:12:45,304 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 848/3600 [06:33<20:06,  2.28it/s]2026-01-18 22:12:45,756 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 849/3600 [06:33<20:13,  2.27it/s]2026-01-18 22:12:46,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 850/3600 [06:33<20:27,  2.24it/s]2026-01-18 22:12:46,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 851/3600 [06:34<19:48,  2.31it/s]2026-01-18 22:12:46,996 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 852/3600 [06:34<19:05,  2.40it/s]2026-01-18 22:12:47,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 853/3600 [06:35<19:48,  2.31it/s]2026-01-18 22:12:48,004 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 854/3600 [06:35<21:18,  2.15it/s]2026-01-18 22:12:48,411 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 855/3600 [06:36<20:26,  2.24it/s]2026-01-18 22:12:48,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 856/3600 [06:36<20:12,  2.26it/s]2026-01-18 22:12:49,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 857/3600 [06:36<19:25,  2.35it/s]2026-01-18 22:12:49,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 858/3600 [06:37<19:42,  2.32it/s]2026-01-18 22:12:50,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 859/3600 [06:37<19:14,  2.37it/s]2026-01-18 22:12:50,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 860/3600 [06:38<19:18,  2.37it/s]2026-01-18 22:12:50,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 861/3600 [06:38<18:51,  2.42it/s]2026-01-18 22:12:51,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 862/3600 [06:38<18:10,  2.51it/s]2026-01-18 22:12:51,709 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 863/3600 [06:39<19:04,  2.39it/s]2026-01-18 22:12:52,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 864/3600 [06:39<19:18,  2.36it/s]2026-01-18 22:12:52,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 865/3600 [06:40<19:44,  2.31it/s]2026-01-18 22:12:53,097 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 866/3600 [06:40<20:33,  2.22it/s]2026-01-18 22:12:53,497 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 867/3600 [06:41<19:50,  2.30it/s]2026-01-18 22:12:53,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 868/3600 [06:41<20:17,  2.24it/s]2026-01-18 22:12:54,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 869/3600 [06:42<21:21,  2.13it/s]2026-01-18 22:12:54,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 870/3600 [06:42<20:19,  2.24it/s]2026-01-18 22:12:55,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 871/3600 [06:43<19:59,  2.28it/s]2026-01-18 22:12:55,677 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 872/3600 [06:43<19:03,  2.39it/s]2026-01-18 22:12:56,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 873/3600 [06:43<18:29,  2.46it/s]2026-01-18 22:12:56,470 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 874/3600 [06:44<18:35,  2.44it/s]2026-01-18 22:12:56,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 875/3600 [06:44<19:09,  2.37it/s]2026-01-18 22:12:57,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 876/3600 [06:45<18:43,  2.42it/s]2026-01-18 22:12:57,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 877/3600 [06:45<19:29,  2.33it/s]2026-01-18 22:12:58,415 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 878/3600 [06:46<22:14,  2.04it/s]2026-01-18 22:12:58,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 879/3600 [06:46<21:52,  2.07it/s]2026-01-18 22:12:59,405 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 880/3600 [06:47<22:27,  2.02it/s]2026-01-18 22:12:59,770 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 881/3600 [06:47<20:41,  2.19it/s]2026-01-18 22:13:00,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 882/3600 [06:47<21:06,  2.15it/s]2026-01-18 22:13:00,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 883/3600 [06:48<20:30,  2.21it/s]2026-01-18 22:13:01,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 884/3600 [06:48<20:57,  2.16it/s]2026-01-18 22:13:01,584 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 885/3600 [06:49<20:19,  2.23it/s]2026-01-18 22:13:01,978 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 886/3600 [06:49<19:33,  2.31it/s]2026-01-18 22:13:02,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 887/3600 [06:50<19:00,  2.38it/s]2026-01-18 22:13:02,838 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 888/3600 [06:50<19:37,  2.30it/s]2026-01-18 22:13:03,341 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 889/3600 [06:51<20:32,  2.20it/s]2026-01-18 22:13:03,743 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 890/3600 [06:51<19:50,  2.28it/s]2026-01-18 22:13:04,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 891/3600 [06:51<19:05,  2.37it/s]2026-01-18 22:13:04,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 892/3600 [06:52<19:57,  2.26it/s]2026-01-18 22:13:05,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 893/3600 [06:52<21:51,  2.06it/s]2026-01-18 22:13:05,617 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 894/3600 [06:53<20:56,  2.15it/s]2026-01-18 22:13:06,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 895/3600 [06:53<20:35,  2.19it/s]2026-01-18 22:13:06,449 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 896/3600 [06:54<19:44,  2.28it/s]2026-01-18 22:13:06,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 897/3600 [06:54<18:49,  2.39it/s]2026-01-18 22:13:07,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 898/3600 [06:54<18:51,  2.39it/s]2026-01-18 22:13:07,723 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 899/3600 [06:55<19:43,  2.28it/s]2026-01-18 22:13:08,139 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 900/3600 [06:55<19:25,  2.32it/s]2026-01-18 22:13:08,247 - INFO -     Accuracy: 76.00% (76/100)\n2026-01-18 22:13:08,248 - INFO -   Language: te\n2026-01-18 22:13:08,652 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 901/3600 [06:56<20:37,  2.18it/s]2026-01-18 22:13:09,035 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 902/3600 [06:56<19:32,  2.30it/s]2026-01-18 22:13:09,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 903/3600 [06:57<19:29,  2.31it/s]2026-01-18 22:13:10,024 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 904/3600 [06:57<21:06,  2.13it/s]2026-01-18 22:13:10,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 905/3600 [06:58<20:34,  2.18it/s]2026-01-18 22:13:10,904 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 906/3600 [06:58<20:26,  2.20it/s]2026-01-18 22:13:11,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 907/3600 [06:59<19:48,  2.27it/s]2026-01-18 22:13:11,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 908/3600 [06:59<19:37,  2.29it/s]2026-01-18 22:13:12,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 909/3600 [06:59<19:20,  2.32it/s]2026-01-18 22:13:12,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 910/3600 [07:00<18:26,  2.43it/s]2026-01-18 22:13:12,916 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 911/3600 [07:00<18:10,  2.47it/s]2026-01-18 22:13:13,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 912/3600 [07:01<19:09,  2.34it/s]2026-01-18 22:13:13,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 913/3600 [07:01<19:28,  2.30it/s]2026-01-18 22:13:14,315 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 914/3600 [07:02<19:55,  2.25it/s]2026-01-18 22:13:15,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 915/3600 [07:02<24:08,  1.85it/s]2026-01-18 22:13:15,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 916/3600 [07:03<24:43,  1.81it/s]2026-01-18 22:13:16,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 917/3600 [07:03<22:55,  1.95it/s]2026-01-18 22:13:16,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 918/3600 [07:04<21:27,  2.08it/s]2026-01-18 22:13:16,902 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 919/3600 [07:04<20:37,  2.17it/s]2026-01-18 22:13:17,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 920/3600 [07:05<20:04,  2.22it/s]2026-01-18 22:13:17,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 921/3600 [07:05<18:52,  2.37it/s]2026-01-18 22:13:18,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 922/3600 [07:05<20:03,  2.23it/s]2026-01-18 22:13:19,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 923/3600 [07:06<26:23,  1.69it/s]2026-01-18 22:13:19,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 924/3600 [07:07<23:57,  1.86it/s]2026-01-18 22:13:19,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 925/3600 [07:07<22:57,  1.94it/s]2026-01-18 22:13:20,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 926/3600 [07:08<21:54,  2.03it/s]2026-01-18 22:13:20,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 927/3600 [07:08<20:23,  2.18it/s]2026-01-18 22:13:21,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 928/3600 [07:08<19:50,  2.24it/s]2026-01-18 22:13:21,796 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 929/3600 [07:09<21:31,  2.07it/s]2026-01-18 22:13:22,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 930/3600 [07:09<20:45,  2.14it/s]2026-01-18 22:13:22,624 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 931/3600 [07:10<19:53,  2.24it/s]2026-01-18 22:13:23,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 932/3600 [07:10<19:34,  2.27it/s]2026-01-18 22:13:23,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 933/3600 [07:11<19:11,  2.32it/s]2026-01-18 22:13:23,857 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 934/3600 [07:11<18:42,  2.38it/s]2026-01-18 22:13:24,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 935/3600 [07:11<18:15,  2.43it/s]2026-01-18 22:13:24,729 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 936/3600 [07:12<19:15,  2.31it/s]2026-01-18 22:13:25,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 937/3600 [07:12<19:20,  2.29it/s]2026-01-18 22:13:25,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 938/3600 [07:13<21:21,  2.08it/s]2026-01-18 22:13:26,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 939/3600 [07:13<20:36,  2.15it/s]2026-01-18 22:13:26,592 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 940/3600 [07:14<19:52,  2.23it/s]2026-01-18 22:13:26,981 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 941/3600 [07:14<19:04,  2.32it/s]2026-01-18 22:13:27,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 942/3600 [07:15<18:52,  2.35it/s]2026-01-18 22:13:27,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 943/3600 [07:15<19:24,  2.28it/s]2026-01-18 22:13:28,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 944/3600 [07:15<18:14,  2.43it/s]2026-01-18 22:13:28,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 945/3600 [07:16<19:30,  2.27it/s]2026-01-18 22:13:29,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 946/3600 [07:16<19:49,  2.23it/s]2026-01-18 22:13:29,662 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 947/3600 [07:17<20:06,  2.20it/s]2026-01-18 22:13:30,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 948/3600 [07:18<26:07,  1.69it/s]2026-01-18 22:13:30,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 949/3600 [07:18<23:55,  1.85it/s]2026-01-18 22:13:31,348 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 950/3600 [07:19<21:24,  2.06it/s]2026-01-18 22:13:31,756 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 951/3600 [07:19<20:21,  2.17it/s]2026-01-18 22:13:32,182 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 952/3600 [07:19<19:59,  2.21it/s]2026-01-18 22:13:32,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 953/3600 [07:20<19:09,  2.30it/s]2026-01-18 22:13:32,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 954/3600 [07:20<18:52,  2.34it/s]2026-01-18 22:13:33,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 955/3600 [07:21<18:14,  2.42it/s]2026-01-18 22:13:33,899 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 956/3600 [07:21<19:45,  2.23it/s]2026-01-18 22:13:34,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 957/3600 [07:22<19:58,  2.20it/s]2026-01-18 22:13:34,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 958/3600 [07:22<20:51,  2.11it/s]2026-01-18 22:13:35,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 959/3600 [07:22<19:32,  2.25it/s]2026-01-18 22:13:35,611 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 960/3600 [07:23<18:18,  2.40it/s]2026-01-18 22:13:36,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 961/3600 [07:23<18:54,  2.33it/s]2026-01-18 22:13:36,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 962/3600 [07:24<18:08,  2.42it/s]2026-01-18 22:13:36,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 963/3600 [07:24<17:39,  2.49it/s]2026-01-18 22:13:37,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 964/3600 [07:24<17:38,  2.49it/s]2026-01-18 22:13:37,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 965/3600 [07:25<18:25,  2.38it/s]2026-01-18 22:13:38,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 966/3600 [07:25<18:38,  2.36it/s]2026-01-18 22:13:38,539 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 967/3600 [07:26<18:31,  2.37it/s]2026-01-18 22:13:38,894 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 968/3600 [07:26<17:38,  2.49it/s]2026-01-18 22:13:39,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 969/3600 [07:27<19:58,  2.19it/s]2026-01-18 22:13:40,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 970/3600 [07:27<20:55,  2.09it/s]2026-01-18 22:13:40,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 971/3600 [07:28<19:36,  2.23it/s]2026-01-18 22:13:40,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 972/3600 [07:28<19:28,  2.25it/s]2026-01-18 22:13:41,250 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 973/3600 [07:28<19:17,  2.27it/s]2026-01-18 22:13:41,712 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 974/3600 [07:29<19:34,  2.24it/s]2026-01-18 22:13:42,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 975/3600 [07:29<19:18,  2.27it/s]2026-01-18 22:13:42,644 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 976/3600 [07:30<20:07,  2.17it/s]2026-01-18 22:13:43,018 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 977/3600 [07:30<19:00,  2.30it/s]2026-01-18 22:13:43,726 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 978/3600 [07:31<22:35,  1.93it/s]2026-01-18 22:13:44,205 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 979/3600 [07:31<22:04,  1.98it/s]2026-01-18 22:13:44,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 980/3600 [07:32<22:11,  1.97it/s]2026-01-18 22:13:45,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 981/3600 [07:32<20:14,  2.16it/s]2026-01-18 22:13:45,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 982/3600 [07:33<19:17,  2.26it/s]2026-01-18 22:13:45,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 983/3600 [07:33<18:29,  2.36it/s]2026-01-18 22:13:46,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 984/3600 [07:34<18:54,  2.31it/s]2026-01-18 22:13:47,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 985/3600 [07:34<22:20,  1.95it/s]2026-01-18 22:13:47,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 986/3600 [07:35<21:14,  2.05it/s]2026-01-18 22:13:47,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 987/3600 [07:35<20:39,  2.11it/s]2026-01-18 22:13:48,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 988/3600 [07:36<20:06,  2.17it/s]2026-01-18 22:13:48,834 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 989/3600 [07:36<20:52,  2.09it/s]2026-01-18 22:13:49,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 990/3600 [07:37<20:55,  2.08it/s]2026-01-18 22:13:49,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 991/3600 [07:37<20:53,  2.08it/s]2026-01-18 22:13:50,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 992/3600 [07:37<20:23,  2.13it/s]2026-01-18 22:13:50,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 993/3600 [07:38<21:01,  2.07it/s]2026-01-18 22:13:51,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 994/3600 [07:38<20:16,  2.14it/s]2026-01-18 22:13:51,615 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 995/3600 [07:39<19:45,  2.20it/s]2026-01-18 22:13:52,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 996/3600 [07:39<18:59,  2.29it/s]2026-01-18 22:13:52,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 997/3600 [07:40<21:35,  2.01it/s]2026-01-18 22:13:53,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 998/3600 [07:40<19:56,  2.17it/s]2026-01-18 22:13:53,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 999/3600 [07:41<20:21,  2.13it/s]2026-01-18 22:13:53,887 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1000/3600 [07:41<19:08,  2.26it/s]2026-01-18 22:13:54,005 - INFO -     Accuracy: 69.00% (69/100)\n2026-01-18 22:13:54,005 - INFO -   Language: sw\n2026-01-18 22:13:54,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1001/3600 [07:42<18:41,  2.32it/s]2026-01-18 22:13:54,776 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1002/3600 [07:42<19:19,  2.24it/s]2026-01-18 22:13:55,187 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1003/3600 [07:42<18:52,  2.29it/s]2026-01-18 22:13:55,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1004/3600 [07:43<19:51,  2.18it/s]2026-01-18 22:13:56,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1005/3600 [07:43<19:06,  2.26it/s]2026-01-18 22:13:56,491 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1006/3600 [07:44<18:24,  2.35it/s]2026-01-18 22:13:56,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1007/3600 [07:44<18:06,  2.39it/s]2026-01-18 22:13:57,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1008/3600 [07:45<18:17,  2.36it/s]2026-01-18 22:13:57,974 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1009/3600 [07:45<21:10,  2.04it/s]2026-01-18 22:13:58,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1010/3600 [07:46<20:27,  2.11it/s]2026-01-18 22:13:58,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1011/3600 [07:46<19:17,  2.24it/s]2026-01-18 22:13:59,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1012/3600 [07:46<19:18,  2.23it/s]2026-01-18 22:13:59,726 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1013/3600 [07:47<19:44,  2.18it/s]2026-01-18 22:14:00,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1014/3600 [07:47<19:28,  2.21it/s]2026-01-18 22:14:00,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1015/3600 [07:48<18:50,  2.29it/s]2026-01-18 22:14:00,992 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1016/3600 [07:48<18:41,  2.30it/s]2026-01-18 22:14:01,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1017/3600 [07:49<17:49,  2.41it/s]2026-01-18 22:14:01,728 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1018/3600 [07:49<17:15,  2.49it/s]2026-01-18 22:14:02,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1019/3600 [07:49<17:43,  2.43it/s]2026-01-18 22:14:02,814 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1020/3600 [07:50<20:41,  2.08it/s]2026-01-18 22:14:03,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1021/3600 [07:51<20:25,  2.10it/s]2026-01-18 22:14:03,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1022/3600 [07:51<20:05,  2.14it/s]2026-01-18 22:14:04,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1023/3600 [07:51<19:13,  2.23it/s]2026-01-18 22:14:04,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1024/3600 [07:52<19:42,  2.18it/s]2026-01-18 22:14:04,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1025/3600 [07:52<18:31,  2.32it/s]2026-01-18 22:14:05,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1026/3600 [07:53<19:21,  2.22it/s]2026-01-18 22:14:05,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1027/3600 [07:53<19:30,  2.20it/s]2026-01-18 22:14:06,562 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1028/3600 [07:54<21:42,  1.97it/s]2026-01-18 22:14:07,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1029/3600 [07:54<21:26,  2.00it/s]2026-01-18 22:14:07,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1030/3600 [07:55<19:58,  2.14it/s]2026-01-18 22:14:08,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1031/3600 [07:55<21:25,  2.00it/s]2026-01-18 22:14:08,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1032/3600 [07:56<19:41,  2.17it/s]2026-01-18 22:14:08,871 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1033/3600 [07:56<20:06,  2.13it/s]2026-01-18 22:14:09,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1034/3600 [07:57<20:15,  2.11it/s]2026-01-18 22:14:09,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1035/3600 [07:57<19:18,  2.21it/s]2026-01-18 22:14:10,191 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1036/3600 [07:57<19:01,  2.25it/s]2026-01-18 22:14:10,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1037/3600 [07:58<19:22,  2.20it/s]2026-01-18 22:14:11,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1038/3600 [07:58<18:43,  2.28it/s]2026-01-18 22:14:11,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1039/3600 [07:59<18:05,  2.36it/s]2026-01-18 22:14:11,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1040/3600 [07:59<17:36,  2.42it/s]2026-01-18 22:14:12,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1041/3600 [08:00<17:55,  2.38it/s]2026-01-18 22:14:12,753 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1042/3600 [08:00<18:38,  2.29it/s]2026-01-18 22:14:13,134 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1043/3600 [08:00<17:54,  2.38it/s]2026-01-18 22:14:13,548 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1044/3600 [08:01<17:51,  2.38it/s]2026-01-18 22:14:13,964 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1045/3600 [08:01<17:43,  2.40it/s]2026-01-18 22:14:14,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1046/3600 [08:02<18:40,  2.28it/s]2026-01-18 22:14:14,866 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1047/3600 [08:02<18:19,  2.32it/s]2026-01-18 22:14:15,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1048/3600 [08:02<17:53,  2.38it/s]2026-01-18 22:14:15,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1049/3600 [08:03<17:45,  2.39it/s]2026-01-18 22:14:16,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1050/3600 [08:03<17:22,  2.45it/s]2026-01-18 22:14:16,588 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1051/3600 [08:04<18:51,  2.25it/s]2026-01-18 22:14:16,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1052/3600 [08:04<17:37,  2.41it/s]2026-01-18 22:14:17,330 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1053/3600 [08:05<17:23,  2.44it/s]2026-01-18 22:14:17,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1054/3600 [08:05<18:27,  2.30it/s]2026-01-18 22:14:18,266 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1055/3600 [08:05<18:30,  2.29it/s]2026-01-18 22:14:18,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1056/3600 [08:06<18:18,  2.32it/s]2026-01-18 22:14:19,077 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1057/3600 [08:06<17:46,  2.38it/s]2026-01-18 22:14:19,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1058/3600 [08:07<17:05,  2.48it/s]2026-01-18 22:14:19,867 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1059/3600 [08:07<17:20,  2.44it/s]2026-01-18 22:14:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1060/3600 [08:08<18:37,  2.27it/s]2026-01-18 22:14:20,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1061/3600 [08:08<20:12,  2.09it/s]2026-01-18 22:14:21,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1062/3600 [08:09<18:49,  2.25it/s]2026-01-18 22:14:21,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1063/3600 [08:09<17:52,  2.36it/s]2026-01-18 22:14:22,140 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1064/3600 [08:09<18:15,  2.32it/s]2026-01-18 22:14:22,550 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1065/3600 [08:10<17:57,  2.35it/s]2026-01-18 22:14:22,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1066/3600 [08:10<17:25,  2.42it/s]2026-01-18 22:14:23,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1067/3600 [08:11<19:20,  2.18it/s]2026-01-18 22:14:24,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1068/3600 [08:11<20:10,  2.09it/s]2026-01-18 22:14:24,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1069/3600 [08:12<19:39,  2.15it/s]2026-01-18 22:14:24,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1070/3600 [08:12<20:04,  2.10it/s]2026-01-18 22:14:25,328 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1071/3600 [08:13<18:46,  2.24it/s]2026-01-18 22:14:25,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1072/3600 [08:13<19:53,  2.12it/s]2026-01-18 22:14:26,254 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1073/3600 [08:13<18:58,  2.22it/s]2026-01-18 22:14:26,730 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1074/3600 [08:14<19:07,  2.20it/s]2026-01-18 22:14:27,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1075/3600 [08:14<17:55,  2.35it/s]2026-01-18 22:14:27,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1076/3600 [08:15<16:54,  2.49it/s]2026-01-18 22:14:27,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1077/3600 [08:15<17:37,  2.39it/s]2026-01-18 22:14:28,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1078/3600 [08:16<17:24,  2.41it/s]2026-01-18 22:14:28,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1079/3600 [08:16<17:14,  2.44it/s]2026-01-18 22:14:29,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1080/3600 [08:16<17:19,  2.42it/s]2026-01-18 22:14:29,522 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1081/3600 [08:17<17:18,  2.43it/s]2026-01-18 22:14:30,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1082/3600 [08:17<18:59,  2.21it/s]2026-01-18 22:14:30,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1083/3600 [08:18<17:58,  2.33it/s]2026-01-18 22:14:30,859 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1084/3600 [08:18<17:44,  2.36it/s]2026-01-18 22:14:31,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1085/3600 [08:19<17:41,  2.37it/s]2026-01-18 22:14:31,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1086/3600 [08:19<17:55,  2.34it/s]2026-01-18 22:14:32,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1087/3600 [08:19<18:23,  2.28it/s]2026-01-18 22:14:32,541 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1088/3600 [08:20<17:21,  2.41it/s]2026-01-18 22:14:32,951 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1089/3600 [08:20<17:18,  2.42it/s]2026-01-18 22:14:33,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1090/3600 [08:21<17:05,  2.45it/s]2026-01-18 22:14:33,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1091/3600 [08:21<18:08,  2.30it/s]2026-01-18 22:14:34,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1092/3600 [08:21<17:56,  2.33it/s]2026-01-18 22:14:34,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1093/3600 [08:22<17:17,  2.42it/s]2026-01-18 22:14:35,116 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1094/3600 [08:22<18:03,  2.31it/s]2026-01-18 22:14:35,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1095/3600 [08:23<19:25,  2.15it/s]2026-01-18 22:14:36,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1096/3600 [08:23<19:06,  2.18it/s]2026-01-18 22:14:36,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1097/3600 [08:24<18:03,  2.31it/s]2026-01-18 22:14:37,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1098/3600 [08:24<20:37,  2.02it/s]2026-01-18 22:14:37,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1099/3600 [08:25<19:26,  2.14it/s]2026-01-18 22:14:37,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1100/3600 [08:25<17:54,  2.33it/s]2026-01-18 22:14:37,963 - INFO -     Accuracy: 79.00% (79/100)\n2026-01-18 22:14:37,963 - INFO -   Language: ta\n2026-01-18 22:14:38,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1101/3600 [08:26<19:22,  2.15it/s]2026-01-18 22:14:38,793 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1102/3600 [08:26<18:27,  2.25it/s]2026-01-18 22:14:39,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1103/3600 [08:26<18:28,  2.25it/s]2026-01-18 22:14:39,782 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1104/3600 [08:27<19:41,  2.11it/s]2026-01-18 22:14:40,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1105/3600 [08:28<19:54,  2.09it/s]2026-01-18 22:14:40,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1106/3600 [08:28<19:33,  2.13it/s]2026-01-18 22:14:41,141 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1107/3600 [08:28<19:00,  2.19it/s]2026-01-18 22:14:41,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1108/3600 [08:29<17:53,  2.32it/s]2026-01-18 22:14:41,941 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1109/3600 [08:29<17:45,  2.34it/s]2026-01-18 22:14:42,352 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1110/3600 [08:30<17:31,  2.37it/s]2026-01-18 22:14:42,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1111/3600 [08:30<17:14,  2.41it/s]2026-01-18 22:14:43,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1112/3600 [08:31<18:40,  2.22it/s]2026-01-18 22:14:43,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1113/3600 [08:31<18:11,  2.28it/s]2026-01-18 22:14:44,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1114/3600 [08:31<17:47,  2.33it/s]2026-01-18 22:14:44,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1115/3600 [08:32<17:18,  2.39it/s]2026-01-18 22:14:44,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1116/3600 [08:32<17:45,  2.33it/s]2026-01-18 22:14:45,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1117/3600 [08:33<20:03,  2.06it/s]2026-01-18 22:14:46,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1118/3600 [08:33<20:01,  2.07it/s]2026-01-18 22:14:46,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1119/3600 [08:34<20:00,  2.07it/s]2026-01-18 22:14:46,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1120/3600 [08:34<19:09,  2.16it/s]2026-01-18 22:14:47,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1121/3600 [08:35<18:24,  2.24it/s]2026-01-18 22:14:47,786 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1122/3600 [08:35<18:16,  2.26it/s]2026-01-18 22:14:48,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1123/3600 [08:35<17:44,  2.33it/s]2026-01-18 22:14:48,604 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1124/3600 [08:36<17:35,  2.35it/s]2026-01-18 22:14:49,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1125/3600 [08:36<18:06,  2.28it/s]2026-01-18 22:14:49,518 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1126/3600 [08:37<18:11,  2.27it/s]2026-01-18 22:14:49,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1127/3600 [08:37<17:35,  2.34it/s]2026-01-18 22:14:50,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1128/3600 [08:38<17:20,  2.37it/s]2026-01-18 22:14:50,717 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1129/3600 [08:38<17:06,  2.41it/s]2026-01-18 22:14:51,231 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1130/3600 [08:38<18:13,  2.26it/s]2026-01-18 22:14:51,660 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1131/3600 [08:39<18:05,  2.28it/s]2026-01-18 22:14:52,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1132/3600 [08:39<17:37,  2.33it/s]2026-01-18 22:14:52,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1133/3600 [08:40<16:50,  2.44it/s]2026-01-18 22:14:52,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1134/3600 [08:40<16:25,  2.50it/s]2026-01-18 22:14:53,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1135/3600 [08:40<16:28,  2.49it/s]2026-01-18 22:14:53,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1136/3600 [08:41<17:32,  2.34it/s]2026-01-18 22:14:54,088 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1137/3600 [08:41<17:03,  2.41it/s]2026-01-18 22:14:54,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1138/3600 [08:42<16:51,  2.44it/s]2026-01-18 22:14:54,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1139/3600 [08:42<16:45,  2.45it/s]2026-01-18 22:14:55,484 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1140/3600 [08:43<19:02,  2.15it/s]2026-01-18 22:14:55,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1141/3600 [08:43<19:11,  2.13it/s]2026-01-18 22:14:56,421 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1142/3600 [08:44<19:04,  2.15it/s]2026-01-18 22:14:56,915 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1143/3600 [08:44<19:25,  2.11it/s]2026-01-18 22:14:57,389 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1144/3600 [08:45<19:24,  2.11it/s]2026-01-18 22:14:57,816 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1145/3600 [08:45<18:52,  2.17it/s]2026-01-18 22:14:58,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1146/3600 [08:45<17:42,  2.31it/s]2026-01-18 22:14:58,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1147/3600 [08:46<18:10,  2.25it/s]2026-01-18 22:14:59,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1148/3600 [08:46<17:20,  2.36it/s]2026-01-18 22:14:59,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1149/3600 [08:47<16:43,  2.44it/s]2026-01-18 22:14:59,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1150/3600 [08:47<17:08,  2.38it/s]2026-01-18 22:15:00,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1151/3600 [08:48<19:52,  2.05it/s]2026-01-18 22:15:00,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1152/3600 [08:48<18:53,  2.16it/s]2026-01-18 22:15:01,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1153/3600 [08:49<18:48,  2.17it/s]2026-01-18 22:15:01,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1154/3600 [08:49<17:59,  2.27it/s]2026-01-18 22:15:02,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1155/3600 [08:49<18:33,  2.20it/s]2026-01-18 22:15:02,630 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1156/3600 [08:50<17:43,  2.30it/s]2026-01-18 22:15:03,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1157/3600 [08:50<17:41,  2.30it/s]2026-01-18 22:15:03,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1158/3600 [08:51<18:16,  2.23it/s]2026-01-18 22:15:03,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1159/3600 [08:51<17:42,  2.30it/s]2026-01-18 22:15:04,405 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1160/3600 [08:52<17:54,  2.27it/s]2026-01-18 22:15:04,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1161/3600 [08:52<17:38,  2.30it/s]2026-01-18 22:15:05,214 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1162/3600 [08:52<17:07,  2.37it/s]2026-01-18 22:15:05,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1163/3600 [08:53<17:34,  2.31it/s]2026-01-18 22:15:06,078 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1164/3600 [08:53<17:15,  2.35it/s]2026-01-18 22:15:06,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1165/3600 [08:54<18:50,  2.15it/s]2026-01-18 22:15:07,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1166/3600 [08:54<18:27,  2.20it/s]2026-01-18 22:15:07,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1167/3600 [08:55<18:43,  2.17it/s]2026-01-18 22:15:08,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1168/3600 [08:56<24:14,  1.67it/s]2026-01-18 22:15:08,897 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1169/3600 [08:56<22:15,  1.82it/s]2026-01-18 22:15:09,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▎      | 1170/3600 [08:57<20:22,  1.99it/s]2026-01-18 22:15:09,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1171/3600 [08:57<21:35,  1.87it/s]2026-01-18 22:15:10,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1172/3600 [08:58<20:19,  1.99it/s]2026-01-18 22:15:11,008 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1173/3600 [08:58<22:26,  1.80it/s]2026-01-18 22:15:11,473 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1174/3600 [08:59<21:22,  1.89it/s]2026-01-18 22:15:11,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1175/3600 [08:59<19:24,  2.08it/s]2026-01-18 22:15:12,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1176/3600 [09:00<20:52,  1.94it/s]2026-01-18 22:15:13,030 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1177/3600 [09:00<21:41,  1.86it/s]2026-01-18 22:15:13,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1178/3600 [09:01<21:03,  1.92it/s]2026-01-18 22:15:13,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1179/3600 [09:01<19:41,  2.05it/s]2026-01-18 22:15:14,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1180/3600 [09:02<19:17,  2.09it/s]2026-01-18 22:15:14,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1181/3600 [09:02<18:41,  2.16it/s]2026-01-18 22:15:15,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1182/3600 [09:02<17:51,  2.26it/s]2026-01-18 22:15:15,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1183/3600 [09:03<17:22,  2.32it/s]2026-01-18 22:15:15,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1184/3600 [09:03<16:50,  2.39it/s]2026-01-18 22:15:16,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]\rEvaluating:  34%|███▍      | 1217/3600 [09:40<1:18:00,  1.96s/it]\rEvaluating:  34%|███▍      | 1218/3600 [09:42<1:11:35,  1.80s/it]\rEvaluating:  34%|███▍      | 1219/3600 [09:44<1:13:39,  1.86s/it]\rEvaluating:  34%|███▍      | 1220/3600 [09:45<1:06:39,  1.68s/it]\rEvaluating:  34%|███▍      | 1221/3600 [09:47<1:08:41,  1.73s/it]\rEvaluating:  34%|███▍      | 1222/3600 [09:49<1:18:09,  1.97s/it]\rEvaluating:  34%|███▍      | 1223/3600 [09:51<1:11:54,  1.82s/it]\rEvaluating:  34%|███▍      | 1224/3600 [09:52<1:11:49,  1.81s/it]\rEvaluating:  34%|███▍      | 1225/3600 [09:54<1:11:48,  1.81s/it]\rEvaluating:  34%|███▍      | 1226/3600 [09:56<1:08:02,  1.72s/it]\rEvaluating:  34%|███▍      | 1227/3600 [09:57<1:01:24,  1.55s/it]\rEvaluating:  34%|███▍      | 1228/3600 [09:59<1:05:06,  1.65s/it]\rEvaluating:  34%|███▍      | 1229/3600 [10:01<1:10:44,  1.79s/it]\rEvaluating:  34%|███▍      | 1230/3600 [10:03<1:13:11,  1.85s/it]\rEvaluating:  34%|███▍      | 1231/3600 [10:05<1:15:20,  1.91s/it]\rEvaluating:  34%|███▍      | 1232/3600 [10:07<1:11:12,  1.80s/it]\rEvaluating:  34%|███▍      | 1233/3600 [10:09<1:17:46,  1.97s/it]\rEvaluating:  34%|███▍      | 1234/3600 [10:10<1:07:45,  1.72s/it]\rEvaluating:  34%|███▍      | 1235/3600 [10:12<1:05:59,  1.67s/it]\rEvaluating:  34%|███▍      | 1236/3600 [10:14<1:09:50,  1.77s/it]\rEvaluating:  34%|███▍      | 1237/3600 [10:15<1:02:51,  1.60s/it]\rEvaluating:  34%|███▍      | 1238/3600 [10:16<57:00,  1.45s/it]  \rEvaluating:  34%|███▍      | 1239/3600 [10:18<1:00:22,  1.53s/it]\rEvaluating:  34%|███▍      | 1240/3600 [10:20<1:14:02,  1.88s/it]\rEvaluating:  34%|███▍      | 1241/3600 [10:22<1:11:31,  1.82s/it]\rEvaluating:  34%|███▍      | 1242/3600 [10:23<1:04:27,  1.64s/it]\rEvaluating:  35%|███▍      | 1243/3600 [10:25<1:01:17,  1.56s/it]\rEvaluating:  35%|███▍      | 1244/3600 [10:26<1:04:16,  1.64s/it]\rEvaluating:  35%|███▍      | 1245/3600 [10:29<1:11:00,  1.81s/it]\rEvaluating:  35%|███▍      | 1246/3600 [10:31<1:14:14,  1.89s/it]\rEvaluating:  35%|███▍      | 1247/3600 [10:33<1:16:38,  1.95s/it]\rEvaluating:  35%|███▍      | 1248/3600 [10:34<1:11:19,  1.82s/it]\rEvaluating:  35%|███▍      | 1249/3600 [10:35<1:02:38,  1.60s/it]\rEvaluating:  35%|███▍      | 1250/3600 [10:38<1:17:04,  1.97s/it]\rEvaluating:  35%|███▍      | 1251/3600 [10:41<1:22:32,  2.11s/it]\rEvaluating:  35%|███▍      | 1252/3600 [10:42<1:08:25,  1.75s/it]\rEvaluating:  35%|███▍      | 1253/3600 [10:43<1:08:23,  1.75s/it]\rEvaluating:  35%|███▍      | 1254/3600 [10:45<1:02:31,  1.60s/it]\rEvaluating:  35%|███▍      | 1255/3600 [10:46<1:05:12,  1.67s/it]\rEvaluating:  35%|███▍      | 1256/3600 [10:48<1:00:14,  1.54s/it]\rEvaluating:  35%|███▍      | 1257/3600 [10:50<1:13:05,  1.87s/it]\rEvaluating:  35%|███▍      | 1258/3600 [10:53<1:22:04,  2.10s/it]\rEvaluating:  35%|███▍      | 1259/3600 [10:54<1:15:01,  1.92s/it]\rEvaluating:  35%|███▌      | 1260/3600 [10:56<1:08:51,  1.77s/it]\rEvaluating:  35%|███▌      | 1261/3600 [10:58<1:08:52,  1.77s/it]\rEvaluating:  35%|███▌      | 1262/3600 [11:00<1:14:24,  1.91s/it]\rEvaluating:  35%|███▌      | 1263/3600 [11:02<1:12:22,  1.86s/it]\rEvaluating:  35%|███▌      | 1264/3600 [11:03<1:04:31,  1.66s/it]\rEvaluating:  35%|███▌      | 1265/3600 [11:04<1:00:03,  1.54s/it]\rEvaluating:  35%|███▌      | 1266/3600 [11:05<54:54,  1.41s/it]  \rEvaluating:  35%|███▌      | 1267/3600 [11:08<1:07:01,  1.72s/it]\rEvaluating:  35%|███▌      | 1268/3600 [11:09<1:05:34,  1.69s/it]\rEvaluating:  35%|███▌      | 1269/3600 [11:11<1:10:39,  1.82s/it]\rEvaluating:  35%|███▌      | 1270/3600 [11:14<1:16:11,  1.96s/it]\rEvaluating:  35%|███▌      | 1271/3600 [11:15<1:06:05,  1.70s/it]\rEvaluating:  35%|███▌      | 1272/3600 [11:17<1:07:02,  1.73s/it]\rEvaluating:  35%|███▌      | 1273/3600 [11:18<1:05:56,  1.70s/it]\rEvaluating:  35%|███▌      | 1274/3600 [11:20<1:06:13,  1.71s/it]\rEvaluating:  35%|███▌      | 1275/3600 [11:22<1:15:42,  1.95s/it]\rEvaluating:  35%|███▌      | 1276/3600 [11:24<1:05:48,  1.70s/it]\rEvaluating:  35%|███▌      | 1277/3600 [11:26<1:09:27,  1.79s/it]\rEvaluating:  36%|███▌      | 1278/3600 [11:27<1:03:06,  1.63s/it]\rEvaluating:  36%|███▌      | 1279/3600 [11:28<1:01:03,  1.58s/it]\rEvaluating:  36%|███▌      | 1280/3600 [11:30<1:06:39,  1.72s/it]\rEvaluating:  36%|███▌      | 1281/3600 [11:32<1:02:34,  1.62s/it]\rEvaluating:  36%|███▌      | 1282/3600 [11:33<58:41,  1.52s/it]  \rEvaluating:  36%|███▌      | 1283/3600 [11:34<53:28,  1.38s/it]\rEvaluating:  36%|███▌      | 1284/3600 [11:35<49:03,  1.27s/it]\rEvaluating:  36%|███▌      | 1285/3600 [11:37<1:02:26,  1.62s/it]\rEvaluating:  36%|███▌      | 1286/3600 [11:40<1:12:44,  1.89s/it]\rEvaluating:  36%|███▌      | 1287/3600 [11:42<1:14:15,  1.93s/it]\rEvaluating:  36%|███▌      | 1288/3600 [11:43<1:06:34,  1.73s/it]\rEvaluating:  36%|███▌      | 1289/3600 [11:45<1:09:14,  1.80s/it]\rEvaluating:  36%|███▌      | 1290/3600 [11:48<1:16:35,  1.99s/it]\rEvaluating:  36%|███▌      | 1291/3600 [11:49<1:13:01,  1.90s/it]\rEvaluating:  36%|███▌      | 1292/3600 [11:52<1:16:36,  1.99s/it]\rEvaluating:  36%|███▌      | 1293/3600 [11:53<1:11:10,  1.85s/it]\rEvaluating:  36%|███▌      | 1294/3600 [11:55<1:11:48,  1.87s/it]\rEvaluating:  36%|███▌      | 1295/3600 [11:56<1:03:05,  1.64s/it]\rEvaluating:  36%|███▌      | 1296/3600 [11:57<58:39,  1.53s/it]  \rEvaluating:  36%|███▌      | 1297/3600 [11:59<1:02:25,  1.63s/it]\rEvaluating:  36%|███▌      | 1298/3600 [12:02<1:10:54,  1.85s/it]\rEvaluating:  36%|███▌      | 1299/3600 [12:03<1:05:52,  1.72s/it]\rEvaluating:  36%|███▌      | 1300/3600 [12:04<1:02:49,  1.64s/it]2026-01-18 22:18:17,324 - INFO -     Accuracy: 69.00% (69/100)\n2026-01-18 22:18:17,324 - INFO -   Language: zh\n\rEvaluating:  36%|███▌      | 1301/3600 [12:06<1:00:48,  1.59s/it]\rEvaluating:  36%|███▌      | 1302/3600 [12:07<56:55,  1.49s/it]  \rEvaluating:  36%|███▌      | 1303/3600 [12:09<1:03:25,  1.66s/it]\rEvaluating:  36%|███▌      | 1304/3600 [12:11<59:45,  1.56s/it]  \rEvaluating:  36%|███▋      | 1305/3600 [12:12<53:35,  1.40s/it]\rEvaluating:  36%|███▋      | 1306/3600 [12:13<54:11,  1.42s/it]\rEvaluating:  36%|███▋      | 1307/3600 [12:15<58:54,  1.54s/it]\rEvaluating:  36%|███▋      | 1308/3600 [12:16<58:16,  1.53s/it]\rEvaluating:  36%|███▋      | 1309/3600 [12:18<55:40,  1.46s/it]\rEvaluating:  36%|███▋      | 1310/3600 [12:20<1:08:49,  1.80s/it]\rEvaluating:  36%|███▋      | 1311/3600 [12:23<1:21:20,  2.13s/it]\rEvaluating:  36%|███▋      | 1312/3600 [12:25<1:17:29,  2.03s/it]\rEvaluating:  36%|███▋      | 1313/3600 [12:27<1:19:56,  2.10s/it]\rEvaluating:  36%|███▋      | 1314/3600 [12:28<1:09:10,  1.82s/it]\rEvaluating:  37%|███▋      | 1315/3600 [12:30<1:01:26,  1.61s/it]\rEvaluating:  37%|███▋      | 1316/3600 [12:32<1:07:29,  1.77s/it]\rEvaluating:  37%|███▋      | 1317/3600 [12:34<1:17:03,  2.03s/it]\rEvaluating:  37%|███▋      | 1318/3600 [12:36<1:10:26,  1.85s/it]\rEvaluating:  37%|███▋      | 1319/3600 [12:38<1:17:33,  2.04s/it]\rEvaluating:  37%|███▋      | 1320/3600 [12:39<1:06:56,  1.76s/it]\rEvaluating:  37%|███▋      | 1321/3600 [12:41<1:08:30,  1.80s/it]\rEvaluating:  37%|███▋      | 1322/3600 [12:43<1:07:19,  1.77s/it]\rEvaluating:  37%|███▋      | 1323/3600 [12:44<1:02:42,  1.65s/it]\rEvaluating:  37%|███▋      | 1324/3600 [12:46<1:07:58,  1.79s/it]\rEvaluating:  37%|███▋      | 1325/3600 [12:49<1:11:36,  1.89s/it]\rEvaluating:  37%|███▋      | 1326/3600 [12:51<1:14:46,  1.97s/it]\rEvaluating:  37%|███▋      | 1327/3600 [12:53<1:14:11,  1.96s/it]\rEvaluating:  37%|███▋      | 1328/3600 [12:54<1:12:00,  1.90s/it]\rEvaluating:  37%|███▋      | 1329/3600 [12:57<1:19:11,  2.09s/it]\rEvaluating:  37%|███▋      | 1330/3600 [13:00<1:26:22,  2.28s/it]\rEvaluating:  37%|███▋      | 1331/3600 [13:01<1:16:38,  2.03s/it]\rEvaluating:  37%|███▋      | 1332/3600 [13:02<1:06:38,  1.76s/it]\rEvaluating:  37%|███▋      | 1333/3600 [13:05<1:16:42,  2.03s/it]\rEvaluating:  37%|███▋      | 1334/3600 [13:06<1:03:57,  1.69s/it]\rEvaluating:  37%|███▋      | 1335/3600 [13:08<1:09:37,  1.84s/it]\rEvaluating:  37%|███▋      | 1336/3600 [13:10<1:10:32,  1.87s/it]\rEvaluating:  37%|███▋      | 1337/3600 [13:11<1:00:14,  1.60s/it]\rEvaluating:  37%|███▋      | 1338/3600 [13:13<1:01:38,  1.63s/it]\rEvaluating:  37%|███▋      | 1339/3600 [13:15<1:07:40,  1.80s/it]\rEvaluating:  37%|███▋      | 1340/3600 [13:17<1:12:37,  1.93s/it]\rEvaluating:  37%|███▋      | 1341/3600 [13:18<1:06:52,  1.78s/it]\rEvaluating:  37%|███▋      | 1342/3600 [13:20<1:03:46,  1.69s/it]\rEvaluating:  37%|███▋      | 1343/3600 [13:22<1:05:47,  1.75s/it]\rEvaluating:  37%|███▋      | 1344/3600 [13:24<1:06:04,  1.76s/it]\rEvaluating:  37%|███▋      | 1345/3600 [13:26<1:11:55,  1.91s/it]\rEvaluating:  37%|███▋      | 1346/3600 [13:28<1:15:07,  2.00s/it]\rEvaluating:  37%|███▋      | 1347/3600 [13:30<1:15:31,  2.01s/it]\rEvaluating:  37%|███▋      | 1348/3600 [13:32<1:17:02,  2.05s/it]\rEvaluating:  37%|███▋      | 1349/3600 [13:33<1:06:03,  1.76s/it]\rEvaluating:  38%|███▊      | 1350/3600 [13:35<1:02:10,  1.66s/it]\rEvaluating:  38%|███▊      | 1351/3600 [13:36<1:00:28,  1.61s/it]\rEvaluating:  38%|███▊      | 1352/3600 [13:39<1:07:40,  1.81s/it]\rEvaluating:  38%|███▊      | 1353/3600 [13:41<1:11:25,  1.91s/it]\rEvaluating:  38%|███▊      | 1354/3600 [13:42<1:07:12,  1.80s/it]\rEvaluating:  38%|███▊      | 1355/3600 [13:43<56:58,  1.52s/it]  \rEvaluating:  38%|███▊      | 1356/3600 [13:44<52:41,  1.41s/it]\rEvaluating:  38%|███▊      | 1357/3600 [13:46<55:44,  1.49s/it]\rEvaluating:  38%|███▊      | 1358/3600 [13:47<52:55,  1.42s/it]\rEvaluating:  38%|███▊      | 1359/3600 [13:48<51:37,  1.38s/it]\rEvaluating:  38%|███▊      | 1360/3600 [13:50<58:58,  1.58s/it]\rEvaluating:  38%|███▊      | 1361/3600 [13:53<1:06:50,  1.79s/it]\rEvaluating:  38%|███▊      | 1362/3600 [13:54<1:01:29,  1.65s/it]\rEvaluating:  38%|███▊      | 1363/3600 [13:57<1:12:50,  1.95s/it]\rEvaluating:  38%|███▊      | 1364/3600 [13:58<1:01:17,  1.64s/it]\rEvaluating:  38%|███▊      | 1365/3600 [13:59<1:01:59,  1.66s/it]\rEvaluating:  38%|███▊      | 1366/3600 [14:00<55:28,  1.49s/it]  \rEvaluating:  38%|███▊      | 1367/3600 [14:02<54:33,  1.47s/it]\rEvaluating:  38%|███▊      | 1368/3600 [14:03<50:55,  1.37s/it]\rEvaluating:  38%|███▊      | 1369/3600 [14:04<51:32,  1.39s/it]\rEvaluating:  38%|███▊      | 1370/3600 [14:06<48:41,  1.31s/it]\rEvaluating:  38%|███▊      | 1371/3600 [14:07<45:48,  1.23s/it]\rEvaluating:  38%|███▊      | 1372/3600 [14:08<43:22,  1.17s/it]\rEvaluating:  38%|███▊      | 1373/3600 [14:09<42:10,  1.14s/it]\rEvaluating:  38%|███▊      | 1374/3600 [14:10<44:28,  1.20s/it]\rEvaluating:  38%|███▊      | 1375/3600 [14:11<43:41,  1.18s/it]\rEvaluating:  38%|███▊      | 1376/3600 [14:12<40:58,  1.11s/it]\rEvaluating:  38%|███▊      | 1377/3600 [14:13<40:30,  1.09s/it]\rEvaluating:  38%|███▊      | 1378/3600 [14:14<42:03,  1.14s/it]\rEvaluating:  38%|███▊      | 1379/3600 [14:17<53:15,  1.44s/it]\rEvaluating:  38%|███▊      | 1380/3600 [14:18<51:28,  1.39s/it]\rEvaluating:  38%|███▊      | 1381/3600 [14:20<58:21,  1.58s/it]\rEvaluating:  38%|███▊      | 1382/3600 [14:22<59:33,  1.61s/it]\rEvaluating:  38%|███▊      | 1383/3600 [14:23<1:01:34,  1.67s/it]\rEvaluating:  38%|███▊      | 1384/3600 [14:25<57:09,  1.55s/it]  \rEvaluating:  38%|███▊      | 1385/3600 [14:26<53:34,  1.45s/it]\rEvaluating:  38%|███▊      | 1386/3600 [14:28<58:51,  1.60s/it]\rEvaluating:  39%|███▊      | 1387/3600 [14:29<54:37,  1.48s/it]\rEvaluating:  39%|███▊      | 1388/3600 [14:30<51:43,  1.40s/it]\rEvaluating:  39%|███▊      | 1389/3600 [14:31<48:15,  1.31s/it]\rEvaluating:  39%|███▊      | 1390/3600 [14:33<47:38,  1.29s/it]\rEvaluating:  39%|███▊      | 1391/3600 [14:34<54:00,  1.47s/it]\rEvaluating:  39%|███▊      | 1392/3600 [14:36<59:33,  1.62s/it]\rEvaluating:  39%|███▊      | 1393/3600 [14:40<1:18:10,  2.13s/it]\rEvaluating:  39%|███▊      | 1394/3600 [14:41<1:08:44,  1.87s/it]\rEvaluating:  39%|███▉      | 1395/3600 [14:42<58:16,  1.59s/it]  \rEvaluating:  39%|███▉      | 1396/3600 [14:45<1:10:52,  1.93s/it]\rEvaluating:  39%|███▉      | 1397/3600 [14:46<1:06:57,  1.82s/it]\rEvaluating:  39%|███▉      | 1398/3600 [14:48<1:07:41,  1.84s/it]\rEvaluating:  39%|███▉      | 1399/3600 [14:49<1:01:34,  1.68s/it]\rEvaluating:  39%|███▉      | 1400/3600 [14:52<1:13:11,  2.00s/it]2026-01-18 22:21:05,015 - INFO -     Accuracy: 59.00% (59/100)\n2026-01-18 22:21:05,016 - INFO -   Language: es\n\rEvaluating:  39%|███▉      | 1401/3600 [14:53<1:03:42,  1.74s/it]\rEvaluating:  39%|███▉      | 1402/3600 [14:55<59:12,  1.62s/it]  \rEvaluating:  39%|███▉      | 1403/3600 [14:57<1:02:42,  1.71s/it]\rEvaluating:  39%|███▉      | 1404/3600 [14:59<1:05:50,  1.80s/it]\rEvaluating:  39%|███▉      | 1405/3600 [14:59<56:09,  1.54s/it]  \rEvaluating:  39%|███▉      | 1406/3600 [15:01<53:25,  1.46s/it]\rEvaluating:  39%|███▉      | 1407/3600 [15:02<53:07,  1.45s/it]\rEvaluating:  39%|███▉      | 1408/3600 [15:03<50:31,  1.38s/it]\rEvaluating:  39%|███▉      | 1409/3600 [15:06<1:01:57,  1.70s/it]\rEvaluating:  39%|███▉      | 1410/3600 [15:08<1:06:23,  1.82s/it]\rEvaluating:  39%|███▉      | 1411/3600 [15:09<59:04,  1.62s/it]  \rEvaluating:  39%|███▉      | 1412/3600 [15:10<55:38,  1.53s/it]\rEvaluating:  39%|███▉      | 1413/3600 [15:12<52:10,  1.43s/it]\rEvaluating:  39%|███▉      | 1414/3600 [15:13<56:31,  1.55s/it]\rEvaluating:  39%|███▉      | 1415/3600 [15:16<1:06:27,  1.82s/it]\rEvaluating:  39%|███▉      | 1416/3600 [15:18<1:09:50,  1.92s/it]\rEvaluating:  39%|███▉      | 1417/3600 [15:20<1:06:17,  1.82s/it]\rEvaluating:  39%|███▉      | 1418/3600 [15:21<57:53,  1.59s/it]  \rEvaluating:  39%|███▉      | 1419/3600 [15:23<1:01:54,  1.70s/it]\rEvaluating:  39%|███▉      | 1420/3600 [15:24<1:00:36,  1.67s/it]\rEvaluating:  39%|███▉      | 1421/3600 [15:26<1:03:43,  1.75s/it]\rEvaluating:  40%|███▉      | 1422/3600 [15:29<1:10:13,  1.93s/it]\rEvaluating:  40%|███▉      | 1423/3600 [15:30<1:07:29,  1.86s/it]\rEvaluating:  40%|███▉      | 1424/3600 [15:32<1:09:49,  1.93s/it]\rEvaluating:  40%|███▉      | 1425/3600 [15:33<1:00:59,  1.68s/it]\rEvaluating:  40%|███▉      | 1426/3600 [15:35<54:20,  1.50s/it]  \rEvaluating:  40%|███▉      | 1427/3600 [15:36<51:00,  1.41s/it]\rEvaluating:  40%|███▉      | 1428/3600 [15:37<51:35,  1.42s/it]\rEvaluating:  40%|███▉      | 1429/3600 [15:38<48:45,  1.35s/it]\rEvaluating:  40%|███▉      | 1430/3600 [15:39<44:08,  1.22s/it]\rEvaluating:  40%|███▉      | 1431/3600 [15:41<54:37,  1.51s/it]\rEvaluating:  40%|███▉      | 1432/3600 [15:44<1:05:28,  1.81s/it]\rEvaluating:  40%|███▉      | 1433/3600 [15:45<1:00:01,  1.66s/it]\rEvaluating:  40%|███▉      | 1434/3600 [15:47<1:01:14,  1.70s/it]\rEvaluating:  40%|███▉      | 1435/3600 [15:48<56:55,  1.58s/it]  \rEvaluating:  40%|███▉      | 1436/3600 [15:50<54:20,  1.51s/it]\rEvaluating:  40%|███▉      | 1437/3600 [15:51<54:37,  1.52s/it]\rEvaluating:  40%|███▉      | 1438/3600 [15:52<48:47,  1.35s/it]\rEvaluating:  40%|███▉      | 1439/3600 [15:54<49:55,  1.39s/it]\rEvaluating:  40%|████      | 1440/3600 [15:55<50:01,  1.39s/it]\rEvaluating:  40%|████      | 1441/3600 [15:57<58:41,  1.63s/it]\rEvaluating:  40%|████      | 1442/3600 [15:59<59:11,  1.65s/it]\rEvaluating:  40%|████      | 1443/3600 [16:00<57:44,  1.61s/it]\rEvaluating:  40%|████      | 1444/3600 [16:02<57:59,  1.61s/it]\rEvaluating:  40%|████      | 1445/3600 [16:03<54:27,  1.52s/it]\rEvaluating:  40%|████      | 1446/3600 [16:05<52:20,  1.46s/it]\rEvaluating:  40%|████      | 1447/3600 [16:06<53:13,  1.48s/it]\rEvaluating:  40%|████      | 1448/3600 [16:08<55:15,  1.54s/it]\rEvaluating:  40%|████      | 1449/3600 [16:10<1:02:38,  1.75s/it]\rEvaluating:  40%|████      | 1450/3600 [16:12<1:06:30,  1.86s/it]\rEvaluating:  40%|████      | 1451/3600 [16:14<1:08:50,  1.92s/it]\rEvaluating:  40%|████      | 1452/3600 [16:16<1:03:34,  1.78s/it]\rEvaluating:  40%|████      | 1453/3600 [16:17<59:00,  1.65s/it]  \rEvaluating:  40%|████      | 1454/3600 [16:18<50:37,  1.42s/it]\rEvaluating:  40%|████      | 1455/3600 [16:20<55:44,  1.56s/it]\rEvaluating:  40%|████      | 1456/3600 [16:21<52:14,  1.46s/it]\rEvaluating:  40%|████      | 1457/3600 [16:23<58:53,  1.65s/it]\rEvaluating:  40%|████      | 1458/3600 [16:24<54:06,  1.52s/it]\rEvaluating:  41%|████      | 1459/3600 [16:26<53:00,  1.49s/it]\rEvaluating:  41%|████      | 1460/3600 [16:27<50:19,  1.41s/it]\rEvaluating:  41%|████      | 1461/3600 [16:28<47:09,  1.32s/it]\rEvaluating:  41%|████      | 1462/3600 [16:29<46:19,  1.30s/it]\rEvaluating:  41%|████      | 1463/3600 [16:31<45:02,  1.26s/it]\rEvaluating:  41%|████      | 1464/3600 [16:33<58:59,  1.66s/it]\rEvaluating:  41%|████      | 1465/3600 [16:34<52:58,  1.49s/it]\rEvaluating:  41%|████      | 1466/3600 [16:35<48:11,  1.35s/it]\rEvaluating:  41%|████      | 1467/3600 [16:37<56:29,  1.59s/it]\rEvaluating:  41%|████      | 1468/3600 [16:39<53:07,  1.49s/it]\rEvaluating:  41%|████      | 1469/3600 [16:40<55:18,  1.56s/it]\rEvaluating:  41%|████      | 1470/3600 [16:41<48:56,  1.38s/it]\rEvaluating:  41%|████      | 1471/3600 [16:43<51:11,  1.44s/it]\rEvaluating:  41%|████      | 1472/3600 [16:45<59:38,  1.68s/it]\rEvaluating:  41%|████      | 1473/3600 [16:47<56:07,  1.58s/it]\rEvaluating:  41%|████      | 1474/3600 [16:49<1:06:44,  1.88s/it]\rEvaluating:  41%|████      | 1475/3600 [16:51<1:01:26,  1.74s/it]\rEvaluating:  41%|████      | 1476/3600 [16:52<58:37,  1.66s/it]  \rEvaluating:  41%|████      | 1477/3600 [16:53<53:42,  1.52s/it]\rEvaluating:  41%|████      | 1478/3600 [16:54<48:18,  1.37s/it]\rEvaluating:  41%|████      | 1479/3600 [16:56<47:42,  1.35s/it]\rEvaluating:  41%|████      | 1480/3600 [16:58<55:03,  1.56s/it]\rEvaluating:  41%|████      | 1481/3600 [16:59<51:53,  1.47s/it]\rEvaluating:  41%|████      | 1482/3600 [17:01<58:19,  1.65s/it]\rEvaluating:  41%|████      | 1483/3600 [17:03<1:03:41,  1.81s/it]\rEvaluating:  41%|████      | 1484/3600 [17:06<1:13:30,  2.08s/it]\rEvaluating:  41%|████▏     | 1485/3600 [17:07<1:03:44,  1.81s/it]\rEvaluating:  41%|████▏     | 1486/3600 [17:09<1:04:46,  1.84s/it]\rEvaluating:  41%|████▏     | 1487/3600 [17:10<59:17,  1.68s/it]  \rEvaluating:  41%|████▏     | 1488/3600 [17:12<1:03:09,  1.79s/it]\rEvaluating:  41%|████▏     | 1489/3600 [17:14<1:03:59,  1.82s/it]\rEvaluating:  41%|████▏     | 1490/3600 [17:16<59:41,  1.70s/it]  \rEvaluating:  41%|████▏     | 1491/3600 [17:17<59:15,  1.69s/it]\rEvaluating:  41%|████▏     | 1492/3600 [17:19<1:02:56,  1.79s/it]\rEvaluating:  41%|████▏     | 1493/3600 [17:21<58:48,  1.67s/it]  \rEvaluating:  42%|████▏     | 1494/3600 [17:22<50:55,  1.45s/it]\rEvaluating:  42%|████▏     | 1495/3600 [17:23<49:05,  1.40s/it]\rEvaluating:  42%|████▏     | 1496/3600 [17:24<50:15,  1.43s/it]\rEvaluating:  42%|████▏     | 1497/3600 [17:26<53:36,  1.53s/it]\rEvaluating:  42%|████▏     | 1498/3600 [17:28<54:45,  1.56s/it]\rEvaluating:  42%|████▏     | 1499/3600 [17:29<55:07,  1.57s/it]\rEvaluating:  42%|████▏     | 1500/3600 [17:31<58:16,  1.66s/it]2026-01-18 22:23:44,127 - INFO -     Accuracy: 54.00% (54/100)\n2026-01-18 22:23:44,128 - INFO -   Language: fr\n\rEvaluating:  42%|████▏     | 1501/3600 [17:33<1:02:46,  1.79s/it]\rEvaluating:  42%|████▏     | 1502/3600 [17:35<1:01:35,  1.76s/it]\rEvaluating:  42%|████▏     | 1503/3600 [17:36<54:12,  1.55s/it]  \rEvaluating:  42%|████▏     | 1504/3600 [17:37<48:02,  1.38s/it]\rEvaluating:  42%|████▏     | 1505/3600 [17:40<1:00:34,  1.73s/it]\rEvaluating:  42%|████▏     | 1506/3600 [17:41<54:25,  1.56s/it]  \rEvaluating:  42%|████▏     | 1507/3600 [17:42<48:54,  1.40s/it]\rEvaluating:  42%|████▏     | 1508/3600 [17:43<45:17,  1.30s/it]\rEvaluating:  42%|████▏     | 1509/3600 [17:44<44:46,  1.28s/it]\rEvaluating:  42%|████▏     | 1510/3600 [17:45<44:01,  1.26s/it]\rEvaluating:  42%|████▏     | 1511/3600 [17:47<49:24,  1.42s/it]\rEvaluating:  42%|████▏     | 1512/3600 [17:49<52:21,  1.50s/it]\rEvaluating:  42%|████▏     | 1513/3600 [17:50<49:15,  1.42s/it]\rEvaluating:  42%|████▏     | 1514/3600 [17:52<56:09,  1.62s/it]\rEvaluating:  42%|████▏     | 1515/3600 [17:54<54:14,  1.56s/it]\rEvaluating:  42%|████▏     | 1516/3600 [17:55<52:53,  1.52s/it]\rEvaluating:  42%|████▏     | 1517/3600 [17:56<48:17,  1.39s/it]\rEvaluating:  42%|████▏     | 1518/3600 [17:59<59:40,  1.72s/it]\rEvaluating:  42%|████▏     | 1519/3600 [18:00<57:08,  1.65s/it]\rEvaluating:  42%|████▏     | 1520/3600 [18:01<54:32,  1.57s/it]\rEvaluating:  42%|████▏     | 1521/3600 [18:03<49:22,  1.43s/it]\rEvaluating:  42%|████▏     | 1522/3600 [18:04<52:04,  1.50s/it]\rEvaluating:  42%|████▏     | 1523/3600 [18:08<1:10:51,  2.05s/it]\rEvaluating:  42%|████▏     | 1524/3600 [18:09<1:03:23,  1.83s/it]\rEvaluating:  42%|████▏     | 1525/3600 [18:10<56:24,  1.63s/it]  \rEvaluating:  42%|████▏     | 1526/3600 [18:12<1:00:37,  1.75s/it]\rEvaluating:  42%|████▏     | 1527/3600 [18:13<55:59,  1.62s/it]  \rEvaluating:  42%|████▏     | 1528/3600 [18:15<52:48,  1.53s/it]\rEvaluating:  42%|████▏     | 1529/3600 [18:17<57:45,  1.67s/it]\rEvaluating:  42%|████▎     | 1530/3600 [18:18<52:15,  1.51s/it]\rEvaluating:  43%|████▎     | 1531/3600 [18:20<54:14,  1.57s/it]\rEvaluating:  43%|████▎     | 1532/3600 [18:22<1:04:08,  1.86s/it]\rEvaluating:  43%|████▎     | 1533/3600 [18:24<1:08:09,  1.98s/it]\rEvaluating:  43%|████▎     | 1534/3600 [18:26<1:09:25,  2.02s/it]\rEvaluating:  43%|████▎     | 1535/3600 [18:29<1:10:46,  2.06s/it]\rEvaluating:  43%|████▎     | 1536/3600 [18:31<1:10:14,  2.04s/it]\rEvaluating:  43%|████▎     | 1537/3600 [18:32<1:00:26,  1.76s/it]\rEvaluating:  43%|████▎     | 1538/3600 [18:33<56:42,  1.65s/it]  \rEvaluating:  43%|████▎     | 1539/3600 [18:35<1:00:10,  1.75s/it]\rEvaluating:  43%|████▎     | 1540/3600 [18:37<1:03:38,  1.85s/it]\rEvaluating:  43%|████▎     | 1541/3600 [18:40<1:08:57,  2.01s/it]\rEvaluating:  43%|████▎     | 1542/3600 [18:41<1:03:26,  1.85s/it]\rEvaluating:  43%|████▎     | 1543/3600 [18:42<55:17,  1.61s/it]  \rEvaluating:  43%|████▎     | 1544/3600 [18:45<1:07:16,  1.96s/it]\rEvaluating:  43%|████▎     | 1545/3600 [18:47<1:04:40,  1.89s/it]\rEvaluating:  43%|████▎     | 1546/3600 [18:49<1:13:24,  2.14s/it]\rEvaluating:  43%|████▎     | 1547/3600 [18:51<1:05:09,  1.90s/it]\rEvaluating:  43%|████▎     | 1548/3600 [18:53<1:09:29,  2.03s/it]\rEvaluating:  43%|████▎     | 1549/3600 [18:55<1:10:36,  2.07s/it]\rEvaluating:  43%|████▎     | 1550/3600 [18:57<1:07:43,  1.98s/it]\rEvaluating:  43%|████▎     | 1551/3600 [18:58<59:54,  1.75s/it]  \rEvaluating:  43%|████▎     | 1552/3600 [19:00<58:25,  1.71s/it]\rEvaluating:  43%|████▎     | 1553/3600 [19:02<1:04:03,  1.88s/it]\rEvaluating:  43%|████▎     | 1554/3600 [19:04<1:03:26,  1.86s/it]\rEvaluating:  43%|████▎     | 1555/3600 [19:06<1:04:13,  1.88s/it]\rEvaluating:  43%|████▎     | 1556/3600 [19:08<1:04:27,  1.89s/it]\rEvaluating:  43%|████▎     | 1557/3600 [19:09<55:41,  1.64s/it]  \rEvaluating:  43%|████▎     | 1558/3600 [19:11<58:08,  1.71s/it]\rEvaluating:  43%|████▎     | 1559/3600 [19:12<51:36,  1.52s/it]\rEvaluating:  43%|████▎     | 1560/3600 [19:13<51:26,  1.51s/it]\rEvaluating:  43%|████▎     | 1561/3600 [19:15<51:18,  1.51s/it]\rEvaluating:  43%|████▎     | 1562/3600 [19:16<50:25,  1.48s/it]\rEvaluating:  43%|████▎     | 1563/3600 [19:19<1:02:50,  1.85s/it]\rEvaluating:  43%|████▎     | 1564/3600 [19:20<58:16,  1.72s/it]  \rEvaluating:  43%|████▎     | 1565/3600 [19:22<1:03:23,  1.87s/it]\rEvaluating:  44%|████▎     | 1566/3600 [19:24<1:00:00,  1.77s/it]\rEvaluating:  44%|████▎     | 1567/3600 [19:26<1:01:14,  1.81s/it]\rEvaluating:  44%|████▎     | 1568/3600 [19:27<55:37,  1.64s/it]  \rEvaluating:  44%|████▎     | 1569/3600 [19:29<53:22,  1.58s/it]\rEvaluating:  44%|████▎     | 1570/3600 [19:30<51:10,  1.51s/it]\rEvaluating:  44%|████▎     | 1571/3600 [19:32<1:01:46,  1.83s/it]\rEvaluating:  44%|████▎     | 1572/3600 [19:35<1:06:04,  1.95s/it]\rEvaluating:  44%|████▎     | 1573/3600 [19:38<1:14:56,  2.22s/it]\rEvaluating:  44%|████▎     | 1574/3600 [19:39<1:05:41,  1.95s/it]\rEvaluating:  44%|████▍     | 1575/3600 [19:41<1:03:55,  1.89s/it]\rEvaluating:  44%|████▍     | 1576/3600 [19:42<53:54,  1.60s/it]  \rEvaluating:  44%|████▍     | 1577/3600 [19:43<52:15,  1.55s/it]\rEvaluating:  44%|████▍     | 1578/3600 [19:44<46:38,  1.38s/it]\rEvaluating:  44%|████▍     | 1579/3600 [19:45<43:04,  1.28s/it]\rEvaluating:  44%|████▍     | 1580/3600 [19:46<43:07,  1.28s/it]\rEvaluating:  44%|████▍     | 1581/3600 [19:48<49:35,  1.47s/it]\rEvaluating:  44%|████▍     | 1582/3600 [19:49<44:12,  1.31s/it]\rEvaluating:  44%|████▍     | 1583/3600 [19:51<53:26,  1.59s/it]\rEvaluating:  44%|████▍     | 1584/3600 [19:53<48:39,  1.45s/it]\rEvaluating:  44%|████▍     | 1585/3600 [19:54<47:41,  1.42s/it]\rEvaluating:  44%|████▍     | 1586/3600 [19:55<45:28,  1.35s/it]\rEvaluating:  44%|████▍     | 1587/3600 [19:56<45:12,  1.35s/it]\rEvaluating:  44%|████▍     | 1588/3600 [19:58<50:36,  1.51s/it]\rEvaluating:  44%|████▍     | 1589/3600 [19:59<46:36,  1.39s/it]\rEvaluating:  44%|████▍     | 1590/3600 [20:01<44:26,  1.33s/it]\rEvaluating:  44%|████▍     | 1591/3600 [20:02<49:11,  1.47s/it]\n</output>"}]},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"7e070fee-b438-4bfc-be66-13aaeadbdc89","tool_use_result":{"retrieval_status":"timeout","task":{"task_id":"b035253","task_type":"local_bash","status":"running","description":"Run evaluation with reduced sample size","output":"2026-01-18 22:05:48,144 - INFO - ============================================================\n2026-01-18 22:05:48,144 - INFO - Multilingual LLM Evaluation Starting\n2026-01-18 22:05:48,144 - INFO - Seed: 42\n2026-01-18 22:05:48,144 - INFO - Languages: ['en', 'zh', 'es', 'fr', 'ar', 'ko', 'vi', 'id', 'bn', 'te', 'sw', 'ta']\n2026-01-18 22:05:48,144 - INFO - Models: ['gpt-4o', 'claude-sonnet-4.5', 'gemini-3-flash']\n2026-01-18 22:05:48,145 - INFO - Sample size per language: 100\n2026-01-18 22:05:48,145 - INFO - ============================================================\n2026-01-18 22:05:48,145 - INFO - Loading datasets...\n2026-01-18 22:05:48,145 - INFO - Loading MuBench MMLU for language: en (config: MMLUDataset_en_template_en)\n2026-01-18 22:05:48,287 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:48,294 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:48,338 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:48,424 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:49,399 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/revision/b59e353548c14c68701ec8eb56137aa7a8678d46 \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:49,546 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:50,126 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,539 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/tree/b59e353548c14c68701ec8eb56137aa7a8678d46/SNLIDataset?recursive=false&expand=false \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,684 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:50,840 - INFO - HTTP Request: GET https://huggingface.co/api/datasets/aialt/MuBench/tree/b59e353548c14c68701ec8eb56137aa7a8678d46/MMLUDataset?recursive=false&expand=false \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:50,869 - INFO - Loaded 100 questions for en (from 12338 total)\n2026-01-18 22:05:50,870 - INFO - Loading MuBench MMLU for language: zh (config: MMLUDataset_en_template_zh)\n2026-01-18 22:05:51,003 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:51,011 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:51,054 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:51,082 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,020 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,550 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:52,794 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,814 - INFO - Loaded 100 questions for zh (from 12338 total)\n2026-01-18 22:05:52,815 - INFO - Loading MuBench MMLU for language: es (config: MMLUDataset_en_template_es)\n2026-01-18 22:05:52,852 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:52,860 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:52,898 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:52,925 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:53,865 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,354 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:54,596 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,617 - INFO - Loaded 100 questions for es (from 12338 total)\n2026-01-18 22:05:54,618 - INFO - Loading MuBench MMLU for language: fr (config: MMLUDataset_en_template_fr)\n2026-01-18 22:05:54,658 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:54,664 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:54,715 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:54,743 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:55,698 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,218 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:56,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,482 - INFO - Loaded 100 questions for fr (from 12338 total)\n2026-01-18 22:05:56,483 - INFO - Loading MuBench MMLU for language: ar (config: MMLUDataset_en_template_ar)\n2026-01-18 22:05:56,521 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:56,529 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:56,567 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:56,596 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:57,579 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,104 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:58,362 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,382 - INFO - Loaded 100 questions for ar (from 12338 total)\n2026-01-18 22:05:58,383 - INFO - Loading MuBench MMLU for language: ko (config: MMLUDataset_en_template_ko)\n2026-01-18 22:05:58,422 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:05:58,429 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:05:58,466 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:58,494 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:59,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:05:59,988 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:00,295 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:00,320 - INFO - Loaded 100 questions for ko (from 12338 total)\n2026-01-18 22:06:00,320 - INFO - Loading MuBench MMLU for language: vi (config: MMLUDataset_en_template_vi)\n2026-01-18 22:06:00,362 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:00,369 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:00,404 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:00,433 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:01,461 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:02,027 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:02,373 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-01-18 22:06:02,374 - WARNING - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n2026-01-18 22:06:02,398 - INFO - Loaded 100 questions for vi (from 12338 total)\n2026-01-18 22:06:02,398 - INFO - Loading MuBench MMLU for language: id (config: MMLUDataset_en_template_id)\n2026-01-18 22:06:02,438 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:02,445 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:02,482 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:02,509 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:03,562 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,073 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:04,417 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,439 - INFO - Loaded 100 questions for id (from 12338 total)\n2026-01-18 22:06:04,440 - INFO - Loading MuBench MMLU for language: bn (config: MMLUDataset_en_template_bn)\n2026-01-18 22:06:04,476 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:04,483 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:04,520 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:04,550 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:05,588 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,073 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:06,258 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,282 - INFO - Loaded 100 questions for bn (from 12338 total)\n2026-01-18 22:06:06,283 - INFO - Loading MuBench MMLU for language: te (config: MMLUDataset_en_template_te)\n2026-01-18 22:06:06,325 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:06,333 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:06,374 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:06,402 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:07,586 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,130 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:08,309 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,331 - INFO - Loaded 100 questions for te (from 12338 total)\n2026-01-18 22:06:08,332 - INFO - Loading MuBench MMLU for language: sw (config: MMLUDataset_en_template_sw)\n2026-01-18 22:06:08,370 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:08,378 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:08,417 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:08,445 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:09,476 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,005 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:10,319 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,341 - INFO - Loaded 100 questions for sw (from 12338 total)\n2026-01-18 22:06:10,342 - INFO - Loading MuBench MMLU for language: ta (config: MMLUDataset_en_template_ta)\n2026-01-18 22:06:10,379 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n2026-01-18 22:06:10,387 - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/aialt/MuBench/b59e353548c14c68701ec8eb56137aa7a8678d46/README.md \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:10,426 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:10,454 - INFO - HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/aialt/MuBench/aialt/MuBench.py \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:11,452 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:11,958 - INFO - HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=aialt/MuBench \"HTTP/1.1 200 OK\"\n2026-01-18 22:06:12,249 - INFO - HTTP Request: HEAD https://huggingface.co/datasets/aialt/MuBench/resolve/b59e353548c14c68701ec8eb56137aa7a8678d46/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n2026-01-18 22:06:12,271 - INFO - Loaded 100 questions for ta (from 12338 total)\n\rEvaluating:   0%|          | 0/3600 [00:00<?, ?it/s]2026-01-18 22:06:12,273 - INFO - \nEvaluating model: gpt-4o\n2026-01-18 22:06:12,273 - INFO -   Language: en\n2026-01-18 22:06:12,761 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 1/3600 [00:00<29:41,  2.02it/s]2026-01-18 22:06:13,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 2/3600 [00:00<26:21,  2.27it/s]2026-01-18 22:06:13,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 3/3600 [00:01<27:27,  2.18it/s]2026-01-18 22:06:13,984 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 4/3600 [00:01<24:40,  2.43it/s]2026-01-18 22:06:14,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 5/3600 [00:02<24:17,  2.47it/s]2026-01-18 22:06:14,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 6/3600 [00:02<24:18,  2.46it/s]2026-01-18 22:06:15,199 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 7/3600 [00:02<24:22,  2.46it/s]2026-01-18 22:06:15,627 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 8/3600 [00:03<24:45,  2.42it/s]2026-01-18 22:06:16,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 9/3600 [00:03<24:08,  2.48it/s]2026-01-18 22:06:16,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 10/3600 [00:04<23:20,  2.56it/s]2026-01-18 22:06:16,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 11/3600 [00:04<23:09,  2.58it/s]2026-01-18 22:06:17,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 12/3600 [00:04<23:49,  2.51it/s]2026-01-18 22:06:17,653 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 13/3600 [00:05<25:22,  2.36it/s]2026-01-18 22:06:18,097 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 14/3600 [00:05<25:39,  2.33it/s]2026-01-18 22:06:18,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 15/3600 [00:06<25:36,  2.33it/s]2026-01-18 22:06:18,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 16/3600 [00:06<25:24,  2.35it/s]2026-01-18 22:06:19,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 17/3600 [00:07<26:31,  2.25it/s]2026-01-18 22:06:19,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   0%|          | 18/3600 [00:07<25:02,  2.38it/s]2026-01-18 22:06:20,198 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 19/3600 [00:07<25:01,  2.38it/s]2026-01-18 22:06:20,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 20/3600 [00:08<24:03,  2.48it/s]2026-01-18 22:06:20,984 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 21/3600 [00:08<24:08,  2.47it/s]2026-01-18 22:06:21,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 22/3600 [00:09<24:29,  2.43it/s]2026-01-18 22:06:21,914 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 23/3600 [00:09<26:10,  2.28it/s]2026-01-18 22:06:22,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 24/3600 [00:10<25:11,  2.37it/s]2026-01-18 22:06:22,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 25/3600 [00:10<23:35,  2.53it/s]2026-01-18 22:06:23,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 26/3600 [00:11<28:20,  2.10it/s]2026-01-18 22:06:23,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 27/3600 [00:11<27:32,  2.16it/s]2026-01-18 22:06:24,214 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 28/3600 [00:11<27:59,  2.13it/s]2026-01-18 22:06:24,678 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 29/3600 [00:12<27:56,  2.13it/s]2026-01-18 22:06:25,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 30/3600 [00:12<26:28,  2.25it/s]2026-01-18 22:06:25,466 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 31/3600 [00:13<25:40,  2.32it/s]2026-01-18 22:06:25,945 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 32/3600 [00:13<26:26,  2.25it/s]2026-01-18 22:06:26,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 33/3600 [00:14<25:22,  2.34it/s]2026-01-18 22:06:26,680 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 34/3600 [00:14<24:00,  2.47it/s]2026-01-18 22:06:27,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 35/3600 [00:14<26:59,  2.20it/s]2026-01-18 22:06:27,699 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 36/3600 [00:15<26:50,  2.21it/s]2026-01-18 22:06:28,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 37/3600 [00:15<27:39,  2.15it/s]2026-01-18 22:06:28,619 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 38/3600 [00:16<26:53,  2.21it/s]2026-01-18 22:06:29,014 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 39/3600 [00:16<25:58,  2.28it/s]2026-01-18 22:06:29,493 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 40/3600 [00:17<26:43,  2.22it/s]2026-01-18 22:06:29,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 41/3600 [00:17<25:38,  2.31it/s]2026-01-18 22:06:30,288 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 42/3600 [00:18<25:03,  2.37it/s]2026-01-18 22:06:30,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 43/3600 [00:18<25:34,  2.32it/s]2026-01-18 22:06:31,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|          | 44/3600 [00:18<26:14,  2.26it/s]2026-01-18 22:06:31,635 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 45/3600 [00:19<25:58,  2.28it/s]2026-01-18 22:06:32,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 46/3600 [00:19<25:22,  2.33it/s]2026-01-18 22:06:32,459 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 47/3600 [00:20<25:04,  2.36it/s]2026-01-18 22:06:32,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 48/3600 [00:20<25:03,  2.36it/s]2026-01-18 22:06:33,371 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 49/3600 [00:21<26:16,  2.25it/s]2026-01-18 22:06:33,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 50/3600 [00:21<25:02,  2.36it/s]2026-01-18 22:06:34,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 51/3600 [00:21<25:05,  2.36it/s]2026-01-18 22:06:34,536 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 52/3600 [00:22<23:56,  2.47it/s]2026-01-18 22:06:35,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   1%|▏         | 53/3600 [00:22<26:00,  2.27it/s]2026-01-18 22:06:35,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 54/3600 [00:23<25:15,  2.34it/s]2026-01-18 22:06:35,892 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 55/3600 [00:23<25:27,  2.32it/s]2026-01-18 22:06:36,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 56/3600 [00:24<26:30,  2.23it/s]2026-01-18 22:06:36,768 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 57/3600 [00:24<25:24,  2.32it/s]2026-01-18 22:06:37,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 58/3600 [00:24<26:17,  2.24it/s]2026-01-18 22:06:37,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 59/3600 [00:25<27:41,  2.13it/s]2026-01-18 22:06:38,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 60/3600 [00:25<27:23,  2.15it/s]2026-01-18 22:06:38,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 61/3600 [00:26<25:49,  2.28it/s]2026-01-18 22:06:38,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 62/3600 [00:26<24:52,  2.37it/s]2026-01-18 22:06:39,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 63/3600 [00:27<25:13,  2.34it/s]2026-01-18 22:06:39,865 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 64/3600 [00:27<25:17,  2.33it/s]2026-01-18 22:06:40,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 65/3600 [00:27<24:37,  2.39it/s]2026-01-18 22:06:40,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 66/3600 [00:28<23:55,  2.46it/s]2026-01-18 22:06:41,010 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 67/3600 [00:28<23:32,  2.50it/s]2026-01-18 22:06:41,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 68/3600 [00:29<24:32,  2.40it/s]2026-01-18 22:06:41,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 69/3600 [00:29<25:51,  2.28it/s]2026-01-18 22:06:42,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 70/3600 [00:30<25:37,  2.30it/s]2026-01-18 22:06:42,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 71/3600 [00:30<25:59,  2.26it/s]2026-01-18 22:06:43,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 72/3600 [00:31<27:24,  2.15it/s]2026-01-18 22:06:43,817 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 73/3600 [00:31<26:59,  2.18it/s]2026-01-18 22:06:44,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 74/3600 [00:31<26:12,  2.24it/s]2026-01-18 22:06:44,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 75/3600 [00:32<25:28,  2.31it/s]2026-01-18 22:06:45,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 76/3600 [00:32<24:37,  2.38it/s]2026-01-18 22:06:45,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 77/3600 [00:33<27:03,  2.17it/s]2026-01-18 22:06:45,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 78/3600 [00:33<25:39,  2.29it/s]2026-01-18 22:06:46,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 79/3600 [00:34<24:23,  2.41it/s]2026-01-18 22:06:46,716 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 80/3600 [00:34<23:52,  2.46it/s]2026-01-18 22:06:47,105 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 81/3600 [00:34<23:35,  2.49it/s]2026-01-18 22:06:47,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 82/3600 [00:35<23:05,  2.54it/s]2026-01-18 22:06:47,834 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 83/3600 [00:35<22:25,  2.61it/s]2026-01-18 22:06:48,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 84/3600 [00:35<22:29,  2.61it/s]2026-01-18 22:06:48,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 85/3600 [00:36<23:53,  2.45it/s]2026-01-18 22:06:49,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 86/3600 [00:36<26:11,  2.24it/s]2026-01-18 22:06:49,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 87/3600 [00:37<25:49,  2.27it/s]2026-01-18 22:06:50,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 88/3600 [00:37<25:40,  2.28it/s]2026-01-18 22:06:50,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▏         | 89/3600 [00:38<25:35,  2.29it/s]2026-01-18 22:06:50,903 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   2%|▎         | 90/3600 [00:38<24:44,  2.36it/s]2026-01-18 22:06:51,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 91/3600 [00:39<23:41,  2.47it/s]2026-01-18 22:06:51,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 92/3600 [00:39<24:36,  2.38it/s]2026-01-18 22:06:52,137 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 93/3600 [00:39<24:21,  2.40it/s]2026-01-18 22:06:52,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 94/3600 [00:40<23:33,  2.48it/s]2026-01-18 22:06:52,968 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 95/3600 [00:40<24:33,  2.38it/s]2026-01-18 22:06:53,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 96/3600 [00:41<24:51,  2.35it/s]2026-01-18 22:06:53,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 97/3600 [00:41<25:43,  2.27it/s]2026-01-18 22:06:54,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 98/3600 [00:42<25:03,  2.33it/s]2026-01-18 22:06:54,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 99/3600 [00:42<25:13,  2.31it/s]2026-01-18 22:06:55,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 100/3600 [00:43<27:24,  2.13it/s]2026-01-18 22:06:55,389 - INFO -     Accuracy: 86.00% (86/100)\n2026-01-18 22:06:55,389 - INFO -   Language: zh\n2026-01-18 22:06:55,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 101/3600 [00:43<26:40,  2.19it/s]2026-01-18 22:06:56,161 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 102/3600 [00:43<26:30,  2.20it/s]2026-01-18 22:06:56,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 103/3600 [00:44<27:54,  2.09it/s]2026-01-18 22:06:57,169 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 104/3600 [00:44<27:51,  2.09it/s]2026-01-18 22:06:57,536 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 105/3600 [00:45<25:53,  2.25it/s]2026-01-18 22:06:57,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 106/3600 [00:45<25:49,  2.25it/s]2026-01-18 22:06:58,417 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 107/3600 [00:46<25:45,  2.26it/s]2026-01-18 22:06:58,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 108/3600 [00:46<24:05,  2.42it/s]2026-01-18 22:06:59,200 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 109/3600 [00:46<24:34,  2.37it/s]2026-01-18 22:06:59,635 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 110/3600 [00:47<24:54,  2.34it/s]2026-01-18 22:07:00,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 111/3600 [00:47<25:55,  2.24it/s]2026-01-18 22:07:00,517 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 112/3600 [00:48<24:49,  2.34it/s]2026-01-18 22:07:00,931 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 113/3600 [00:48<24:36,  2.36it/s]2026-01-18 22:07:01,295 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 114/3600 [00:49<23:33,  2.47it/s]2026-01-18 22:07:01,711 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 115/3600 [00:49<23:47,  2.44it/s]2026-01-18 22:07:02,136 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 116/3600 [00:49<24:00,  2.42it/s]2026-01-18 22:07:02,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 117/3600 [00:50<24:33,  2.36it/s]2026-01-18 22:07:02,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 118/3600 [00:50<23:36,  2.46it/s]2026-01-18 22:07:03,356 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 119/3600 [00:51<23:29,  2.47it/s]2026-01-18 22:07:03,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 120/3600 [00:51<24:34,  2.36it/s]2026-01-18 22:07:04,203 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 121/3600 [00:51<23:52,  2.43it/s]2026-01-18 22:07:04,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 122/3600 [00:52<23:26,  2.47it/s]2026-01-18 22:07:04,981 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 123/3600 [00:52<23:10,  2.50it/s]2026-01-18 22:07:05,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 124/3600 [00:53<25:09,  2.30it/s]2026-01-18 22:07:05,973 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   3%|▎         | 125/3600 [00:53<26:15,  2.21it/s]2026-01-18 22:07:06,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 126/3600 [00:54<24:47,  2.34it/s]2026-01-18 22:07:06,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 127/3600 [00:54<24:39,  2.35it/s]2026-01-18 22:07:07,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 128/3600 [00:54<24:49,  2.33it/s]2026-01-18 22:07:07,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 129/3600 [00:55<24:44,  2.34it/s]2026-01-18 22:07:08,103 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 130/3600 [00:55<25:13,  2.29it/s]2026-01-18 22:07:08,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 131/3600 [00:56<24:54,  2.32it/s]2026-01-18 22:07:08,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 132/3600 [00:56<23:01,  2.51it/s]2026-01-18 22:07:09,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 133/3600 [00:56<23:14,  2.49it/s]2026-01-18 22:07:10,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▎         | 134/3600 [00:57<31:06,  1.86it/s]2026-01-18 22:07:10,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 135/3600 [00:58<30:56,  1.87it/s]2026-01-18 22:07:11,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 136/3600 [00:58<28:08,  2.05it/s]2026-01-18 22:07:11,424 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 137/3600 [00:59<26:51,  2.15it/s]2026-01-18 22:07:11,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 138/3600 [00:59<25:31,  2.26it/s]2026-01-18 22:07:12,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 139/3600 [00:59<24:55,  2.31it/s]2026-01-18 22:07:12,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 140/3600 [01:00<24:25,  2.36it/s]2026-01-18 22:07:13,090 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 141/3600 [01:00<25:05,  2.30it/s]2026-01-18 22:07:13,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 142/3600 [01:01<24:21,  2.37it/s]2026-01-18 22:07:13,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 143/3600 [01:01<25:41,  2.24it/s]2026-01-18 22:07:14,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 144/3600 [01:02<25:59,  2.22it/s]2026-01-18 22:07:14,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 145/3600 [01:02<26:21,  2.18it/s]2026-01-18 22:07:15,351 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 146/3600 [01:03<25:53,  2.22it/s]2026-01-18 22:07:15,745 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 147/3600 [01:03<24:51,  2.31it/s]2026-01-18 22:07:16,236 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 148/3600 [01:03<25:57,  2.22it/s]2026-01-18 22:07:16,610 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 149/3600 [01:04<24:32,  2.34it/s]2026-01-18 22:07:16,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 150/3600 [01:04<23:29,  2.45it/s]2026-01-18 22:07:17,553 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 151/3600 [01:05<26:26,  2.17it/s]2026-01-18 22:07:17,939 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 152/3600 [01:05<25:08,  2.29it/s]2026-01-18 22:07:18,359 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 153/3600 [01:06<24:47,  2.32it/s]2026-01-18 22:07:18,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 154/3600 [01:06<25:24,  2.26it/s]2026-01-18 22:07:19,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 155/3600 [01:07<27:06,  2.12it/s]2026-01-18 22:07:19,773 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 156/3600 [01:07<25:59,  2.21it/s]2026-01-18 22:07:20,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 157/3600 [01:07<26:18,  2.18it/s]2026-01-18 22:07:20,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 158/3600 [01:08<25:34,  2.24it/s]2026-01-18 22:07:21,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 159/3600 [01:08<24:21,  2.35it/s]2026-01-18 22:07:21,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 160/3600 [01:09<23:57,  2.39it/s]2026-01-18 22:07:21,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 161/3600 [01:09<23:36,  2.43it/s]2026-01-18 22:07:22,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   4%|▍         | 162/3600 [01:10<25:52,  2.21it/s]2026-01-18 22:07:22,846 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 163/3600 [01:10<26:09,  2.19it/s]2026-01-18 22:07:23,243 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 164/3600 [01:10<25:04,  2.28it/s]2026-01-18 22:07:23,709 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 165/3600 [01:11<25:33,  2.24it/s]2026-01-18 22:07:24,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 166/3600 [01:11<23:53,  2.40it/s]2026-01-18 22:07:24,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 167/3600 [01:12<23:57,  2.39it/s]2026-01-18 22:07:24,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 168/3600 [01:12<22:56,  2.49it/s]2026-01-18 22:07:25,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 169/3600 [01:13<24:15,  2.36it/s]2026-01-18 22:07:25,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 170/3600 [01:13<24:40,  2.32it/s]2026-01-18 22:07:26,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 171/3600 [01:13<24:14,  2.36it/s]2026-01-18 22:07:26,644 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 172/3600 [01:14<25:05,  2.28it/s]2026-01-18 22:07:27,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 173/3600 [01:14<23:50,  2.40it/s]2026-01-18 22:07:27,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 174/3600 [01:15<24:20,  2.35it/s]2026-01-18 22:07:27,929 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 175/3600 [01:15<25:08,  2.27it/s]2026-01-18 22:07:28,397 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 176/3600 [01:16<25:31,  2.24it/s]2026-01-18 22:07:28,780 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 177/3600 [01:16<24:21,  2.34it/s]2026-01-18 22:07:29,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 178/3600 [01:16<25:02,  2.28it/s]2026-01-18 22:07:29,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▍         | 179/3600 [01:17<25:39,  2.22it/s]2026-01-18 22:07:30,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 180/3600 [01:17<24:50,  2.29it/s]2026-01-18 22:07:30,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 181/3600 [01:18<23:53,  2.38it/s]2026-01-18 22:07:30,886 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 182/3600 [01:18<23:12,  2.45it/s]2026-01-18 22:07:31,298 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 183/3600 [01:19<23:15,  2.45it/s]2026-01-18 22:07:31,799 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 184/3600 [01:19<24:52,  2.29it/s]2026-01-18 22:07:32,267 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 185/3600 [01:20<25:35,  2.22it/s]2026-01-18 22:07:32,907 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 186/3600 [01:20<28:35,  1.99it/s]2026-01-18 22:07:33,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 187/3600 [01:21<26:58,  2.11it/s]2026-01-18 22:07:33,832 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 188/3600 [01:21<27:45,  2.05it/s]2026-01-18 22:07:34,229 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 189/3600 [01:21<26:19,  2.16it/s]2026-01-18 22:07:34,690 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 190/3600 [01:22<26:07,  2.18it/s]2026-01-18 22:07:35,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 191/3600 [01:22<27:17,  2.08it/s]2026-01-18 22:07:35,640 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 192/3600 [01:23<26:17,  2.16it/s]2026-01-18 22:07:36,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 193/3600 [01:23<24:50,  2.29it/s]2026-01-18 22:07:36,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 194/3600 [01:24<24:32,  2.31it/s]2026-01-18 22:07:36,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 195/3600 [01:24<23:26,  2.42it/s]2026-01-18 22:07:37,232 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 196/3600 [01:24<23:36,  2.40it/s]2026-01-18 22:07:37,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   5%|▌         | 197/3600 [01:25<25:55,  2.19it/s]2026-01-18 22:07:38,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 198/3600 [01:25<26:13,  2.16it/s]2026-01-18 22:07:38,707 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 199/3600 [01:26<26:00,  2.18it/s]2026-01-18 22:07:39,141 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 200/3600 [01:26<25:30,  2.22it/s]2026-01-18 22:07:39,246 - INFO -     Accuracy: 75.00% (75/100)\n2026-01-18 22:07:39,246 - INFO -   Language: es\n2026-01-18 22:07:39,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 201/3600 [01:27<25:48,  2.19it/s]2026-01-18 22:07:40,049 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 202/3600 [01:27<25:32,  2.22it/s]2026-01-18 22:07:40,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 203/3600 [01:28<24:11,  2.34it/s]2026-01-18 22:07:40,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 204/3600 [01:28<23:47,  2.38it/s]2026-01-18 22:07:41,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 205/3600 [01:29<24:22,  2.32it/s]2026-01-18 22:07:41,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 206/3600 [01:29<26:02,  2.17it/s]2026-01-18 22:07:42,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 207/3600 [01:30<27:16,  2.07it/s]2026-01-18 22:07:42,800 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 208/3600 [01:30<26:55,  2.10it/s]2026-01-18 22:07:43,188 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 209/3600 [01:30<25:22,  2.23it/s]2026-01-18 22:07:43,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 210/3600 [01:31<24:20,  2.32it/s]2026-01-18 22:07:43,975 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 211/3600 [01:31<23:46,  2.38it/s]2026-01-18 22:07:44,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 212/3600 [01:32<25:13,  2.24it/s]2026-01-18 22:07:44,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 213/3600 [01:32<23:59,  2.35it/s]2026-01-18 22:07:45,313 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 214/3600 [01:33<24:29,  2.30it/s]2026-01-18 22:07:45,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 215/3600 [01:33<23:36,  2.39it/s]2026-01-18 22:07:46,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 216/3600 [01:33<23:25,  2.41it/s]2026-01-18 22:07:46,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 217/3600 [01:34<24:29,  2.30it/s]2026-01-18 22:07:46,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 218/3600 [01:34<23:08,  2.44it/s]2026-01-18 22:07:47,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 219/3600 [01:35<23:01,  2.45it/s]2026-01-18 22:07:47,759 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 220/3600 [01:35<23:13,  2.43it/s]2026-01-18 22:07:48,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 221/3600 [01:36<25:05,  2.24it/s]2026-01-18 22:07:48,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 222/3600 [01:36<23:29,  2.40it/s]2026-01-18 22:07:49,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 223/3600 [01:36<23:31,  2.39it/s]2026-01-18 22:07:49,554 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▌         | 224/3600 [01:37<24:57,  2.25it/s]2026-01-18 22:07:49,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 225/3600 [01:37<24:00,  2.34it/s]2026-01-18 22:07:50,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 226/3600 [01:38<23:49,  2.36it/s]2026-01-18 22:07:50,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 227/3600 [01:38<24:39,  2.28it/s]2026-01-18 22:07:51,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 228/3600 [01:38<23:47,  2.36it/s]2026-01-18 22:07:51,718 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 229/3600 [01:39<25:01,  2.24it/s]2026-01-18 22:07:52,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 230/3600 [01:39<23:57,  2.34it/s]2026-01-18 22:07:52,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 231/3600 [01:40<25:10,  2.23it/s]2026-01-18 22:07:52,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 232/3600 [01:40<24:03,  2.33it/s]2026-01-18 22:07:53,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 233/3600 [01:41<23:25,  2.40it/s]2026-01-18 22:07:53,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   6%|▋         | 234/3600 [01:41<22:59,  2.44it/s]2026-01-18 22:07:54,133 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 235/3600 [01:41<22:19,  2.51it/s]2026-01-18 22:07:54,555 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 236/3600 [01:42<22:36,  2.48it/s]2026-01-18 22:07:54,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 237/3600 [01:42<23:12,  2.42it/s]2026-01-18 22:07:55,366 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 238/3600 [01:43<22:33,  2.48it/s]2026-01-18 22:07:55,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 239/3600 [01:43<23:26,  2.39it/s]2026-01-18 22:07:56,233 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 240/3600 [01:43<23:17,  2.40it/s]2026-01-18 22:07:56,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 241/3600 [01:44<23:10,  2.42it/s]2026-01-18 22:07:57,130 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 242/3600 [01:44<24:29,  2.28it/s]2026-01-18 22:07:57,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 243/3600 [01:45<23:48,  2.35it/s]2026-01-18 22:07:57,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 244/3600 [01:45<23:09,  2.41it/s]2026-01-18 22:07:58,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 245/3600 [01:46<24:44,  2.26it/s]2026-01-18 22:07:58,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 246/3600 [01:46<26:00,  2.15it/s]2026-01-18 22:07:59,542 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 247/3600 [01:47<28:11,  1.98it/s]2026-01-18 22:07:59,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 248/3600 [01:47<26:22,  2.12it/s]2026-01-18 22:08:00,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 249/3600 [01:48<25:21,  2.20it/s]2026-01-18 22:08:00,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 250/3600 [01:48<25:42,  2.17it/s]2026-01-18 22:08:01,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 251/3600 [01:48<25:21,  2.20it/s]2026-01-18 22:08:01,702 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 252/3600 [01:49<25:08,  2.22it/s]2026-01-18 22:08:02,194 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 253/3600 [01:49<25:47,  2.16it/s]2026-01-18 22:08:02,695 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 254/3600 [01:50<26:22,  2.11it/s]2026-01-18 22:08:03,130 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 255/3600 [01:50<25:43,  2.17it/s]2026-01-18 22:08:03,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 256/3600 [01:51<24:19,  2.29it/s]2026-01-18 22:08:04,010 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 257/3600 [01:51<25:26,  2.19it/s]2026-01-18 22:08:04,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 258/3600 [01:52<25:10,  2.21it/s]2026-01-18 22:08:05,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 259/3600 [01:52<26:44,  2.08it/s]2026-01-18 22:08:05,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 260/3600 [01:53<26:21,  2.11it/s]2026-01-18 22:08:05,888 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 261/3600 [01:53<25:42,  2.16it/s]2026-01-18 22:08:06,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 262/3600 [01:54<25:57,  2.14it/s]2026-01-18 22:08:06,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 263/3600 [01:54<25:38,  2.17it/s]2026-01-18 22:08:07,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 264/3600 [01:55<25:44,  2.16it/s]2026-01-18 22:08:07,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 265/3600 [01:55<25:16,  2.20it/s]2026-01-18 22:08:08,145 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 266/3600 [01:55<24:45,  2.24it/s]2026-01-18 22:08:08,605 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 267/3600 [01:56<24:59,  2.22it/s]2026-01-18 22:08:08,983 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 268/3600 [01:56<23:55,  2.32it/s]2026-01-18 22:08:09,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   7%|▋         | 269/3600 [01:57<23:42,  2.34it/s]2026-01-18 22:08:10,167 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 270/3600 [01:57<29:09,  1.90it/s]2026-01-18 22:08:10,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 271/3600 [01:58<26:32,  2.09it/s]2026-01-18 22:08:11,005 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 272/3600 [01:58<26:32,  2.09it/s]2026-01-18 22:08:11,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 273/3600 [01:59<24:58,  2.22it/s]2026-01-18 22:08:11,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 274/3600 [01:59<25:49,  2.15it/s]2026-01-18 22:08:12,336 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 275/3600 [02:00<25:19,  2.19it/s]2026-01-18 22:08:12,837 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 276/3600 [02:00<26:03,  2.13it/s]2026-01-18 22:08:13,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 277/3600 [02:01<25:50,  2.14it/s]2026-01-18 22:08:13,781 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 278/3600 [02:01<26:11,  2.11it/s]2026-01-18 22:08:14,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 279/3600 [02:02<26:25,  2.09it/s]2026-01-18 22:08:14,674 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 280/3600 [02:02<25:12,  2.20it/s]2026-01-18 22:08:15,099 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 281/3600 [02:02<24:39,  2.24it/s]2026-01-18 22:08:15,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 282/3600 [02:03<24:19,  2.27it/s]2026-01-18 22:08:15,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 283/3600 [02:03<23:52,  2.32it/s]2026-01-18 22:08:16,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 284/3600 [02:04<23:44,  2.33it/s]2026-01-18 22:08:16,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 285/3600 [02:04<22:38,  2.44it/s]2026-01-18 22:08:17,103 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 286/3600 [02:04<22:04,  2.50it/s]2026-01-18 22:08:17,573 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 287/3600 [02:05<23:19,  2.37it/s]2026-01-18 22:08:18,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 288/3600 [02:05<27:10,  2.03it/s]2026-01-18 22:08:18,628 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 289/3600 [02:06<25:31,  2.16it/s]2026-01-18 22:08:19,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 290/3600 [02:06<27:16,  2.02it/s]2026-01-18 22:08:19,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 291/3600 [02:07<26:33,  2.08it/s]2026-01-18 22:08:20,027 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 292/3600 [02:07<24:50,  2.22it/s]2026-01-18 22:08:20,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 293/3600 [02:08<25:09,  2.19it/s]2026-01-18 22:08:20,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 294/3600 [02:08<25:40,  2.15it/s]2026-01-18 22:08:21,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 295/3600 [02:09<26:32,  2.07it/s]2026-01-18 22:08:22,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 296/3600 [02:09<28:01,  1.97it/s]2026-01-18 22:08:22,498 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 297/3600 [02:10<26:37,  2.07it/s]2026-01-18 22:08:22,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 298/3600 [02:10<25:10,  2.19it/s]2026-01-18 22:08:23,434 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 299/3600 [02:11<26:43,  2.06it/s]2026-01-18 22:08:23,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 300/3600 [02:11<25:04,  2.19it/s]2026-01-18 22:08:23,940 - INFO -     Accuracy: 82.00% (82/100)\n2026-01-18 22:08:23,940 - INFO -   Language: fr\n2026-01-18 22:08:24,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 301/3600 [02:11<23:50,  2.31it/s]2026-01-18 22:08:24,625 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 302/3600 [02:12<23:27,  2.34it/s]2026-01-18 22:08:25,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 303/3600 [02:12<22:39,  2.43it/s]2026-01-18 22:08:25,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 304/3600 [02:13<23:12,  2.37it/s]2026-01-18 22:08:26,025 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 305/3600 [02:13<25:48,  2.13it/s]2026-01-18 22:08:26,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   8%|▊         | 306/3600 [02:14<26:29,  2.07it/s]2026-01-18 22:08:26,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 307/3600 [02:14<25:46,  2.13it/s]2026-01-18 22:08:27,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 308/3600 [02:15<23:58,  2.29it/s]2026-01-18 22:08:27,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 309/3600 [02:15<25:21,  2.16it/s]2026-01-18 22:08:28,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 310/3600 [02:16<28:40,  1.91it/s]2026-01-18 22:08:28,901 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 311/3600 [02:16<26:11,  2.09it/s]2026-01-18 22:08:29,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 312/3600 [02:17<25:08,  2.18it/s]2026-01-18 22:08:29,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 313/3600 [02:17<24:15,  2.26it/s]2026-01-18 22:08:30,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▊         | 314/3600 [02:17<24:09,  2.27it/s]2026-01-18 22:08:30,681 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 315/3600 [02:18<25:26,  2.15it/s]2026-01-18 22:08:31,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 316/3600 [02:19<30:27,  1.80it/s]2026-01-18 22:08:31,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 317/3600 [02:19<28:04,  1.95it/s]2026-01-18 22:08:32,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 318/3600 [02:20<29:27,  1.86it/s]2026-01-18 22:08:32,856 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 319/3600 [02:20<27:06,  2.02it/s]2026-01-18 22:08:33,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 320/3600 [02:21<26:53,  2.03it/s]2026-01-18 22:08:33,762 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 321/3600 [02:21<25:46,  2.12it/s]2026-01-18 22:08:34,156 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 322/3600 [02:21<24:31,  2.23it/s]2026-01-18 22:08:34,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 323/3600 [02:22<25:38,  2.13it/s]2026-01-18 22:08:35,114 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 324/3600 [02:22<25:05,  2.18it/s]2026-01-18 22:08:35,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 325/3600 [02:23<24:47,  2.20it/s]2026-01-18 22:08:35,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 326/3600 [02:23<23:27,  2.33it/s]2026-01-18 22:08:36,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 327/3600 [02:24<22:43,  2.40it/s]2026-01-18 22:08:36,732 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 328/3600 [02:24<22:45,  2.40it/s]2026-01-18 22:08:37,176 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 329/3600 [02:24<23:10,  2.35it/s]2026-01-18 22:08:37,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 330/3600 [02:25<23:56,  2.28it/s]2026-01-18 22:08:38,093 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 331/3600 [02:25<24:00,  2.27it/s]2026-01-18 22:08:38,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 332/3600 [02:26<26:01,  2.09it/s]2026-01-18 22:08:39,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 333/3600 [02:26<24:55,  2.19it/s]2026-01-18 22:08:39,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 334/3600 [02:27<24:42,  2.20it/s]2026-01-18 22:08:39,876 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 335/3600 [02:27<23:14,  2.34it/s]2026-01-18 22:08:40,283 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 336/3600 [02:28<22:56,  2.37it/s]2026-01-18 22:08:40,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 337/3600 [02:28<23:10,  2.35it/s]2026-01-18 22:08:41,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 338/3600 [02:28<24:35,  2.21it/s]2026-01-18 22:08:41,637 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 339/3600 [02:29<23:48,  2.28it/s]2026-01-18 22:08:42,080 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 340/3600 [02:29<23:49,  2.28it/s]2026-01-18 22:08:42,716 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:   9%|▉         | 341/3600 [02:30<27:00,  2.01it/s]2026-01-18 22:08:43,183 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 342/3600 [02:30<26:31,  2.05it/s]2026-01-18 22:08:43,618 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 343/3600 [02:31<25:40,  2.11it/s]2026-01-18 22:08:44,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 344/3600 [02:31<25:30,  2.13it/s]2026-01-18 22:08:44,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 345/3600 [02:32<24:44,  2.19it/s]2026-01-18 22:08:45,034 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 346/3600 [02:32<25:54,  2.09it/s]2026-01-18 22:08:45,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 347/3600 [02:33<24:30,  2.21it/s]2026-01-18 22:08:45,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 348/3600 [02:33<23:51,  2.27it/s]2026-01-18 22:08:46,223 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 349/3600 [02:33<22:54,  2.37it/s]2026-01-18 22:08:46,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 350/3600 [02:34<23:23,  2.32it/s]2026-01-18 22:08:47,145 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 351/3600 [02:34<24:00,  2.26it/s]2026-01-18 22:08:47,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 352/3600 [02:35<24:13,  2.23it/s]2026-01-18 22:08:48,009 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 353/3600 [02:35<23:32,  2.30it/s]2026-01-18 22:08:48,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 354/3600 [02:36<24:35,  2.20it/s]2026-01-18 22:08:48,928 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 355/3600 [02:36<24:07,  2.24it/s]2026-01-18 22:08:49,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 356/3600 [02:37<22:46,  2.37it/s]2026-01-18 22:08:49,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 357/3600 [02:37<23:48,  2.27it/s]2026-01-18 22:08:50,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 358/3600 [02:37<23:42,  2.28it/s]2026-01-18 22:08:50,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|▉         | 359/3600 [02:38<24:37,  2.19it/s]2026-01-18 22:08:51,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 360/3600 [02:38<24:05,  2.24it/s]2026-01-18 22:08:51,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 361/3600 [02:39<23:58,  2.25it/s]2026-01-18 22:08:52,113 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 362/3600 [02:39<25:28,  2.12it/s]2026-01-18 22:08:52,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 363/3600 [02:40<23:56,  2.25it/s]2026-01-18 22:08:52,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 364/3600 [02:40<24:37,  2.19it/s]2026-01-18 22:08:53,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 365/3600 [02:41<25:55,  2.08it/s]2026-01-18 22:08:53,917 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 366/3600 [02:41<24:41,  2.18it/s]2026-01-18 22:08:54,320 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 367/3600 [02:42<23:43,  2.27it/s]2026-01-18 22:08:54,781 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 368/3600 [02:42<24:06,  2.23it/s]2026-01-18 22:08:55,361 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 369/3600 [02:43<26:14,  2.05it/s]2026-01-18 22:08:55,804 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 370/3600 [02:43<25:34,  2.11it/s]2026-01-18 22:08:56,207 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 371/3600 [02:43<24:20,  2.21it/s]2026-01-18 22:08:56,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 372/3600 [02:44<25:24,  2.12it/s]2026-01-18 22:08:57,201 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 373/3600 [02:44<25:28,  2.11it/s]2026-01-18 22:08:57,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 374/3600 [02:45<25:27,  2.11it/s]2026-01-18 22:08:58,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 375/3600 [02:45<24:58,  2.15it/s]2026-01-18 22:08:58,549 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 376/3600 [02:46<24:24,  2.20it/s]2026-01-18 22:08:59,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 377/3600 [02:46<27:49,  1.93it/s]2026-01-18 22:08:59,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  10%|█         | 378/3600 [02:47<26:57,  1.99it/s]2026-01-18 22:09:00,065 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 379/3600 [02:47<25:00,  2.15it/s]2026-01-18 22:09:00,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 380/3600 [02:48<24:44,  2.17it/s]2026-01-18 22:09:00,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 381/3600 [02:48<24:43,  2.17it/s]2026-01-18 22:09:01,449 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 382/3600 [02:49<24:56,  2.15it/s]2026-01-18 22:09:02,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 383/3600 [02:49<26:26,  2.03it/s]2026-01-18 22:09:02,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 384/3600 [02:50<25:46,  2.08it/s]2026-01-18 22:09:02,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 385/3600 [02:50<24:11,  2.21it/s]2026-01-18 22:09:03,282 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 386/3600 [02:51<24:08,  2.22it/s]2026-01-18 22:09:03,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 387/3600 [02:51<23:25,  2.29it/s]2026-01-18 22:09:04,147 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 388/3600 [02:51<23:38,  2.26it/s]2026-01-18 22:09:04,555 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 389/3600 [02:52<23:01,  2.32it/s]2026-01-18 22:09:05,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 390/3600 [02:52<24:05,  2.22it/s]2026-01-18 22:09:05,444 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 391/3600 [02:53<23:11,  2.31it/s]2026-01-18 22:09:05,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 392/3600 [02:53<23:15,  2.30it/s]2026-01-18 22:09:06,283 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 393/3600 [02:54<22:41,  2.36it/s]2026-01-18 22:09:06,704 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 394/3600 [02:54<22:38,  2.36it/s]2026-01-18 22:09:07,111 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 395/3600 [02:54<22:25,  2.38it/s]2026-01-18 22:09:07,572 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 396/3600 [02:55<23:02,  2.32it/s]2026-01-18 22:09:07,919 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 397/3600 [02:55<21:37,  2.47it/s]2026-01-18 22:09:08,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 398/3600 [02:56<21:31,  2.48it/s]2026-01-18 22:09:08,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 399/3600 [02:56<22:15,  2.40it/s]2026-01-18 22:09:09,178 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 400/3600 [02:56<22:11,  2.40it/s]2026-01-18 22:09:09,286 - INFO -     Accuracy: 82.00% (82/100)\n2026-01-18 22:09:09,287 - INFO -   Language: ar\n2026-01-18 22:09:09,648 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 401/3600 [02:57<23:00,  2.32it/s]2026-01-18 22:09:10,041 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 402/3600 [02:57<22:21,  2.38it/s]2026-01-18 22:09:10,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 403/3600 [02:58<21:50,  2.44it/s]2026-01-18 22:09:10,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█         | 404/3600 [02:58<21:41,  2.46it/s]2026-01-18 22:09:11,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 405/3600 [02:59<22:25,  2.37it/s]2026-01-18 22:09:11,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 406/3600 [02:59<22:21,  2.38it/s]2026-01-18 22:09:12,140 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 407/3600 [02:59<22:50,  2.33it/s]2026-01-18 22:09:12,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 408/3600 [03:00<22:02,  2.41it/s]2026-01-18 22:09:13,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 409/3600 [03:01<30:39,  1.74it/s]2026-01-18 22:09:13,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 410/3600 [03:01<28:42,  1.85it/s]2026-01-18 22:09:14,362 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 411/3600 [03:02<26:50,  1.98it/s]2026-01-18 22:09:15,008 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 412/3600 [03:02<29:10,  1.82it/s]2026-01-18 22:09:15,489 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  11%|█▏        | 413/3600 [03:03<27:59,  1.90it/s]2026-01-18 22:09:15,995 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 414/3600 [03:03<27:40,  1.92it/s]2026-01-18 22:09:16,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 415/3600 [03:04<26:28,  2.00it/s]2026-01-18 22:09:17,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 416/3600 [03:04<27:42,  1.92it/s]2026-01-18 22:09:17,416 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 417/3600 [03:05<25:42,  2.06it/s]2026-01-18 22:09:17,904 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 418/3600 [03:05<25:43,  2.06it/s]2026-01-18 22:09:18,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 419/3600 [03:06<25:30,  2.08it/s]2026-01-18 22:09:18,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 420/3600 [03:06<25:55,  2.04it/s]2026-01-18 22:09:19,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 421/3600 [03:07<25:21,  2.09it/s]2026-01-18 22:09:19,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 422/3600 [03:07<25:26,  2.08it/s]2026-01-18 22:09:20,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 423/3600 [03:08<26:40,  1.99it/s]2026-01-18 22:09:20,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 424/3600 [03:08<25:23,  2.08it/s]2026-01-18 22:09:21,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 425/3600 [03:09<25:16,  2.09it/s]2026-01-18 22:09:21,692 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 426/3600 [03:09<24:22,  2.17it/s]2026-01-18 22:09:22,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 427/3600 [03:09<25:23,  2.08it/s]2026-01-18 22:09:22,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 428/3600 [03:10<23:59,  2.20it/s]2026-01-18 22:09:23,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 429/3600 [03:10<25:18,  2.09it/s]2026-01-18 22:09:23,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 430/3600 [03:11<25:58,  2.03it/s]2026-01-18 22:09:24,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 431/3600 [03:11<25:38,  2.06it/s]2026-01-18 22:09:24,551 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 432/3600 [03:12<24:22,  2.17it/s]2026-01-18 22:09:24,988 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 433/3600 [03:12<23:58,  2.20it/s]2026-01-18 22:09:25,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 434/3600 [03:13<23:01,  2.29it/s]2026-01-18 22:09:25,841 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 435/3600 [03:13<23:23,  2.26it/s]2026-01-18 22:09:26,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 436/3600 [03:13<22:34,  2.34it/s]2026-01-18 22:09:26,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 437/3600 [03:14<22:53,  2.30it/s]2026-01-18 22:09:27,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 438/3600 [03:14<21:51,  2.41it/s]2026-01-18 22:09:27,515 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 439/3600 [03:15<22:39,  2.32it/s]2026-01-18 22:09:27,926 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 440/3600 [03:15<22:19,  2.36it/s]2026-01-18 22:09:28,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 441/3600 [03:16<22:00,  2.39it/s]2026-01-18 22:09:28,787 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 442/3600 [03:16<22:40,  2.32it/s]2026-01-18 22:09:29,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 443/3600 [03:16<22:30,  2.34it/s]2026-01-18 22:09:29,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 444/3600 [03:17<21:22,  2.46it/s]2026-01-18 22:09:29,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 445/3600 [03:17<20:52,  2.52it/s]2026-01-18 22:09:30,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 446/3600 [03:18<22:11,  2.37it/s]2026-01-18 22:09:30,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 447/3600 [03:18<23:51,  2.20it/s]2026-01-18 22:09:31,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 448/3600 [03:19<24:21,  2.16it/s]2026-01-18 22:09:31,947 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▏        | 449/3600 [03:19<25:03,  2.10it/s]2026-01-18 22:09:32,488 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  12%|█▎        | 450/3600 [03:20<26:06,  2.01it/s]2026-01-18 22:09:32,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 451/3600 [03:20<24:25,  2.15it/s]2026-01-18 22:09:33,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 452/3600 [03:20<23:04,  2.27it/s]2026-01-18 22:09:33,708 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 453/3600 [03:21<23:08,  2.27it/s]2026-01-18 22:09:34,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 454/3600 [03:21<22:23,  2.34it/s]2026-01-18 22:09:34,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 455/3600 [03:22<24:02,  2.18it/s]2026-01-18 22:09:35,034 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 456/3600 [03:22<23:03,  2.27it/s]2026-01-18 22:09:35,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 457/3600 [03:23<21:40,  2.42it/s]2026-01-18 22:09:35,835 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 458/3600 [03:23<22:15,  2.35it/s]2026-01-18 22:09:36,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 459/3600 [03:23<22:14,  2.35it/s]2026-01-18 22:09:36,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 460/3600 [03:24<21:59,  2.38it/s]2026-01-18 22:09:37,107 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 461/3600 [03:24<22:13,  2.35it/s]2026-01-18 22:09:37,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 462/3600 [03:25<22:12,  2.36it/s]2026-01-18 22:09:37,954 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 463/3600 [03:25<22:10,  2.36it/s]2026-01-18 22:09:38,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 464/3600 [03:26<22:42,  2.30it/s]2026-01-18 22:09:38,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 465/3600 [03:26<24:03,  2.17it/s]2026-01-18 22:09:39,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 466/3600 [03:27<23:52,  2.19it/s]2026-01-18 22:09:39,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 467/3600 [03:27<23:07,  2.26it/s]2026-01-18 22:09:40,230 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 468/3600 [03:27<23:05,  2.26it/s]2026-01-18 22:09:40,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 469/3600 [03:28<23:03,  2.26it/s]2026-01-18 22:09:41,082 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 470/3600 [03:28<22:32,  2.31it/s]2026-01-18 22:09:41,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 471/3600 [03:29<21:58,  2.37it/s]2026-01-18 22:09:41,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 472/3600 [03:29<23:27,  2.22it/s]2026-01-18 22:09:42,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 473/3600 [03:30<22:51,  2.28it/s]2026-01-18 22:09:42,771 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 474/3600 [03:30<21:41,  2.40it/s]2026-01-18 22:09:43,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 475/3600 [03:30<21:38,  2.41it/s]2026-01-18 22:09:43,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 476/3600 [03:31<21:53,  2.38it/s]2026-01-18 22:09:44,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 477/3600 [03:31<22:01,  2.36it/s]2026-01-18 22:09:44,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 478/3600 [03:32<21:28,  2.42it/s]2026-01-18 22:09:44,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 479/3600 [03:32<20:55,  2.49it/s]2026-01-18 22:09:45,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 480/3600 [03:32<20:34,  2.53it/s]2026-01-18 22:09:45,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 481/3600 [03:33<22:09,  2.35it/s]2026-01-18 22:09:46,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 482/3600 [03:33<21:43,  2.39it/s]2026-01-18 22:09:46,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 483/3600 [03:34<21:59,  2.36it/s]2026-01-18 22:09:46,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 484/3600 [03:34<22:17,  2.33it/s]2026-01-18 22:09:47,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  13%|█▎        | 485/3600 [03:35<22:59,  2.26it/s]2026-01-18 22:09:47,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 486/3600 [03:35<23:03,  2.25it/s]2026-01-18 22:09:48,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 487/3600 [03:36<22:02,  2.35it/s]2026-01-18 22:09:48,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 488/3600 [03:36<22:39,  2.29it/s]2026-01-18 22:09:49,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 489/3600 [03:36<23:15,  2.23it/s]2026-01-18 22:09:49,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 490/3600 [03:37<23:25,  2.21it/s]2026-01-18 22:09:50,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 491/3600 [03:37<22:54,  2.26it/s]2026-01-18 22:09:50,562 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 492/3600 [03:38<23:19,  2.22it/s]2026-01-18 22:09:50,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 493/3600 [03:38<22:28,  2.30it/s]2026-01-18 22:09:51,369 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▎        | 494/3600 [03:39<22:07,  2.34it/s]2026-01-18 22:09:51,794 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 495/3600 [03:39<22:07,  2.34it/s]2026-01-18 22:09:52,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 496/3600 [03:40<23:05,  2.24it/s]2026-01-18 22:09:52,718 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 497/3600 [03:40<22:52,  2.26it/s]2026-01-18 22:09:53,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 498/3600 [03:40<22:13,  2.33it/s]2026-01-18 22:09:53,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 499/3600 [03:41<22:36,  2.29it/s]2026-01-18 22:09:53,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 500/3600 [03:41<22:13,  2.32it/s]2026-01-18 22:09:54,094 - INFO -     Accuracy: 85.00% (85/100)\n2026-01-18 22:09:54,094 - INFO -   Language: ko\n2026-01-18 22:09:54,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 501/3600 [03:42<22:39,  2.28it/s]2026-01-18 22:09:54,810 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 502/3600 [03:42<21:32,  2.40it/s]2026-01-18 22:09:55,205 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 503/3600 [03:42<21:07,  2.44it/s]2026-01-18 22:09:55,603 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 504/3600 [03:43<20:59,  2.46it/s]2026-01-18 22:09:56,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 505/3600 [03:43<21:11,  2.43it/s]2026-01-18 22:09:56,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 506/3600 [03:44<22:55,  2.25it/s]2026-01-18 22:09:56,948 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 507/3600 [03:44<22:16,  2.32it/s]2026-01-18 22:09:57,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 508/3600 [03:45<23:56,  2.15it/s]2026-01-18 22:09:57,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 509/3600 [03:45<23:24,  2.20it/s]2026-01-18 22:09:58,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 510/3600 [03:46<22:42,  2.27it/s]2026-01-18 22:09:58,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 511/3600 [03:46<24:07,  2.13it/s]2026-01-18 22:09:59,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 512/3600 [03:47<23:09,  2.22it/s]2026-01-18 22:09:59,842 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 513/3600 [03:47<25:03,  2.05it/s]2026-01-18 22:10:00,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 514/3600 [03:48<24:10,  2.13it/s]2026-01-18 22:10:00,665 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 515/3600 [03:48<22:54,  2.24it/s]2026-01-18 22:10:01,134 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 516/3600 [03:48<23:15,  2.21it/s]2026-01-18 22:10:01,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 517/3600 [03:49<22:05,  2.33it/s]2026-01-18 22:10:01,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 518/3600 [03:49<22:21,  2.30it/s]2026-01-18 22:10:02,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 519/3600 [03:50<21:20,  2.41it/s]2026-01-18 22:10:02,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 520/3600 [03:50<23:13,  2.21it/s]2026-01-18 22:10:03,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 521/3600 [03:51<22:46,  2.25it/s]2026-01-18 22:10:03,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  14%|█▍        | 522/3600 [03:51<22:02,  2.33it/s]2026-01-18 22:10:04,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 523/3600 [03:51<21:49,  2.35it/s]2026-01-18 22:10:04,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 524/3600 [03:52<21:37,  2.37it/s]2026-01-18 22:10:05,163 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 525/3600 [03:52<25:06,  2.04it/s]2026-01-18 22:10:05,573 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 526/3600 [03:53<23:53,  2.14it/s]2026-01-18 22:10:06,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 527/3600 [03:53<25:39,  2.00it/s]2026-01-18 22:10:06,607 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 528/3600 [03:54<24:53,  2.06it/s]2026-01-18 22:10:07,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 529/3600 [03:54<24:27,  2.09it/s]2026-01-18 22:10:07,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 530/3600 [03:55<27:13,  1.88it/s]2026-01-18 22:10:08,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 531/3600 [03:55<25:15,  2.03it/s]2026-01-18 22:10:08,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 532/3600 [03:56<23:51,  2.14it/s]2026-01-18 22:10:08,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 533/3600 [03:56<22:34,  2.26it/s]2026-01-18 22:10:09,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 534/3600 [03:57<22:14,  2.30it/s]2026-01-18 22:10:09,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 535/3600 [03:57<22:13,  2.30it/s]2026-01-18 22:10:10,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 536/3600 [03:57<21:54,  2.33it/s]2026-01-18 22:10:10,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 537/3600 [03:58<22:14,  2.29it/s]2026-01-18 22:10:11,021 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 538/3600 [03:58<21:28,  2.38it/s]2026-01-18 22:10:11,486 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▍        | 539/3600 [03:59<22:11,  2.30it/s]2026-01-18 22:10:11,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 540/3600 [03:59<21:12,  2.40it/s]2026-01-18 22:10:12,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 541/3600 [04:00<21:26,  2.38it/s]2026-01-18 22:10:12,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 542/3600 [04:00<23:11,  2.20it/s]2026-01-18 22:10:13,325 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 543/3600 [04:01<24:01,  2.12it/s]2026-01-18 22:10:13,766 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 544/3600 [04:01<23:17,  2.19it/s]2026-01-18 22:10:14,267 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 545/3600 [04:01<24:00,  2.12it/s]2026-01-18 22:10:14,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 546/3600 [04:02<23:48,  2.14it/s]2026-01-18 22:10:15,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 547/3600 [04:02<23:42,  2.15it/s]2026-01-18 22:10:15,585 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 548/3600 [04:03<22:38,  2.25it/s]2026-01-18 22:10:16,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 549/3600 [04:03<22:22,  2.27it/s]2026-01-18 22:10:16,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 550/3600 [04:04<23:23,  2.17it/s]2026-01-18 22:10:16,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 551/3600 [04:04<22:36,  2.25it/s]2026-01-18 22:10:17,345 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 552/3600 [04:05<22:19,  2.28it/s]2026-01-18 22:10:17,955 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 553/3600 [04:05<24:54,  2.04it/s]2026-01-18 22:10:20,055 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 554/3600 [04:07<49:14,  1.03it/s]2026-01-18 22:10:20,514 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 555/3600 [04:08<41:24,  1.23it/s]2026-01-18 22:10:20,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 556/3600 [04:08<34:31,  1.47it/s]2026-01-18 22:10:21,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  15%|█▌        | 557/3600 [04:09<30:26,  1.67it/s]2026-01-18 22:10:21,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 558/3600 [04:09<28:43,  1.76it/s]2026-01-18 22:10:22,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 559/3600 [04:09<26:01,  1.95it/s]2026-01-18 22:10:22,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 560/3600 [04:10<24:11,  2.09it/s]2026-01-18 22:10:22,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 561/3600 [04:10<23:09,  2.19it/s]2026-01-18 22:10:23,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 562/3600 [04:11<22:29,  2.25it/s]2026-01-18 22:10:23,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 563/3600 [04:11<22:09,  2.28it/s]2026-01-18 22:10:24,246 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 564/3600 [04:11<22:18,  2.27it/s]2026-01-18 22:10:24,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 565/3600 [04:12<21:55,  2.31it/s]2026-01-18 22:10:25,195 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 566/3600 [04:12<23:17,  2.17it/s]2026-01-18 22:10:25,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 567/3600 [04:13<22:44,  2.22it/s]2026-01-18 22:10:26,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 568/3600 [04:13<24:17,  2.08it/s]2026-01-18 22:10:26,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 569/3600 [04:14<23:01,  2.19it/s]2026-01-18 22:10:27,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 570/3600 [04:14<24:34,  2.06it/s]2026-01-18 22:10:27,584 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 571/3600 [04:15<24:08,  2.09it/s]2026-01-18 22:10:27,980 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 572/3600 [04:15<22:52,  2.21it/s]2026-01-18 22:10:28,387 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 573/3600 [04:16<22:07,  2.28it/s]2026-01-18 22:10:28,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 574/3600 [04:16<21:11,  2.38it/s]2026-01-18 22:10:29,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 575/3600 [04:16<20:45,  2.43it/s]2026-01-18 22:10:29,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 576/3600 [04:17<20:25,  2.47it/s]2026-01-18 22:10:29,978 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 577/3600 [04:17<20:50,  2.42it/s]2026-01-18 22:10:30,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 578/3600 [04:18<20:24,  2.47it/s]2026-01-18 22:10:30,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 579/3600 [04:18<19:59,  2.52it/s]2026-01-18 22:10:31,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 580/3600 [04:18<19:43,  2.55it/s]2026-01-18 22:10:31,564 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 581/3600 [04:19<20:26,  2.46it/s]2026-01-18 22:10:31,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 582/3600 [04:19<20:51,  2.41it/s]2026-01-18 22:10:32,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 583/3600 [04:20<22:13,  2.26it/s]2026-01-18 22:10:33,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▌        | 584/3600 [04:20<23:17,  2.16it/s]2026-01-18 22:10:33,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 585/3600 [04:21<22:15,  2.26it/s]2026-01-18 22:10:33,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 586/3600 [04:21<22:00,  2.28it/s]2026-01-18 22:10:34,275 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 587/3600 [04:22<21:59,  2.28it/s]2026-01-18 22:10:34,775 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 588/3600 [04:22<22:52,  2.19it/s]2026-01-18 22:10:35,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 589/3600 [04:22<21:33,  2.33it/s]2026-01-18 22:10:35,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 590/3600 [04:23<22:33,  2.22it/s]2026-01-18 22:10:36,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 591/3600 [04:23<22:19,  2.25it/s]2026-01-18 22:10:36,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 592/3600 [04:24<21:26,  2.34it/s]2026-01-18 22:10:36,860 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 593/3600 [04:24<21:03,  2.38it/s]2026-01-18 22:10:37,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  16%|█▋        | 594/3600 [04:25<21:08,  2.37it/s]2026-01-18 22:10:37,721 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 595/3600 [04:25<21:16,  2.35it/s]2026-01-18 22:10:38,183 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 596/3600 [04:25<21:52,  2.29it/s]2026-01-18 22:10:38,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 597/3600 [04:26<22:21,  2.24it/s]2026-01-18 22:10:39,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 598/3600 [04:26<21:54,  2.28it/s]2026-01-18 22:10:39,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 599/3600 [04:27<21:02,  2.38it/s]2026-01-18 22:10:40,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 600/3600 [04:27<23:17,  2.15it/s]2026-01-18 22:10:40,130 - INFO -     Accuracy: 84.00% (84/100)\n2026-01-18 22:10:40,131 - INFO -   Language: vi\n2026-01-18 22:10:40,623 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 601/3600 [04:28<25:22,  1.97it/s]2026-01-18 22:10:41,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 602/3600 [04:28<23:40,  2.11it/s]2026-01-18 22:10:41,583 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 603/3600 [04:29<24:55,  2.00it/s]2026-01-18 22:10:41,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 604/3600 [04:29<23:05,  2.16it/s]2026-01-18 22:10:42,363 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 605/3600 [04:30<22:15,  2.24it/s]2026-01-18 22:10:42,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 606/3600 [04:30<22:08,  2.25it/s]2026-01-18 22:10:43,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 607/3600 [04:31<22:32,  2.21it/s]2026-01-18 22:10:43,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 608/3600 [04:31<22:05,  2.26it/s]2026-01-18 22:10:44,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 609/3600 [04:31<21:55,  2.27it/s]2026-01-18 22:10:44,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 610/3600 [04:32<21:02,  2.37it/s]2026-01-18 22:10:45,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 611/3600 [04:32<25:37,  1.94it/s]2026-01-18 22:10:46,112 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 612/3600 [04:33<30:56,  1.61it/s]2026-01-18 22:10:46,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 613/3600 [04:34<28:29,  1.75it/s]2026-01-18 22:10:47,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 614/3600 [04:34<27:11,  1.83it/s]2026-01-18 22:10:47,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 615/3600 [04:35<25:46,  1.93it/s]2026-01-18 22:10:47,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 616/3600 [04:35<23:38,  2.10it/s]2026-01-18 22:10:48,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 617/3600 [04:36<24:00,  2.07it/s]2026-01-18 22:10:48,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 618/3600 [04:36<23:53,  2.08it/s]2026-01-18 22:10:49,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 619/3600 [04:36<21:58,  2.26it/s]2026-01-18 22:10:49,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 620/3600 [04:37<22:22,  2.22it/s]2026-01-18 22:10:50,044 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 621/3600 [04:37<21:02,  2.36it/s]2026-01-18 22:10:50,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 622/3600 [04:38<21:15,  2.33it/s]2026-01-18 22:10:51,062 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 623/3600 [04:38<23:29,  2.11it/s]2026-01-18 22:10:51,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 624/3600 [04:39<21:59,  2.25it/s]2026-01-18 22:10:51,850 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 625/3600 [04:39<21:37,  2.29it/s]2026-01-18 22:10:52,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 626/3600 [04:39<20:54,  2.37it/s]2026-01-18 22:10:52,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 627/3600 [04:40<20:36,  2.40it/s]2026-01-18 22:10:53,109 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 628/3600 [04:40<21:22,  2.32it/s]2026-01-18 22:10:53,600 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  17%|█▋        | 629/3600 [04:41<22:16,  2.22it/s]2026-01-18 22:10:54,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 630/3600 [04:41<22:40,  2.18it/s]2026-01-18 22:10:54,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 631/3600 [04:42<21:22,  2.32it/s]2026-01-18 22:10:55,060 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 632/3600 [04:42<23:57,  2.06it/s]2026-01-18 22:10:55,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 633/3600 [04:43<21:53,  2.26it/s]2026-01-18 22:10:55,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 634/3600 [04:43<22:39,  2.18it/s]2026-01-18 22:10:56,326 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 635/3600 [04:44<22:11,  2.23it/s]2026-01-18 22:10:56,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 636/3600 [04:44<23:04,  2.14it/s]2026-01-18 22:10:57,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 637/3600 [04:45<23:01,  2.14it/s]2026-01-18 22:10:57,651 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 638/3600 [04:45<21:19,  2.32it/s]2026-01-18 22:10:58,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 639/3600 [04:46<24:12,  2.04it/s]2026-01-18 22:10:58,992 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 640/3600 [04:46<27:28,  1.80it/s]2026-01-18 22:10:59,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 641/3600 [04:47<25:33,  1.93it/s]2026-01-18 22:10:59,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 642/3600 [04:47<23:46,  2.07it/s]2026-01-18 22:11:00,192 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 643/3600 [04:47<22:11,  2.22it/s]2026-01-18 22:11:00,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 644/3600 [04:48<21:52,  2.25it/s]2026-01-18 22:11:01,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 645/3600 [04:48<24:19,  2.02it/s]2026-01-18 22:11:01,734 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 646/3600 [04:49<24:32,  2.01it/s]2026-01-18 22:11:02,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 647/3600 [04:49<22:44,  2.16it/s]2026-01-18 22:11:02,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 648/3600 [04:50<22:17,  2.21it/s]2026-01-18 22:11:02,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 649/3600 [04:50<21:32,  2.28it/s]2026-01-18 22:11:03,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 650/3600 [04:51<21:55,  2.24it/s]2026-01-18 22:11:03,809 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 651/3600 [04:51<21:05,  2.33it/s]2026-01-18 22:11:04,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 652/3600 [04:51<20:30,  2.40it/s]2026-01-18 22:11:04,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 653/3600 [04:52<20:00,  2.45it/s]2026-01-18 22:11:05,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 654/3600 [04:52<20:31,  2.39it/s]2026-01-18 22:11:05,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 655/3600 [04:53<19:46,  2.48it/s]2026-01-18 22:11:05,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 656/3600 [04:53<20:27,  2.40it/s]2026-01-18 22:11:06,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 657/3600 [04:54<21:15,  2.31it/s]2026-01-18 22:11:06,715 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 658/3600 [04:54<20:44,  2.36it/s]2026-01-18 22:11:07,506 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 659/3600 [04:55<26:12,  1.87it/s]2026-01-18 22:11:07,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 660/3600 [04:55<23:43,  2.07it/s]2026-01-18 22:11:08,268 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 661/3600 [04:56<22:26,  2.18it/s]2026-01-18 22:11:08,669 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 662/3600 [04:56<21:35,  2.27it/s]2026-01-18 22:11:09,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 663/3600 [04:56<22:28,  2.18it/s]2026-01-18 22:11:09,646 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 664/3600 [04:57<22:38,  2.16it/s]2026-01-18 22:11:10,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 665/3600 [04:57<23:19,  2.10it/s]2026-01-18 22:11:10,661 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  18%|█▊        | 666/3600 [04:58<23:45,  2.06it/s]2026-01-18 22:11:11,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 667/3600 [04:58<22:40,  2.16it/s]2026-01-18 22:11:11,492 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 668/3600 [04:59<21:58,  2.22it/s]2026-01-18 22:11:11,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 669/3600 [04:59<22:03,  2.21it/s]2026-01-18 22:11:12,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 670/3600 [05:00<21:51,  2.23it/s]2026-01-18 22:11:12,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 671/3600 [05:00<21:37,  2.26it/s]2026-01-18 22:11:13,457 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 672/3600 [05:01<24:31,  1.99it/s]2026-01-18 22:11:13,888 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 673/3600 [05:01<23:25,  2.08it/s]2026-01-18 22:11:14,312 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▊        | 674/3600 [05:02<22:37,  2.16it/s]2026-01-18 22:11:14,742 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 675/3600 [05:02<22:08,  2.20it/s]2026-01-18 22:11:15,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 676/3600 [05:02<20:46,  2.35it/s]2026-01-18 22:11:15,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 677/3600 [05:03<20:24,  2.39it/s]2026-01-18 22:11:15,982 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 678/3600 [05:03<21:11,  2.30it/s]2026-01-18 22:11:16,378 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 679/3600 [05:04<20:40,  2.36it/s]2026-01-18 22:11:16,880 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 680/3600 [05:04<21:51,  2.23it/s]2026-01-18 22:11:17,418 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 681/3600 [05:05<23:03,  2.11it/s]2026-01-18 22:11:17,835 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 682/3600 [05:05<22:13,  2.19it/s]2026-01-18 22:11:18,430 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 683/3600 [05:06<24:13,  2.01it/s]2026-01-18 22:11:18,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 684/3600 [05:06<24:51,  1.96it/s]2026-01-18 22:11:19,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 685/3600 [05:07<24:27,  1.99it/s]2026-01-18 22:11:19,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 686/3600 [05:07<23:19,  2.08it/s]2026-01-18 22:11:20,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 687/3600 [05:08<24:26,  1.99it/s]2026-01-18 22:11:20,879 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 688/3600 [05:08<23:27,  2.07it/s]2026-01-18 22:11:21,353 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 689/3600 [05:09<23:20,  2.08it/s]2026-01-18 22:11:21,831 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 690/3600 [05:09<23:24,  2.07it/s]2026-01-18 22:11:22,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 691/3600 [05:09<21:53,  2.21it/s]2026-01-18 22:11:22,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 692/3600 [05:10<20:52,  2.32it/s]2026-01-18 22:11:23,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 693/3600 [05:10<20:49,  2.33it/s]2026-01-18 22:11:23,452 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 694/3600 [05:11<20:47,  2.33it/s]2026-01-18 22:11:23,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 695/3600 [05:11<20:01,  2.42it/s]2026-01-18 22:11:24,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 696/3600 [05:11<20:08,  2.40it/s]2026-01-18 22:11:24,699 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 697/3600 [05:12<20:33,  2.35it/s]2026-01-18 22:11:25,362 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 698/3600 [05:13<24:00,  2.02it/s]2026-01-18 22:11:25,789 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 699/3600 [05:13<22:58,  2.10it/s]2026-01-18 22:11:26,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 700/3600 [05:13<21:47,  2.22it/s]2026-01-18 22:11:26,298 - INFO -     Accuracy: 78.00% (78/100)\n2026-01-18 22:11:26,298 - INFO -   Language: id\n2026-01-18 22:11:26,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  19%|█▉        | 701/3600 [05:14<22:12,  2.18it/s]2026-01-18 22:11:27,078 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 702/3600 [05:14<21:33,  2.24it/s]2026-01-18 22:11:27,528 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 703/3600 [05:15<21:37,  2.23it/s]2026-01-18 22:11:28,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 704/3600 [05:15<21:54,  2.20it/s]2026-01-18 22:11:28,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 705/3600 [05:16<21:09,  2.28it/s]2026-01-18 22:11:38,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n2026-01-18 22:11:38,577 - INFO - Retrying request to /chat/completions in 0.390084 seconds\n2026-01-18 22:11:39,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 706/3600 [05:26<2:52:04,  3.57s/it]2026-01-18 22:11:39,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 707/3600 [05:27<2:06:24,  2.62s/it]2026-01-18 22:11:40,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 708/3600 [05:27<1:34:02,  1.95s/it]2026-01-18 22:11:40,631 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 709/3600 [05:28<1:13:52,  1.53s/it]2026-01-18 22:11:41,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 710/3600 [05:28<57:52,  1.20s/it]  2026-01-18 22:11:41,510 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 711/3600 [05:29<47:05,  1.02it/s]2026-01-18 22:11:41,949 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 712/3600 [05:29<39:15,  1.23it/s]2026-01-18 22:11:42,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 713/3600 [05:30<33:50,  1.42it/s]2026-01-18 22:11:42,829 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 714/3600 [05:30<29:59,  1.60it/s]2026-01-18 22:11:43,202 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 715/3600 [05:30<26:22,  1.82it/s]2026-01-18 22:11:43,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 716/3600 [05:31<24:09,  1.99it/s]2026-01-18 22:11:44,050 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 717/3600 [05:31<23:28,  2.05it/s]2026-01-18 22:11:44,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 718/3600 [05:32<22:41,  2.12it/s]2026-01-18 22:11:44,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|█▉        | 719/3600 [05:32<21:23,  2.24it/s]2026-01-18 22:11:45,574 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 720/3600 [05:33<25:06,  1.91it/s]2026-01-18 22:11:46,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 721/3600 [05:33<26:14,  1.83it/s]2026-01-18 22:11:46,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 722/3600 [05:34<25:20,  1.89it/s]2026-01-18 22:11:47,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 723/3600 [05:34<23:49,  2.01it/s]2026-01-18 22:11:47,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 724/3600 [05:35<24:19,  1.97it/s]2026-01-18 22:11:48,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 725/3600 [05:35<22:53,  2.09it/s]2026-01-18 22:11:48,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 726/3600 [05:36<23:16,  2.06it/s]2026-01-18 22:11:48,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 727/3600 [05:36<21:37,  2.21it/s]2026-01-18 22:11:49,359 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 728/3600 [05:37<21:43,  2.20it/s]2026-01-18 22:11:49,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 729/3600 [05:37<21:22,  2.24it/s]2026-01-18 22:11:50,182 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 730/3600 [05:37<20:33,  2.33it/s]2026-01-18 22:11:50,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 731/3600 [05:38<21:43,  2.20it/s]2026-01-18 22:11:51,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 732/3600 [05:38<22:28,  2.13it/s]2026-01-18 22:11:51,713 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 733/3600 [05:39<23:03,  2.07it/s]2026-01-18 22:11:52,315 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 734/3600 [05:40<24:44,  1.93it/s]2026-01-18 22:11:52,792 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 735/3600 [05:40<24:15,  1.97it/s]2026-01-18 22:11:53,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 736/3600 [05:41<23:50,  2.00it/s]2026-01-18 22:11:53,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 737/3600 [05:41<21:30,  2.22it/s]2026-01-18 22:11:54,091 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  20%|██        | 738/3600 [05:41<21:51,  2.18it/s]2026-01-18 22:11:54,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 739/3600 [05:42<21:53,  2.18it/s]2026-01-18 22:11:54,953 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 740/3600 [05:42<21:05,  2.26it/s]2026-01-18 22:11:55,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 741/3600 [05:43<21:24,  2.23it/s]2026-01-18 22:11:55,844 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 742/3600 [05:43<21:04,  2.26it/s]2026-01-18 22:11:56,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 743/3600 [05:44<24:15,  1.96it/s]2026-01-18 22:11:56,923 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 744/3600 [05:44<22:50,  2.08it/s]2026-01-18 22:11:57,322 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 745/3600 [05:45<21:43,  2.19it/s]2026-01-18 22:11:57,838 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 746/3600 [05:45<22:32,  2.11it/s]2026-01-18 22:11:58,342 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 747/3600 [05:46<22:54,  2.08it/s]2026-01-18 22:11:58,790 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 748/3600 [05:46<22:25,  2.12it/s]2026-01-18 22:11:59,268 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 749/3600 [05:46<22:32,  2.11it/s]2026-01-18 22:11:59,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 750/3600 [05:47<21:39,  2.19it/s]2026-01-18 22:12:00,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 751/3600 [05:47<20:46,  2.29it/s]2026-01-18 22:12:00,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 752/3600 [05:48<20:44,  2.29it/s]2026-01-18 22:12:00,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 753/3600 [05:48<20:58,  2.26it/s]2026-01-18 22:12:01,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 754/3600 [05:49<21:17,  2.23it/s]2026-01-18 22:12:01,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 755/3600 [05:49<21:12,  2.24it/s]2026-01-18 22:12:02,400 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 756/3600 [05:50<22:18,  2.12it/s]2026-01-18 22:12:02,857 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 757/3600 [05:50<22:05,  2.14it/s]2026-01-18 22:12:03,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 758/3600 [05:50<21:02,  2.25it/s]2026-01-18 22:12:03,638 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 759/3600 [05:51<20:17,  2.33it/s]2026-01-18 22:12:04,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 760/3600 [05:51<20:00,  2.37it/s]2026-01-18 22:12:04,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 761/3600 [05:52<19:50,  2.39it/s]2026-01-18 22:12:04,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 762/3600 [05:52<19:46,  2.39it/s]2026-01-18 22:12:05,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 763/3600 [05:53<20:38,  2.29it/s]2026-01-18 22:12:05,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██        | 764/3600 [05:53<21:39,  2.18it/s]2026-01-18 22:12:06,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 765/3600 [05:54<21:36,  2.19it/s]2026-01-18 22:12:06,749 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 766/3600 [05:54<21:10,  2.23it/s]2026-01-18 22:12:07,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 767/3600 [05:54<20:50,  2.27it/s]2026-01-18 22:12:07,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 768/3600 [05:55<20:23,  2.31it/s]2026-01-18 22:12:08,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 769/3600 [05:55<20:56,  2.25it/s]2026-01-18 22:12:08,545 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 770/3600 [05:56<21:36,  2.18it/s]2026-01-18 22:12:09,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 771/3600 [05:56<21:44,  2.17it/s]2026-01-18 22:12:09,465 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 772/3600 [05:57<21:44,  2.17it/s]2026-01-18 22:12:09,924 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  21%|██▏       | 773/3600 [05:57<21:33,  2.18it/s]2026-01-18 22:12:10,408 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 774/3600 [05:58<21:55,  2.15it/s]2026-01-18 22:12:10,828 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 775/3600 [05:58<21:15,  2.22it/s]2026-01-18 22:12:11,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 776/3600 [05:59<21:22,  2.20it/s]2026-01-18 22:12:11,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 777/3600 [05:59<22:13,  2.12it/s]2026-01-18 22:12:12,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 778/3600 [05:59<21:28,  2.19it/s]2026-01-18 22:12:12,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 779/3600 [06:00<21:11,  2.22it/s]2026-01-18 22:12:13,180 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 780/3600 [06:00<22:09,  2.12it/s]2026-01-18 22:12:13,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 781/3600 [06:01<23:10,  2.03it/s]2026-01-18 22:12:14,096 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 782/3600 [06:01<21:29,  2.19it/s]2026-01-18 22:12:14,548 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 783/3600 [06:02<21:22,  2.20it/s]2026-01-18 22:12:15,033 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 784/3600 [06:02<21:52,  2.15it/s]2026-01-18 22:12:15,705 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 785/3600 [06:03<24:41,  1.90it/s]2026-01-18 22:12:16,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 786/3600 [06:03<22:39,  2.07it/s]2026-01-18 22:12:16,576 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 787/3600 [06:04<22:44,  2.06it/s]2026-01-18 22:12:17,042 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 788/3600 [06:04<22:29,  2.08it/s]2026-01-18 22:12:17,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 789/3600 [06:05<22:30,  2.08it/s]2026-01-18 22:12:17,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 790/3600 [06:05<22:08,  2.12it/s]2026-01-18 22:12:18,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 791/3600 [06:06<22:46,  2.06it/s]2026-01-18 22:12:20,251 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 792/3600 [06:07<40:32,  1.15it/s]2026-01-18 22:12:20,691 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 793/3600 [06:08<34:30,  1.36it/s]2026-01-18 22:12:21,177 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 794/3600 [06:08<31:02,  1.51it/s]2026-01-18 22:12:21,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 795/3600 [06:09<28:09,  1.66it/s]2026-01-18 22:12:22,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 796/3600 [06:09<27:08,  1.72it/s]2026-01-18 22:12:22,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 797/3600 [06:10<28:41,  1.63it/s]2026-01-18 22:12:23,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 798/3600 [06:10<25:24,  1.84it/s]2026-01-18 22:12:23,609 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 799/3600 [06:11<22:56,  2.04it/s]2026-01-18 22:12:24,013 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 800/3600 [06:11<21:40,  2.15it/s]2026-01-18 22:12:24,120 - INFO -     Accuracy: 81.00% (81/100)\n2026-01-18 22:12:24,120 - INFO -   Language: bn\n2026-01-18 22:12:24,446 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 801/3600 [06:12<21:14,  2.20it/s]2026-01-18 22:12:24,859 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 802/3600 [06:12<20:37,  2.26it/s]2026-01-18 22:12:25,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 803/3600 [06:12<20:05,  2.32it/s]2026-01-18 22:12:25,724 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 804/3600 [06:13<20:27,  2.28it/s]2026-01-18 22:12:26,113 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 805/3600 [06:13<19:47,  2.35it/s]2026-01-18 22:12:26,645 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 806/3600 [06:14<21:20,  2.18it/s]2026-01-18 22:12:27,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 807/3600 [06:14<20:25,  2.28it/s]2026-01-18 22:12:27,462 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 808/3600 [06:15<20:09,  2.31it/s]2026-01-18 22:12:27,863 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▏       | 809/3600 [06:15<19:39,  2.37it/s]2026-01-18 22:12:28,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  22%|██▎       | 810/3600 [06:16<19:49,  2.35it/s]2026-01-18 22:12:28,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 811/3600 [06:16<19:04,  2.44it/s]2026-01-18 22:12:29,045 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 812/3600 [06:16<18:34,  2.50it/s]2026-01-18 22:12:29,459 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 813/3600 [06:17<18:48,  2.47it/s]2026-01-18 22:12:30,162 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 814/3600 [06:17<22:57,  2.02it/s]2026-01-18 22:12:30,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 815/3600 [06:18<21:19,  2.18it/s]2026-01-18 22:12:30,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 816/3600 [06:18<20:13,  2.29it/s]2026-01-18 22:12:31,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 817/3600 [06:19<22:50,  2.03it/s]2026-01-18 22:12:31,910 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 818/3600 [06:19<21:02,  2.20it/s]2026-01-18 22:12:32,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 819/3600 [06:20<20:29,  2.26it/s]2026-01-18 22:12:32,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 820/3600 [06:20<19:55,  2.33it/s]2026-01-18 22:12:33,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 821/3600 [06:20<19:53,  2.33it/s]2026-01-18 22:12:33,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 822/3600 [06:21<19:02,  2.43it/s]2026-01-18 22:12:33,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 823/3600 [06:21<19:35,  2.36it/s]2026-01-18 22:12:34,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 824/3600 [06:22<24:27,  1.89it/s]2026-01-18 22:12:35,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 825/3600 [06:22<22:20,  2.07it/s]2026-01-18 22:12:35,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 826/3600 [06:23<21:22,  2.16it/s]2026-01-18 22:12:35,902 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 827/3600 [06:23<19:57,  2.32it/s]2026-01-18 22:12:36,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 828/3600 [06:24<19:29,  2.37it/s]2026-01-18 22:12:36,848 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 829/3600 [06:24<21:13,  2.18it/s]2026-01-18 22:12:37,246 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 830/3600 [06:24<20:21,  2.27it/s]2026-01-18 22:12:37,762 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 831/3600 [06:25<21:26,  2.15it/s]2026-01-18 22:12:38,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 832/3600 [06:25<20:24,  2.26it/s]2026-01-18 22:12:38,591 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 833/3600 [06:26<20:17,  2.27it/s]2026-01-18 22:12:38,997 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 834/3600 [06:26<19:48,  2.33it/s]2026-01-18 22:12:39,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 835/3600 [06:27<19:49,  2.33it/s]2026-01-18 22:12:39,949 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 836/3600 [06:27<21:05,  2.18it/s]2026-01-18 22:12:40,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 837/3600 [06:28<21:32,  2.14it/s]2026-01-18 22:12:40,892 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 838/3600 [06:28<21:16,  2.16it/s]2026-01-18 22:12:41,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 839/3600 [06:28<19:42,  2.33it/s]2026-01-18 22:12:41,661 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 840/3600 [06:29<19:39,  2.34it/s]2026-01-18 22:12:42,132 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 841/3600 [06:29<20:12,  2.28it/s]2026-01-18 22:12:42,703 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 842/3600 [06:30<22:01,  2.09it/s]2026-01-18 22:12:43,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 843/3600 [06:30<21:47,  2.11it/s]2026-01-18 22:12:43,570 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 844/3600 [06:31<20:47,  2.21it/s]2026-01-18 22:12:43,966 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  23%|██▎       | 845/3600 [06:31<19:59,  2.30it/s]2026-01-18 22:12:44,420 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 846/3600 [06:32<20:17,  2.26it/s]2026-01-18 22:12:44,909 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 847/3600 [06:32<20:56,  2.19it/s]2026-01-18 22:12:45,304 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 848/3600 [06:33<20:06,  2.28it/s]2026-01-18 22:12:45,756 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 849/3600 [06:33<20:13,  2.27it/s]2026-01-18 22:12:46,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 850/3600 [06:33<20:27,  2.24it/s]2026-01-18 22:12:46,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 851/3600 [06:34<19:48,  2.31it/s]2026-01-18 22:12:46,996 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 852/3600 [06:34<19:05,  2.40it/s]2026-01-18 22:12:47,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 853/3600 [06:35<19:48,  2.31it/s]2026-01-18 22:12:48,004 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▎       | 854/3600 [06:35<21:18,  2.15it/s]2026-01-18 22:12:48,411 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 855/3600 [06:36<20:26,  2.24it/s]2026-01-18 22:12:48,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 856/3600 [06:36<20:12,  2.26it/s]2026-01-18 22:12:49,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 857/3600 [06:36<19:25,  2.35it/s]2026-01-18 22:12:49,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 858/3600 [06:37<19:42,  2.32it/s]2026-01-18 22:12:50,068 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 859/3600 [06:37<19:14,  2.37it/s]2026-01-18 22:12:50,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 860/3600 [06:38<19:18,  2.37it/s]2026-01-18 22:12:50,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 861/3600 [06:38<18:51,  2.42it/s]2026-01-18 22:12:51,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 862/3600 [06:38<18:10,  2.51it/s]2026-01-18 22:12:51,709 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 863/3600 [06:39<19:04,  2.39it/s]2026-01-18 22:12:52,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 864/3600 [06:39<19:18,  2.36it/s]2026-01-18 22:12:52,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 865/3600 [06:40<19:44,  2.31it/s]2026-01-18 22:12:53,097 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 866/3600 [06:40<20:33,  2.22it/s]2026-01-18 22:12:53,497 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 867/3600 [06:41<19:50,  2.30it/s]2026-01-18 22:12:53,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 868/3600 [06:41<20:17,  2.24it/s]2026-01-18 22:12:54,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 869/3600 [06:42<21:21,  2.13it/s]2026-01-18 22:12:54,884 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 870/3600 [06:42<20:19,  2.24it/s]2026-01-18 22:12:55,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 871/3600 [06:43<19:59,  2.28it/s]2026-01-18 22:12:55,677 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 872/3600 [06:43<19:03,  2.39it/s]2026-01-18 22:12:56,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 873/3600 [06:43<18:29,  2.46it/s]2026-01-18 22:12:56,470 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 874/3600 [06:44<18:35,  2.44it/s]2026-01-18 22:12:56,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 875/3600 [06:44<19:09,  2.37it/s]2026-01-18 22:12:57,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 876/3600 [06:45<18:43,  2.42it/s]2026-01-18 22:12:57,784 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 877/3600 [06:45<19:29,  2.33it/s]2026-01-18 22:12:58,415 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 878/3600 [06:46<22:14,  2.04it/s]2026-01-18 22:12:58,877 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 879/3600 [06:46<21:52,  2.07it/s]2026-01-18 22:12:59,405 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 880/3600 [06:47<22:27,  2.02it/s]2026-01-18 22:12:59,770 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 881/3600 [06:47<20:41,  2.19it/s]2026-01-18 22:13:00,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  24%|██▍       | 882/3600 [06:47<21:06,  2.15it/s]2026-01-18 22:13:00,682 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 883/3600 [06:48<20:30,  2.21it/s]2026-01-18 22:13:01,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 884/3600 [06:48<20:57,  2.16it/s]2026-01-18 22:13:01,584 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 885/3600 [06:49<20:19,  2.23it/s]2026-01-18 22:13:01,978 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 886/3600 [06:49<19:33,  2.31it/s]2026-01-18 22:13:02,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 887/3600 [06:50<19:00,  2.38it/s]2026-01-18 22:13:02,838 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 888/3600 [06:50<19:37,  2.30it/s]2026-01-18 22:13:03,341 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 889/3600 [06:51<20:32,  2.20it/s]2026-01-18 22:13:03,743 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 890/3600 [06:51<19:50,  2.28it/s]2026-01-18 22:13:04,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 891/3600 [06:51<19:05,  2.37it/s]2026-01-18 22:13:04,616 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 892/3600 [06:52<19:57,  2.26it/s]2026-01-18 22:13:05,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 893/3600 [06:52<21:51,  2.06it/s]2026-01-18 22:13:05,617 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 894/3600 [06:53<20:56,  2.15it/s]2026-01-18 22:13:06,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 895/3600 [06:53<20:35,  2.19it/s]2026-01-18 22:13:06,449 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 896/3600 [06:54<19:44,  2.28it/s]2026-01-18 22:13:06,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 897/3600 [06:54<18:49,  2.39it/s]2026-01-18 22:13:07,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 898/3600 [06:54<18:51,  2.39it/s]2026-01-18 22:13:07,723 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▍       | 899/3600 [06:55<19:43,  2.28it/s]2026-01-18 22:13:08,139 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 900/3600 [06:55<19:25,  2.32it/s]2026-01-18 22:13:08,247 - INFO -     Accuracy: 76.00% (76/100)\n2026-01-18 22:13:08,248 - INFO -   Language: te\n2026-01-18 22:13:08,652 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 901/3600 [06:56<20:37,  2.18it/s]2026-01-18 22:13:09,035 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 902/3600 [06:56<19:32,  2.30it/s]2026-01-18 22:13:09,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 903/3600 [06:57<19:29,  2.31it/s]2026-01-18 22:13:10,024 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 904/3600 [06:57<21:06,  2.13it/s]2026-01-18 22:13:10,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 905/3600 [06:58<20:34,  2.18it/s]2026-01-18 22:13:10,904 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 906/3600 [06:58<20:26,  2.20it/s]2026-01-18 22:13:11,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 907/3600 [06:59<19:48,  2.27it/s]2026-01-18 22:13:11,740 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 908/3600 [06:59<19:37,  2.29it/s]2026-01-18 22:13:12,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 909/3600 [06:59<19:20,  2.32it/s]2026-01-18 22:13:12,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 910/3600 [07:00<18:26,  2.43it/s]2026-01-18 22:13:12,916 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 911/3600 [07:00<18:10,  2.47it/s]2026-01-18 22:13:13,391 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 912/3600 [07:01<19:09,  2.34it/s]2026-01-18 22:13:13,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 913/3600 [07:01<19:28,  2.30it/s]2026-01-18 22:13:14,315 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 914/3600 [07:02<19:55,  2.25it/s]2026-01-18 22:13:15,073 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 915/3600 [07:02<24:08,  1.85it/s]2026-01-18 22:13:15,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 916/3600 [07:03<24:43,  1.81it/s]2026-01-18 22:13:16,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  25%|██▌       | 917/3600 [07:03<22:55,  1.95it/s]2026-01-18 22:13:16,481 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 918/3600 [07:04<21:27,  2.08it/s]2026-01-18 22:13:16,902 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 919/3600 [07:04<20:37,  2.17it/s]2026-01-18 22:13:17,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 920/3600 [07:05<20:04,  2.22it/s]2026-01-18 22:13:17,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 921/3600 [07:05<18:52,  2.37it/s]2026-01-18 22:13:18,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 922/3600 [07:05<20:03,  2.23it/s]2026-01-18 22:13:19,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 923/3600 [07:06<26:23,  1.69it/s]2026-01-18 22:13:19,527 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 924/3600 [07:07<23:57,  1.86it/s]2026-01-18 22:13:19,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 925/3600 [07:07<22:57,  1.94it/s]2026-01-18 22:13:20,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 926/3600 [07:08<21:54,  2.03it/s]2026-01-18 22:13:20,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 927/3600 [07:08<20:23,  2.18it/s]2026-01-18 22:13:21,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 928/3600 [07:08<19:50,  2.24it/s]2026-01-18 22:13:21,796 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 929/3600 [07:09<21:31,  2.07it/s]2026-01-18 22:13:22,222 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 930/3600 [07:09<20:45,  2.14it/s]2026-01-18 22:13:22,624 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 931/3600 [07:10<19:53,  2.24it/s]2026-01-18 22:13:23,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 932/3600 [07:10<19:34,  2.27it/s]2026-01-18 22:13:23,460 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 933/3600 [07:11<19:11,  2.32it/s]2026-01-18 22:13:23,857 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 934/3600 [07:11<18:42,  2.38it/s]2026-01-18 22:13:24,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 935/3600 [07:11<18:15,  2.43it/s]2026-01-18 22:13:24,729 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 936/3600 [07:12<19:15,  2.31it/s]2026-01-18 22:13:25,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 937/3600 [07:12<19:20,  2.29it/s]2026-01-18 22:13:25,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 938/3600 [07:13<21:21,  2.08it/s]2026-01-18 22:13:26,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 939/3600 [07:13<20:36,  2.15it/s]2026-01-18 22:13:26,592 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 940/3600 [07:14<19:52,  2.23it/s]2026-01-18 22:13:26,981 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 941/3600 [07:14<19:04,  2.32it/s]2026-01-18 22:13:27,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 942/3600 [07:15<18:52,  2.35it/s]2026-01-18 22:13:27,864 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 943/3600 [07:15<19:24,  2.28it/s]2026-01-18 22:13:28,213 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▌       | 944/3600 [07:15<18:14,  2.43it/s]2026-01-18 22:13:28,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 945/3600 [07:16<19:30,  2.27it/s]2026-01-18 22:13:29,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 946/3600 [07:16<19:49,  2.23it/s]2026-01-18 22:13:29,662 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 947/3600 [07:17<20:06,  2.20it/s]2026-01-18 22:13:30,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 948/3600 [07:18<26:07,  1.69it/s]2026-01-18 22:13:30,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 949/3600 [07:18<23:55,  1.85it/s]2026-01-18 22:13:31,348 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 950/3600 [07:19<21:24,  2.06it/s]2026-01-18 22:13:31,756 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 951/3600 [07:19<20:21,  2.17it/s]2026-01-18 22:13:32,182 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 952/3600 [07:19<19:59,  2.21it/s]2026-01-18 22:13:32,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 953/3600 [07:20<19:09,  2.30it/s]2026-01-18 22:13:32,994 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  26%|██▋       | 954/3600 [07:20<18:52,  2.34it/s]2026-01-18 22:13:33,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 955/3600 [07:21<18:14,  2.42it/s]2026-01-18 22:13:33,899 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 956/3600 [07:21<19:45,  2.23it/s]2026-01-18 22:13:34,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 957/3600 [07:22<19:58,  2.20it/s]2026-01-18 22:13:34,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 958/3600 [07:22<20:51,  2.11it/s]2026-01-18 22:13:35,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 959/3600 [07:22<19:32,  2.25it/s]2026-01-18 22:13:35,611 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 960/3600 [07:23<18:18,  2.40it/s]2026-01-18 22:13:36,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 961/3600 [07:23<18:54,  2.33it/s]2026-01-18 22:13:36,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 962/3600 [07:24<18:08,  2.42it/s]2026-01-18 22:13:36,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 963/3600 [07:24<17:39,  2.49it/s]2026-01-18 22:13:37,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 964/3600 [07:24<17:38,  2.49it/s]2026-01-18 22:13:37,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 965/3600 [07:25<18:25,  2.38it/s]2026-01-18 22:13:38,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 966/3600 [07:25<18:38,  2.36it/s]2026-01-18 22:13:38,539 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 967/3600 [07:26<18:31,  2.37it/s]2026-01-18 22:13:38,894 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 968/3600 [07:26<17:38,  2.49it/s]2026-01-18 22:13:39,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 969/3600 [07:27<19:58,  2.19it/s]2026-01-18 22:13:40,003 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 970/3600 [07:27<20:55,  2.09it/s]2026-01-18 22:13:40,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 971/3600 [07:28<19:36,  2.23it/s]2026-01-18 22:13:40,818 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 972/3600 [07:28<19:28,  2.25it/s]2026-01-18 22:13:41,250 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 973/3600 [07:28<19:17,  2.27it/s]2026-01-18 22:13:41,712 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 974/3600 [07:29<19:34,  2.24it/s]2026-01-18 22:13:42,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 975/3600 [07:29<19:18,  2.27it/s]2026-01-18 22:13:42,644 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 976/3600 [07:30<20:07,  2.17it/s]2026-01-18 22:13:43,018 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 977/3600 [07:30<19:00,  2.30it/s]2026-01-18 22:13:43,726 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 978/3600 [07:31<22:35,  1.93it/s]2026-01-18 22:13:44,205 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 979/3600 [07:31<22:04,  1.98it/s]2026-01-18 22:13:44,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 980/3600 [07:32<22:11,  1.97it/s]2026-01-18 22:13:45,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 981/3600 [07:32<20:14,  2.16it/s]2026-01-18 22:13:45,475 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 982/3600 [07:33<19:17,  2.26it/s]2026-01-18 22:13:45,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 983/3600 [07:33<18:29,  2.36it/s]2026-01-18 22:13:46,309 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 984/3600 [07:34<18:54,  2.31it/s]2026-01-18 22:13:47,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 985/3600 [07:34<22:20,  1.95it/s]2026-01-18 22:13:47,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 986/3600 [07:35<21:14,  2.05it/s]2026-01-18 22:13:47,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 987/3600 [07:35<20:39,  2.11it/s]2026-01-18 22:13:48,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 988/3600 [07:36<20:06,  2.17it/s]2026-01-18 22:13:48,834 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  27%|██▋       | 989/3600 [07:36<20:52,  2.09it/s]2026-01-18 22:13:49,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 990/3600 [07:37<20:55,  2.08it/s]2026-01-18 22:13:49,783 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 991/3600 [07:37<20:53,  2.08it/s]2026-01-18 22:13:50,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 992/3600 [07:37<20:23,  2.13it/s]2026-01-18 22:13:50,751 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 993/3600 [07:38<21:01,  2.07it/s]2026-01-18 22:13:51,186 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 994/3600 [07:38<20:16,  2.14it/s]2026-01-18 22:13:51,615 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 995/3600 [07:39<19:45,  2.20it/s]2026-01-18 22:13:52,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 996/3600 [07:39<18:59,  2.29it/s]2026-01-18 22:13:52,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 997/3600 [07:40<21:35,  2.01it/s]2026-01-18 22:13:53,019 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 998/3600 [07:40<19:56,  2.17it/s]2026-01-18 22:13:53,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 999/3600 [07:41<20:21,  2.13it/s]2026-01-18 22:13:53,887 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1000/3600 [07:41<19:08,  2.26it/s]2026-01-18 22:13:54,005 - INFO -     Accuracy: 69.00% (69/100)\n2026-01-18 22:13:54,005 - INFO -   Language: sw\n2026-01-18 22:13:54,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1001/3600 [07:42<18:41,  2.32it/s]2026-01-18 22:13:54,776 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1002/3600 [07:42<19:19,  2.24it/s]2026-01-18 22:13:55,187 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1003/3600 [07:42<18:52,  2.29it/s]2026-01-18 22:13:55,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1004/3600 [07:43<19:51,  2.18it/s]2026-01-18 22:13:56,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1005/3600 [07:43<19:06,  2.26it/s]2026-01-18 22:13:56,491 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1006/3600 [07:44<18:24,  2.35it/s]2026-01-18 22:13:56,896 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1007/3600 [07:44<18:06,  2.39it/s]2026-01-18 22:13:57,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1008/3600 [07:45<18:17,  2.36it/s]2026-01-18 22:13:57,974 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1009/3600 [07:45<21:10,  2.04it/s]2026-01-18 22:13:58,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1010/3600 [07:46<20:27,  2.11it/s]2026-01-18 22:13:58,798 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1011/3600 [07:46<19:17,  2.24it/s]2026-01-18 22:13:59,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1012/3600 [07:46<19:18,  2.23it/s]2026-01-18 22:13:59,726 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1013/3600 [07:47<19:44,  2.18it/s]2026-01-18 22:14:00,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1014/3600 [07:47<19:28,  2.21it/s]2026-01-18 22:14:00,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1015/3600 [07:48<18:50,  2.29it/s]2026-01-18 22:14:00,992 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1016/3600 [07:48<18:41,  2.30it/s]2026-01-18 22:14:01,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1017/3600 [07:49<17:49,  2.41it/s]2026-01-18 22:14:01,728 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1018/3600 [07:49<17:15,  2.49it/s]2026-01-18 22:14:02,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1019/3600 [07:49<17:43,  2.43it/s]2026-01-18 22:14:02,814 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1020/3600 [07:50<20:41,  2.08it/s]2026-01-18 22:14:03,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1021/3600 [07:51<20:25,  2.10it/s]2026-01-18 22:14:03,722 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1022/3600 [07:51<20:05,  2.14it/s]2026-01-18 22:14:04,125 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1023/3600 [07:51<19:13,  2.23it/s]2026-01-18 22:14:04,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1024/3600 [07:52<19:42,  2.18it/s]2026-01-18 22:14:04,979 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1025/3600 [07:52<18:31,  2.32it/s]2026-01-18 22:14:05,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  28%|██▊       | 1026/3600 [07:53<19:21,  2.22it/s]2026-01-18 22:14:05,940 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1027/3600 [07:53<19:30,  2.20it/s]2026-01-18 22:14:06,562 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1028/3600 [07:54<21:42,  1.97it/s]2026-01-18 22:14:07,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1029/3600 [07:54<21:26,  2.00it/s]2026-01-18 22:14:07,438 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1030/3600 [07:55<19:58,  2.14it/s]2026-01-18 22:14:08,017 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1031/3600 [07:55<21:25,  2.00it/s]2026-01-18 22:14:08,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1032/3600 [07:56<19:41,  2.17it/s]2026-01-18 22:14:08,871 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1033/3600 [07:56<20:06,  2.13it/s]2026-01-18 22:14:09,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▊       | 1034/3600 [07:57<20:15,  2.11it/s]2026-01-18 22:14:09,760 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1035/3600 [07:57<19:18,  2.21it/s]2026-01-18 22:14:10,191 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1036/3600 [07:57<19:01,  2.25it/s]2026-01-18 22:14:10,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1037/3600 [07:58<19:22,  2.20it/s]2026-01-18 22:14:11,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1038/3600 [07:58<18:43,  2.28it/s]2026-01-18 22:14:11,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1039/3600 [07:59<18:05,  2.36it/s]2026-01-18 22:14:11,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1040/3600 [07:59<17:36,  2.42it/s]2026-01-18 22:14:12,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1041/3600 [08:00<17:55,  2.38it/s]2026-01-18 22:14:12,753 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1042/3600 [08:00<18:38,  2.29it/s]2026-01-18 22:14:13,134 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1043/3600 [08:00<17:54,  2.38it/s]2026-01-18 22:14:13,548 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1044/3600 [08:01<17:51,  2.38it/s]2026-01-18 22:14:13,964 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1045/3600 [08:01<17:43,  2.40it/s]2026-01-18 22:14:14,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1046/3600 [08:02<18:40,  2.28it/s]2026-01-18 22:14:14,866 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1047/3600 [08:02<18:19,  2.32it/s]2026-01-18 22:14:15,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1048/3600 [08:02<17:53,  2.38it/s]2026-01-18 22:14:15,673 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1049/3600 [08:03<17:45,  2.39it/s]2026-01-18 22:14:16,064 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1050/3600 [08:03<17:22,  2.45it/s]2026-01-18 22:14:16,588 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1051/3600 [08:04<18:51,  2.25it/s]2026-01-18 22:14:16,937 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1052/3600 [08:04<17:37,  2.41it/s]2026-01-18 22:14:17,330 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1053/3600 [08:05<17:23,  2.44it/s]2026-01-18 22:14:17,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1054/3600 [08:05<18:27,  2.30it/s]2026-01-18 22:14:18,266 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1055/3600 [08:05<18:30,  2.29it/s]2026-01-18 22:14:18,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1056/3600 [08:06<18:18,  2.32it/s]2026-01-18 22:14:19,077 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1057/3600 [08:06<17:46,  2.38it/s]2026-01-18 22:14:19,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1058/3600 [08:07<17:05,  2.48it/s]2026-01-18 22:14:19,867 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1059/3600 [08:07<17:20,  2.44it/s]2026-01-18 22:14:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1060/3600 [08:08<18:37,  2.27it/s]2026-01-18 22:14:20,944 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  29%|██▉       | 1061/3600 [08:08<20:12,  2.09it/s]2026-01-18 22:14:21,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1062/3600 [08:09<18:49,  2.25it/s]2026-01-18 22:14:21,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1063/3600 [08:09<17:52,  2.36it/s]2026-01-18 22:14:22,140 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1064/3600 [08:09<18:15,  2.32it/s]2026-01-18 22:14:22,550 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1065/3600 [08:10<17:57,  2.35it/s]2026-01-18 22:14:22,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1066/3600 [08:10<17:25,  2.42it/s]2026-01-18 22:14:23,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1067/3600 [08:11<19:20,  2.18it/s]2026-01-18 22:14:24,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1068/3600 [08:11<20:10,  2.09it/s]2026-01-18 22:14:24,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1069/3600 [08:12<19:39,  2.15it/s]2026-01-18 22:14:24,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1070/3600 [08:12<20:04,  2.10it/s]2026-01-18 22:14:25,328 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1071/3600 [08:13<18:46,  2.24it/s]2026-01-18 22:14:25,862 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1072/3600 [08:13<19:53,  2.12it/s]2026-01-18 22:14:26,254 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1073/3600 [08:13<18:58,  2.22it/s]2026-01-18 22:14:26,730 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1074/3600 [08:14<19:07,  2.20it/s]2026-01-18 22:14:27,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1075/3600 [08:14<17:55,  2.35it/s]2026-01-18 22:14:27,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1076/3600 [08:15<16:54,  2.49it/s]2026-01-18 22:14:27,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1077/3600 [08:15<17:37,  2.39it/s]2026-01-18 22:14:28,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1078/3600 [08:16<17:24,  2.41it/s]2026-01-18 22:14:28,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|██▉       | 1079/3600 [08:16<17:14,  2.44it/s]2026-01-18 22:14:29,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1080/3600 [08:16<17:19,  2.42it/s]2026-01-18 22:14:29,522 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1081/3600 [08:17<17:18,  2.43it/s]2026-01-18 22:14:30,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1082/3600 [08:17<18:59,  2.21it/s]2026-01-18 22:14:30,447 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1083/3600 [08:18<17:58,  2.33it/s]2026-01-18 22:14:30,859 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1084/3600 [08:18<17:44,  2.36it/s]2026-01-18 22:14:31,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1085/3600 [08:19<17:41,  2.37it/s]2026-01-18 22:14:31,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1086/3600 [08:19<17:55,  2.34it/s]2026-01-18 22:14:32,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1087/3600 [08:19<18:23,  2.28it/s]2026-01-18 22:14:32,541 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1088/3600 [08:20<17:21,  2.41it/s]2026-01-18 22:14:32,951 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1089/3600 [08:20<17:18,  2.42it/s]2026-01-18 22:14:33,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1090/3600 [08:21<17:05,  2.45it/s]2026-01-18 22:14:33,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1091/3600 [08:21<18:08,  2.30it/s]2026-01-18 22:14:34,262 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1092/3600 [08:21<17:56,  2.33it/s]2026-01-18 22:14:34,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1093/3600 [08:22<17:17,  2.42it/s]2026-01-18 22:14:35,116 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1094/3600 [08:22<18:03,  2.31it/s]2026-01-18 22:14:35,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1095/3600 [08:23<19:25,  2.15it/s]2026-01-18 22:14:36,100 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1096/3600 [08:23<19:06,  2.18it/s]2026-01-18 22:14:36,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1097/3600 [08:24<18:03,  2.31it/s]2026-01-18 22:14:37,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  30%|███       | 1098/3600 [08:24<20:37,  2.02it/s]2026-01-18 22:14:37,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1099/3600 [08:25<19:26,  2.14it/s]2026-01-18 22:14:37,854 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1100/3600 [08:25<17:54,  2.33it/s]2026-01-18 22:14:37,963 - INFO -     Accuracy: 79.00% (79/100)\n2026-01-18 22:14:37,963 - INFO -   Language: ta\n2026-01-18 22:14:38,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1101/3600 [08:26<19:22,  2.15it/s]2026-01-18 22:14:38,793 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1102/3600 [08:26<18:27,  2.25it/s]2026-01-18 22:14:39,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1103/3600 [08:26<18:28,  2.25it/s]2026-01-18 22:14:39,782 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1104/3600 [08:27<19:41,  2.11it/s]2026-01-18 22:14:40,273 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1105/3600 [08:28<19:54,  2.09it/s]2026-01-18 22:14:40,725 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1106/3600 [08:28<19:33,  2.13it/s]2026-01-18 22:14:41,141 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1107/3600 [08:28<19:00,  2.19it/s]2026-01-18 22:14:41,525 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1108/3600 [08:29<17:53,  2.32it/s]2026-01-18 22:14:41,941 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1109/3600 [08:29<17:45,  2.34it/s]2026-01-18 22:14:42,352 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1110/3600 [08:30<17:31,  2.37it/s]2026-01-18 22:14:42,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1111/3600 [08:30<17:14,  2.41it/s]2026-01-18 22:14:43,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1112/3600 [08:31<18:40,  2.22it/s]2026-01-18 22:14:43,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1113/3600 [08:31<18:11,  2.28it/s]2026-01-18 22:14:44,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1114/3600 [08:31<17:47,  2.33it/s]2026-01-18 22:14:44,496 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1115/3600 [08:32<17:18,  2.39it/s]2026-01-18 22:14:44,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1116/3600 [08:32<17:45,  2.33it/s]2026-01-18 22:14:45,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1117/3600 [08:33<20:03,  2.06it/s]2026-01-18 22:14:46,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1118/3600 [08:33<20:01,  2.07it/s]2026-01-18 22:14:46,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1119/3600 [08:34<20:00,  2.07it/s]2026-01-18 22:14:46,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1120/3600 [08:34<19:09,  2.16it/s]2026-01-18 22:14:47,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1121/3600 [08:35<18:24,  2.24it/s]2026-01-18 22:14:47,786 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1122/3600 [08:35<18:16,  2.26it/s]2026-01-18 22:14:48,184 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1123/3600 [08:35<17:44,  2.33it/s]2026-01-18 22:14:48,604 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███       | 1124/3600 [08:36<17:35,  2.35it/s]2026-01-18 22:14:49,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1125/3600 [08:36<18:06,  2.28it/s]2026-01-18 22:14:49,518 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1126/3600 [08:37<18:11,  2.27it/s]2026-01-18 22:14:49,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1127/3600 [08:37<17:35,  2.34it/s]2026-01-18 22:14:50,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1128/3600 [08:38<17:20,  2.37it/s]2026-01-18 22:14:50,717 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1129/3600 [08:38<17:06,  2.41it/s]2026-01-18 22:14:51,231 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1130/3600 [08:38<18:13,  2.26it/s]2026-01-18 22:14:51,660 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1131/3600 [08:39<18:05,  2.28it/s]2026-01-18 22:14:52,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1132/3600 [08:39<17:37,  2.33it/s]2026-01-18 22:14:52,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  31%|███▏      | 1133/3600 [08:40<16:50,  2.44it/s]2026-01-18 22:14:52,795 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1134/3600 [08:40<16:25,  2.50it/s]2026-01-18 22:14:53,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1135/3600 [08:40<16:28,  2.49it/s]2026-01-18 22:14:53,697 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1136/3600 [08:41<17:32,  2.34it/s]2026-01-18 22:14:54,088 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1137/3600 [08:41<17:03,  2.41it/s]2026-01-18 22:14:54,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1138/3600 [08:42<16:51,  2.44it/s]2026-01-18 22:14:54,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1139/3600 [08:42<16:45,  2.45it/s]2026-01-18 22:14:55,484 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1140/3600 [08:43<19:02,  2.15it/s]2026-01-18 22:14:55,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1141/3600 [08:43<19:11,  2.13it/s]2026-01-18 22:14:56,421 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1142/3600 [08:44<19:04,  2.15it/s]2026-01-18 22:14:56,915 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1143/3600 [08:44<19:25,  2.11it/s]2026-01-18 22:14:57,389 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1144/3600 [08:45<19:24,  2.11it/s]2026-01-18 22:14:57,816 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1145/3600 [08:45<18:52,  2.17it/s]2026-01-18 22:14:58,185 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1146/3600 [08:45<17:42,  2.31it/s]2026-01-18 22:14:58,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1147/3600 [08:46<18:10,  2.25it/s]2026-01-18 22:14:59,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1148/3600 [08:46<17:20,  2.36it/s]2026-01-18 22:14:59,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1149/3600 [08:47<16:43,  2.44it/s]2026-01-18 22:14:59,852 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1150/3600 [08:47<17:08,  2.38it/s]2026-01-18 22:15:00,495 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1151/3600 [08:48<19:52,  2.05it/s]2026-01-18 22:15:00,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1152/3600 [08:48<18:53,  2.16it/s]2026-01-18 22:15:01,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1153/3600 [08:49<18:48,  2.17it/s]2026-01-18 22:15:01,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1154/3600 [08:49<17:59,  2.27it/s]2026-01-18 22:15:02,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1155/3600 [08:49<18:33,  2.20it/s]2026-01-18 22:15:02,630 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1156/3600 [08:50<17:43,  2.30it/s]2026-01-18 22:15:03,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1157/3600 [08:50<17:41,  2.30it/s]2026-01-18 22:15:03,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1158/3600 [08:51<18:16,  2.23it/s]2026-01-18 22:15:03,952 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1159/3600 [08:51<17:42,  2.30it/s]2026-01-18 22:15:04,405 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1160/3600 [08:52<17:54,  2.27it/s]2026-01-18 22:15:04,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1161/3600 [08:52<17:38,  2.30it/s]2026-01-18 22:15:05,214 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1162/3600 [08:52<17:07,  2.37it/s]2026-01-18 22:15:05,676 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1163/3600 [08:53<17:34,  2.31it/s]2026-01-18 22:15:06,078 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1164/3600 [08:53<17:15,  2.35it/s]2026-01-18 22:15:06,633 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1165/3600 [08:54<18:50,  2.15it/s]2026-01-18 22:15:07,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1166/3600 [08:54<18:27,  2.20it/s]2026-01-18 22:15:07,544 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1167/3600 [08:55<18:43,  2.17it/s]2026-01-18 22:15:08,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1168/3600 [08:56<24:14,  1.67it/s]2026-01-18 22:15:08,897 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▏      | 1169/3600 [08:56<22:15,  1.82it/s]2026-01-18 22:15:09,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  32%|███▎      | 1170/3600 [08:57<20:22,  1.99it/s]2026-01-18 22:15:09,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1171/3600 [08:57<21:35,  1.87it/s]2026-01-18 22:15:10,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1172/3600 [08:58<20:19,  1.99it/s]2026-01-18 22:15:11,008 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1173/3600 [08:58<22:26,  1.80it/s]2026-01-18 22:15:11,473 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1174/3600 [08:59<21:22,  1.89it/s]2026-01-18 22:15:11,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1175/3600 [08:59<19:24,  2.08it/s]2026-01-18 22:15:12,442 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1176/3600 [09:00<20:52,  1.94it/s]2026-01-18 22:15:13,030 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1177/3600 [09:00<21:41,  1.86it/s]2026-01-18 22:15:13,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1178/3600 [09:01<21:03,  1.92it/s]2026-01-18 22:15:13,900 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1179/3600 [09:01<19:41,  2.05it/s]2026-01-18 22:15:14,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1180/3600 [09:02<19:17,  2.09it/s]2026-01-18 22:15:14,805 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1181/3600 [09:02<18:41,  2.16it/s]2026-01-18 22:15:15,204 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1182/3600 [09:02<17:51,  2.26it/s]2026-01-18 22:15:15,599 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1183/3600 [09:03<17:22,  2.32it/s]2026-01-18 22:15:15,991 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1184/3600 [09:03<16:50,  2.39it/s]2026-01-18 22:15:16,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1185/3600 [09:04<17:05,  2.36it/s]2026-01-18 22:15:16,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1186/3600 [09:04<17:08,  2.35it/s]2026-01-18 22:15:17,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1187/3600 [09:04<16:21,  2.46it/s]2026-01-18 22:15:17,629 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1188/3600 [09:05<16:21,  2.46it/s]2026-01-18 22:15:18,124 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1189/3600 [09:05<17:20,  2.32it/s]2026-01-18 22:15:18,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1190/3600 [09:06<17:01,  2.36it/s]2026-01-18 22:15:19,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1191/3600 [09:06<17:35,  2.28it/s]2026-01-18 22:15:19,409 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1192/3600 [09:07<17:14,  2.33it/s]2026-01-18 22:15:19,962 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1193/3600 [09:07<18:42,  2.15it/s]2026-01-18 22:15:20,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1194/3600 [09:08<18:08,  2.21it/s]2026-01-18 22:15:20,764 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1195/3600 [09:08<17:20,  2.31it/s]2026-01-18 22:15:21,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1196/3600 [09:08<17:02,  2.35it/s]2026-01-18 22:15:21,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1197/3600 [09:09<16:19,  2.45it/s]2026-01-18 22:15:21,977 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1198/3600 [09:09<16:40,  2.40it/s]2026-01-18 22:15:22,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1199/3600 [09:10<17:10,  2.33it/s]2026-01-18 22:15:22,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n\rEvaluating:  33%|███▎      | 1200/3600 [09:10<16:51,  2.37it/s]2026-01-18 22:15:22,947 - INFO -     Accuracy: 74.00% (74/100)\n2026-01-18 22:15:22,947 - INFO - \nEvaluating model: claude-sonnet-4.5\n2026-01-18 22:15:22,948 - INFO -   Language: en\n\rEvaluating:  33%|███▎      | 1201/3600 [09:12<38:26,  1.04it/s]\rEvaluating:  33%|███▎      | 1202/3600 [09:14<42:20,  1.06s/it]\rEvaluating:  33%|███▎      | 1203/3600 [09:15<41:03,  1.03s/it]\rEvaluating:  33%|███▎      | 1204/3600 [09:16<48:05,  1.20s/it]\rEvaluating:  33%|███▎      | 1205/3600 [09:18<54:47,  1.37s/it]\rEvaluating:  34%|███▎      | 1206/3600 [09:20<59:50,  1.50s/it]\rEvaluating:  34%|███▎      | 1207/3600 [09:21<1:02:34,  1.57s/it]\rEvaluating:  34%|███▎      | 1208/3600 [09:23<1:07:45,  1.70s/it]\rEvaluating:  34%|███▎      | 1209/3600 [09:25<1:11:26,  1.79s/it]\rEvaluating:  34%|███▎      | 1210/3600 [09:28<1:17:31,  1.95s/it]\rEvaluating:  34%|███▎      | 1211/3600 [09:29<1:09:26,  1.74s/it]\rEvaluating:  34%|███▎      | 1212/3600 [09:30<1:02:13,  1.56s/it]\rEvaluating:  34%|███▎      | 1213/3600 [09:31<57:17,  1.44s/it]  \rEvaluating:  34%|███▎      | 1214/3600 [09:34<1:12:27,  1.82s/it]\rEvaluating:  34%|███▍      | 1215/3600 [09:37<1:21:29,  2.05s/it]\rEvaluating:  34%|███▍      | 1216/3600 [09:38<1:10:32,  1.78s/it]\rEvaluating:  34%|███▍      | 1217/3600 [09:40<1:18:00,  1.96s/it]\rEvaluating:  34%|███▍      | 1218/3600 [09:42<1:11:35,  1.80s/it]\rEvaluating:  34%|███▍      | 1219/3600 [09:44<1:13:39,  1.86s/it]\rEvaluating:  34%|███▍      | 1220/3600 [09:45<1:06:39,  1.68s/it]\rEvaluating:  34%|███▍      | 1221/3600 [09:47<1:08:41,  1.73s/it]\rEvaluating:  34%|███▍      | 1222/3600 [09:49<1:18:09,  1.97s/it]\rEvaluating:  34%|███▍      | 1223/3600 [09:51<1:11:54,  1.82s/it]\rEvaluating:  34%|███▍      | 1224/3600 [09:52<1:11:49,  1.81s/it]\rEvaluating:  34%|███▍      | 1225/3600 [09:54<1:11:48,  1.81s/it]\rEvaluating:  34%|███▍      | 1226/3600 [09:56<1:08:02,  1.72s/it]\rEvaluating:  34%|███▍      | 1227/3600 [09:57<1:01:24,  1.55s/it]\rEvaluating:  34%|███▍      | 1228/3600 [09:59<1:05:06,  1.65s/it]\rEvaluating:  34%|███▍      | 1229/3600 [10:01<1:10:44,  1.79s/it]\rEvaluating:  34%|███▍      | 1230/3600 [10:03<1:13:11,  1.85s/it]\rEvaluating:  34%|███▍      | 1231/3600 [10:05<1:15:20,  1.91s/it]\rEvaluating:  34%|███▍      | 1232/3600 [10:07<1:11:12,  1.80s/it]\rEvaluating:  34%|███▍      | 1233/3600 [10:09<1:17:46,  1.97s/it]\rEvaluating:  34%|███▍      | 1234/3600 [10:10<1:07:45,  1.72s/it]\rEvaluating:  34%|███▍      | 1235/3600 [10:12<1:05:59,  1.67s/it]\rEvaluating:  34%|███▍      | 1236/3600 [10:14<1:09:50,  1.77s/it]\rEvaluating:  34%|███▍      | 1237/3600 [10:15<1:02:51,  1.60s/it]\rEvaluating:  34%|███▍      | 1238/3600 [10:16<57:00,  1.45s/it]  \rEvaluating:  34%|███▍      | 1239/3600 [10:18<1:00:22,  1.53s/it]\rEvaluating:  34%|███▍      | 1240/3600 [10:20<1:14:02,  1.88s/it]\rEvaluating:  34%|███▍      | 1241/3600 [10:22<1:11:31,  1.82s/it]\rEvaluating:  34%|███▍      | 1242/3600 [10:23<1:04:27,  1.64s/it]\rEvaluating:  35%|███▍      | 1243/3600 [10:25<1:01:17,  1.56s/it]\rEvaluating:  35%|███▍      | 1244/3600 [10:26<1:04:16,  1.64s/it]\rEvaluating:  35%|███▍      | 1245/3600 [10:29<1:11:00,  1.81s/it]\rEvaluating:  35%|███▍      | 1246/3600 [10:31<1:14:14,  1.89s/it]\rEvaluating:  35%|███▍      | 1247/3600 [10:33<1:16:38,  1.95s/it]\rEvaluating:  35%|███▍      | 1248/3600 [10:34<1:11:19,  1.82s/it]\rEvaluating:  35%|███▍      | 1249/3600 [10:35<1:02:38,  1.60s/it]\rEvaluating:  35%|███▍      | 1250/3600 [10:38<1:17:04,  1.97s/it]\rEvaluating:  35%|███▍      | 1251/3600 [10:41<1:22:32,  2.11s/it]\rEvaluating:  35%|███▍      | 1252/3600 [10:42<1:08:25,  1.75s/it]\rEvaluating:  35%|███▍      | 1253/3600 [10:43<1:08:23,  1.75s/it]\rEvaluating:  35%|███▍      | 1254/3600 [10:45<1:02:31,  1.60s/it]\rEvaluating:  35%|███▍      | 1255/3600 [10:46<1:05:12,  1.67s/it]\rEvaluating:  35%|███▍      | 1256/3600 [10:48<1:00:14,  1.54s/it]\rEvaluating:  35%|███▍      | 1257/3600 [10:50<1:13:05,  1.87s/it]\rEvaluating:  35%|███▍      | 1258/3600 [10:53<1:22:04,  2.10s/it]\rEvaluating:  35%|███▍      | 1259/3600 [10:54<1:15:01,  1.92s/it]\rEvaluating:  35%|███▌      | 1260/3600 [10:56<1:08:51,  1.77s/it]\rEvaluating:  35%|███▌      | 1261/3600 [10:58<1:08:52,  1.77s/it]\rEvaluating:  35%|███▌      | 1262/3600 [11:00<1:14:24,  1.91s/it]\rEvaluating:  35%|███▌      | 1263/3600 [11:02<1:12:22,  1.86s/it]\rEvaluating:  35%|███▌      | 1264/3600 [11:03<1:04:31,  1.66s/it]\rEvaluating:  35%|███▌      | 1265/3600 [11:04<1:00:03,  1.54s/it]\rEvaluating:  35%|███▌      | 1266/3600 [11:05<54:54,  1.41s/it]  \rEvaluating:  35%|███▌      | 1267/3600 [11:08<1:07:01,  1.72s/it]\rEvaluating:  35%|███▌      | 1268/3600 [11:09<1:05:34,  1.69s/it]\rEvaluating:  35%|███▌      | 1269/3600 [11:11<1:10:39,  1.82s/it]\rEvaluating:  35%|███▌      | 1270/3600 [11:14<1:16:11,  1.96s/it]\rEvaluating:  35%|███▌      | 1271/3600 [11:15<1:06:05,  1.70s/it]\rEvaluating:  35%|███▌      | 1272/3600 [11:17<1:07:02,  1.73s/it]\rEvaluating:  35%|███▌      | 1273/3600 [11:18<1:05:56,  1.70s/it]\rEvaluating:  35%|███▌      | 1274/3600 [11:20<1:06:13,  1.71s/it]\rEvaluating:  35%|███▌      | 1275/3600 [11:22<1:15:42,  1.95s/it]\rEvaluating:  35%|███▌      | 1276/3600 [11:24<1:05:48,  1.70s/it]\rEvaluating:  35%|███▌      | 1277/3600 [11:26<1:09:27,  1.79s/it]\rEvaluating:  36%|███▌      | 1278/3600 [11:27<1:03:06,  1.63s/it]\rEvaluating:  36%|███▌      | 1279/3600 [11:28<1:01:03,  1.58s/it]\rEvaluating:  36%|███▌      | 1280/3600 [11:30<1:06:39,  1.72s/it]\rEvaluating:  36%|███▌      | 1281/3600 [11:32<1:02:34,  1.62s/it]\rEvaluating:  36%|███▌      | 1282/3600 [11:33<58:41,  1.52s/it]  \rEvaluating:  36%|███▌      | 1283/3600 [11:34<53:28,  1.38s/it]\rEvaluating:  36%|███▌      | 1284/3600 [11:35<49:03,  1.27s/it]\rEvaluating:  36%|███▌      | 1285/3600 [11:37<1:02:26,  1.62s/it]\rEvaluating:  36%|███▌      | 1286/3600 [11:40<1:12:44,  1.89s/it]\rEvaluating:  36%|███▌      | 1287/3600 [11:42<1:14:15,  1.93s/it]\rEvaluating:  36%|███▌      | 1288/3600 [11:43<1:06:34,  1.73s/it]\rEvaluating:  36%|███▌      | 1289/3600 [11:45<1:09:14,  1.80s/it]\rEvaluating:  36%|███▌      | 1290/3600 [11:48<1:16:35,  1.99s/it]\rEvaluating:  36%|███▌      | 1291/3600 [11:49<1:13:01,  1.90s/it]\rEvaluating:  36%|███▌      | 1292/3600 [11:52<1:16:36,  1.99s/it]\rEvaluating:  36%|███▌      | 1293/3600 [11:53<1:11:10,  1.85s/it]\rEvaluating:  36%|███▌      | 1294/3600 [11:55<1:11:48,  1.87s/it]\rEvaluating:  36%|███▌      | 1295/3600 [11:56<1:03:05,  1.64s/it]\rEvaluating:  36%|███▌      | 1296/3600 [11:57<58:39,  1.53s/it]  \rEvaluating:  36%|███▌      | 1297/3600 [11:59<1:02:25,  1.63s/it]\rEvaluating:  36%|███▌      | 1298/3600 [12:02<1:10:54,  1.85s/it]\rEvaluating:  36%|███▌      | 1299/3600 [12:03<1:05:52,  1.72s/it]\rEvaluating:  36%|███▌      | 1300/3600 [12:04<1:02:49,  1.64s/it]2026-01-18 22:18:17,324 - INFO -     Accuracy: 69.00% (69/100)\n2026-01-18 22:18:17,324 - INFO -   Language: zh\n\rEvaluating:  36%|███▌      | 1301/3600 [12:06<1:00:48,  1.59s/it]\rEvaluating:  36%|███▌      | 1302/3600 [12:07<56:55,  1.49s/it]  \rEvaluating:  36%|███▌      | 1303/3600 [12:09<1:03:25,  1.66s/it]\rEvaluating:  36%|███▌      | 1304/3600 [12:11<59:45,  1.56s/it]  \rEvaluating:  36%|███▋      | 1305/3600 [12:12<53:35,  1.40s/it]\rEvaluating:  36%|███▋      | 1306/3600 [12:13<54:11,  1.42s/it]\rEvaluating:  36%|███▋      | 1307/3600 [12:15<58:54,  1.54s/it]\rEvaluating:  36%|███▋      | 1308/3600 [12:16<58:16,  1.53s/it]\rEvaluating:  36%|███▋      | 1309/3600 [12:18<55:40,  1.46s/it]\rEvaluating:  36%|███▋      | 1310/3600 [12:20<1:08:49,  1.80s/it]\rEvaluating:  36%|███▋      | 1311/3600 [12:23<1:21:20,  2.13s/it]\rEvaluating:  36%|███▋      | 1312/3600 [12:25<1:17:29,  2.03s/it]\rEvaluating:  36%|███▋      | 1313/3600 [12:27<1:19:56,  2.10s/it]\rEvaluating:  36%|███▋      | 1314/3600 [12:28<1:09:10,  1.82s/it]\rEvaluating:  37%|███▋      | 1315/3600 [12:30<1:01:26,  1.61s/it]\rEvaluating:  37%|███▋      | 1316/3600 [12:32<1:07:29,  1.77s/it]\rEvaluating:  37%|███▋      | 1317/3600 [12:34<1:17:03,  2.03s/it]\rEvaluating:  37%|███▋      | 1318/3600 [12:36<1:10:26,  1.85s/it]\rEvaluating:  37%|███▋      | 1319/3600 [12:38<1:17:33,  2.04s/it]\rEvaluating:  37%|███▋      | 1320/3600 [12:39<1:06:56,  1.76s/it]\rEvaluating:  37%|███▋      | 1321/3600 [12:41<1:08:30,  1.80s/it]\rEvaluating:  37%|███▋      | 1322/3600 [12:43<1:07:19,  1.77s/it]\rEvaluating:  37%|███▋      | 1323/3600 [12:44<1:02:42,  1.65s/it]\rEvaluating:  37%|███▋      | 1324/3600 [12:46<1:07:58,  1.79s/it]\rEvaluating:  37%|███▋      | 1325/3600 [12:49<1:11:36,  1.89s/it]\rEvaluating:  37%|███▋      | 1326/3600 [12:51<1:14:46,  1.97s/it]\rEvaluating:  37%|███▋      | 1327/3600 [12:53<1:14:11,  1.96s/it]\rEvaluating:  37%|███▋      | 1328/3600 [12:54<1:12:00,  1.90s/it]\rEvaluating:  37%|███▋      | 1329/3600 [12:57<1:19:11,  2.09s/it]\rEvaluating:  37%|███▋      | 1330/3600 [13:00<1:26:22,  2.28s/it]\rEvaluating:  37%|███▋      | 1331/3600 [13:01<1:16:38,  2.03s/it]\rEvaluating:  37%|███▋      | 1332/3600 [13:02<1:06:38,  1.76s/it]\rEvaluating:  37%|███▋      | 1333/3600 [13:05<1:16:42,  2.03s/it]\rEvaluating:  37%|███▋      | 1334/3600 [13:06<1:03:57,  1.69s/it]\rEvaluating:  37%|███▋      | 1335/3600 [13:08<1:09:37,  1.84s/it]\rEvaluating:  37%|███▋      | 1336/3600 [13:10<1:10:32,  1.87s/it]\rEvaluating:  37%|███▋      | 1337/3600 [13:11<1:00:14,  1.60s/it]\rEvaluating:  37%|███▋      | 1338/3600 [13:13<1:01:38,  1.63s/it]\rEvaluating:  37%|███▋      | 1339/3600 [13:15<1:07:40,  1.80s/it]\rEvaluating:  37%|███▋      | 1340/3600 [13:17<1:12:37,  1.93s/it]\rEvaluating:  37%|███▋      | 1341/3600 [13:18<1:06:52,  1.78s/it]\rEvaluating:  37%|███▋      | 1342/3600 [13:20<1:03:46,  1.69s/it]\rEvaluating:  37%|███▋      | 1343/3600 [13:22<1:05:47,  1.75s/it]\rEvaluating:  37%|███▋      | 1344/3600 [13:24<1:06:04,  1.76s/it]\rEvaluating:  37%|███▋      | 1345/3600 [13:26<1:11:55,  1.91s/it]\rEvaluating:  37%|███▋      | 1346/3600 [13:28<1:15:07,  2.00s/it]\rEvaluating:  37%|███▋      | 1347/3600 [13:30<1:15:31,  2.01s/it]\rEvaluating:  37%|███▋      | 1348/3600 [13:32<1:17:02,  2.05s/it]\rEvaluating:  37%|███▋      | 1349/3600 [13:33<1:06:03,  1.76s/it]\rEvaluating:  38%|███▊      | 1350/3600 [13:35<1:02:10,  1.66s/it]\rEvaluating:  38%|███▊      | 1351/3600 [13:36<1:00:28,  1.61s/it]\rEvaluating:  38%|███▊      | 1352/3600 [13:39<1:07:40,  1.81s/it]\rEvaluating:  38%|███▊      | 1353/3600 [13:41<1:11:25,  1.91s/it]\rEvaluating:  38%|███▊      | 1354/3600 [13:42<1:07:12,  1.80s/it]\rEvaluating:  38%|███▊      | 1355/3600 [13:43<56:58,  1.52s/it]  \rEvaluating:  38%|███▊      | 1356/3600 [13:44<52:41,  1.41s/it]\rEvaluating:  38%|███▊      | 1357/3600 [13:46<55:44,  1.49s/it]\rEvaluating:  38%|███▊      | 1358/3600 [13:47<52:55,  1.42s/it]\rEvaluating:  38%|███▊      | 1359/3600 [13:48<51:37,  1.38s/it]\rEvaluating:  38%|███▊      | 1360/3600 [13:50<58:58,  1.58s/it]\rEvaluating:  38%|███▊      | 1361/3600 [13:53<1:06:50,  1.79s/it]\rEvaluating:  38%|███▊      | 1362/3600 [13:54<1:01:29,  1.65s/it]\rEvaluating:  38%|███▊      | 1363/3600 [13:57<1:12:50,  1.95s/it]\rEvaluating:  38%|███▊      | 1364/3600 [13:58<1:01:17,  1.64s/it]\rEvaluating:  38%|███▊      | 1365/3600 [13:59<1:01:59,  1.66s/it]\rEvaluating:  38%|███▊      | 1366/3600 [14:00<55:28,  1.49s/it]  \rEvaluating:  38%|███▊      | 1367/3600 [14:02<54:33,  1.47s/it]\rEvaluating:  38%|███▊      | 1368/3600 [14:03<50:55,  1.37s/it]\rEvaluating:  38%|███▊      | 1369/3600 [14:04<51:32,  1.39s/it]\rEvaluating:  38%|███▊      | 1370/3600 [14:06<48:41,  1.31s/it]\rEvaluating:  38%|███▊      | 1371/3600 [14:07<45:48,  1.23s/it]\rEvaluating:  38%|███▊      | 1372/3600 [14:08<43:22,  1.17s/it]\rEvaluating:  38%|███▊      | 1373/3600 [14:09<42:10,  1.14s/it]\rEvaluating:  38%|███▊      | 1374/3600 [14:10<44:28,  1.20s/it]\rEvaluating:  38%|███▊      | 1375/3600 [14:11<43:41,  1.18s/it]\rEvaluating:  38%|███▊      | 1376/3600 [14:12<40:58,  1.11s/it]\rEvaluating:  38%|███▊      | 1377/3600 [14:13<40:30,  1.09s/it]\rEvaluating:  38%|███▊      | 1378/3600 [14:14<42:03,  1.14s/it]\rEvaluating:  38%|███▊      | 1379/3600 [14:17<53:15,  1.44s/it]\rEvaluating:  38%|███▊      | 1380/3600 [14:18<51:28,  1.39s/it]\rEvaluating:  38%|███▊      | 1381/3600 [14:20<58:21,  1.58s/it]\rEvaluating:  38%|███▊      | 1382/3600 [14:22<59:33,  1.61s/it]\rEvaluating:  38%|███▊      | 1383/3600 [14:23<1:01:34,  1.67s/it]\rEvaluating:  38%|███▊      | 1384/3600 [14:25<57:09,  1.55s/it]  \rEvaluating:  38%|███▊      | 1385/3600 [14:26<53:34,  1.45s/it]\rEvaluating:  38%|███▊      | 1386/3600 [14:28<58:51,  1.60s/it]\rEvaluating:  39%|███▊      | 1387/3600 [14:29<54:37,  1.48s/it]\rEvaluating:  39%|███▊      | 1388/3600 [14:30<51:43,  1.40s/it]\rEvaluating:  39%|███▊      | 1389/3600 [14:31<48:15,  1.31s/it]\rEvaluating:  39%|███▊      | 1390/3600 [14:33<47:38,  1.29s/it]\rEvaluating:  39%|███▊      | 1391/3600 [14:34<54:00,  1.47s/it]\rEvaluating:  39%|███▊      | 1392/3600 [14:36<59:33,  1.62s/it]\rEvaluating:  39%|███▊      | 1393/3600 [14:40<1:18:10,  2.13s/it]\rEvaluating:  39%|███▊      | 1394/3600 [14:41<1:08:44,  1.87s/it]\rEvaluating:  39%|███▉      | 1395/3600 [14:42<58:16,  1.59s/it]  \rEvaluating:  39%|███▉      | 1396/3600 [14:45<1:10:52,  1.93s/it]\rEvaluating:  39%|███▉      | 1397/3600 [14:46<1:06:57,  1.82s/it]\rEvaluating:  39%|███▉      | 1398/3600 [14:48<1:07:41,  1.84s/it]\rEvaluating:  39%|███▉      | 1399/3600 [14:49<1:01:34,  1.68s/it]\rEvaluating:  39%|███▉      | 1400/3600 [14:52<1:13:11,  2.00s/it]2026-01-18 22:21:05,015 - INFO -     Accuracy: 59.00% (59/100)\n2026-01-18 22:21:05,016 - INFO -   Language: es\n\rEvaluating:  39%|███▉      | 1401/3600 [14:53<1:03:42,  1.74s/it]\rEvaluating:  39%|███▉      | 1402/3600 [14:55<59:12,  1.62s/it]  \rEvaluating:  39%|███▉      | 1403/3600 [14:57<1:02:42,  1.71s/it]\rEvaluating:  39%|███▉      | 1404/3600 [14:59<1:05:50,  1.80s/it]\rEvaluating:  39%|███▉      | 1405/3600 [14:59<56:09,  1.54s/it]  \rEvaluating:  39%|███▉      | 1406/3600 [15:01<53:25,  1.46s/it]\rEvaluating:  39%|███▉      | 1407/3600 [15:02<53:07,  1.45s/it]\rEvaluating:  39%|███▉      | 1408/3600 [15:03<50:31,  1.38s/it]\rEvaluating:  39%|███▉      | 1409/3600 [15:06<1:01:57,  1.70s/it]\rEvaluating:  39%|███▉      | 1410/3600 [15:08<1:06:23,  1.82s/it]\rEvaluating:  39%|███▉      | 1411/3600 [15:09<59:04,  1.62s/it]  \rEvaluating:  39%|███▉      | 1412/3600 [15:10<55:38,  1.53s/it]\rEvaluating:  39%|███▉      | 1413/3600 [15:12<52:10,  1.43s/it]\rEvaluating:  39%|███▉      | 1414/3600 [15:13<56:31,  1.55s/it]\rEvaluating:  39%|███▉      | 1415/3600 [15:16<1:06:27,  1.82s/it]\rEvaluating:  39%|███▉      | 1416/3600 [15:18<1:09:50,  1.92s/it]\rEvaluating:  39%|███▉      | 1417/3600 [15:20<1:06:17,  1.82s/it]\rEvaluating:  39%|███▉      | 1418/3600 [15:21<57:53,  1.59s/it]  \rEvaluating:  39%|███▉      | 1419/3600 [15:23<1:01:54,  1.70s/it]\rEvaluating:  39%|███▉      | 1420/3600 [15:24<1:00:36,  1.67s/it]\rEvaluating:  39%|███▉      | 1421/3600 [15:26<1:03:43,  1.75s/it]\rEvaluating:  40%|███▉      | 1422/3600 [15:29<1:10:13,  1.93s/it]\rEvaluating:  40%|███▉      | 1423/3600 [15:30<1:07:29,  1.86s/it]\rEvaluating:  40%|███▉      | 1424/3600 [15:32<1:09:49,  1.93s/it]\rEvaluating:  40%|███▉      | 1425/3600 [15:33<1:00:59,  1.68s/it]\rEvaluating:  40%|███▉      | 1426/3600 [15:35<54:20,  1.50s/it]  \rEvaluating:  40%|███▉      | 1427/3600 [15:36<51:00,  1.41s/it]\rEvaluating:  40%|███▉      | 1428/3600 [15:37<51:35,  1.42s/it]\rEvaluating:  40%|███▉      | 1429/3600 [15:38<48:45,  1.35s/it]\rEvaluating:  40%|███▉      | 1430/3600 [15:39<44:08,  1.22s/it]\rEvaluating:  40%|███▉      | 1431/3600 [15:41<54:37,  1.51s/it]\rEvaluating:  40%|███▉      | 1432/3600 [15:44<1:05:28,  1.81s/it]\rEvaluating:  40%|███▉      | 1433/3600 [15:45<1:00:01,  1.66s/it]\rEvaluating:  40%|███▉      | 1434/3600 [15:47<1:01:14,  1.70s/it]\rEvaluating:  40%|███▉      | 1435/3600 [15:48<56:55,  1.58s/it]  \rEvaluating:  40%|███▉      | 1436/3600 [15:50<54:20,  1.51s/it]\rEvaluating:  40%|███▉      | 1437/3600 [15:51<54:37,  1.52s/it]\rEvaluating:  40%|███▉      | 1438/3600 [15:52<48:47,  1.35s/it]\rEvaluating:  40%|███▉      | 1439/3600 [15:54<49:55,  1.39s/it]\rEvaluating:  40%|████      | 1440/3600 [15:55<50:01,  1.39s/it]\rEvaluating:  40%|████      | 1441/3600 [15:57<58:41,  1.63s/it]\rEvaluating:  40%|████      | 1442/3600 [15:59<59:11,  1.65s/it]\rEvaluating:  40%|████      | 1443/3600 [16:00<57:44,  1.61s/it]\rEvaluating:  40%|████      | 1444/3600 [16:02<57:59,  1.61s/it]\rEvaluating:  40%|████      | 1445/3600 [16:03<54:27,  1.52s/it]\rEvaluating:  40%|████      | 1446/3600 [16:05<52:20,  1.46s/it]\rEvaluating:  40%|████      | 1447/3600 [16:06<53:13,  1.48s/it]\rEvaluating:  40%|████      | 1448/3600 [16:08<55:15,  1.54s/it]\rEvaluating:  40%|████      | 1449/3600 [16:10<1:02:38,  1.75s/it]\rEvaluating:  40%|████      | 1450/3600 [16:12<1:06:30,  1.86s/it]\rEvaluating:  40%|████      | 1451/3600 [16:14<1:08:50,  1.92s/it]\rEvaluating:  40%|████      | 1452/3600 [16:16<1:03:34,  1.78s/it]\rEvaluating:  40%|████      | 1453/3600 [16:17<59:00,  1.65s/it]  \rEvaluating:  40%|████      | 1454/3600 [16:18<50:37,  1.42s/it]\rEvaluating:  40%|████      | 1455/3600 [16:20<55:44,  1.56s/it]\rEvaluating:  40%|████      | 1456/3600 [16:21<52:14,  1.46s/it]\rEvaluating:  40%|████      | 1457/3600 [16:23<58:53,  1.65s/it]\rEvaluating:  40%|████      | 1458/3600 [16:24<54:06,  1.52s/it]\rEvaluating:  41%|████      | 1459/3600 [16:26<53:00,  1.49s/it]\rEvaluating:  41%|████      | 1460/3600 [16:27<50:19,  1.41s/it]\rEvaluating:  41%|████      | 1461/3600 [16:28<47:09,  1.32s/it]\rEvaluating:  41%|████      | 1462/3600 [16:29<46:19,  1.30s/it]\rEvaluating:  41%|████      | 1463/3600 [16:31<45:02,  1.26s/it]\rEvaluating:  41%|████      | 1464/3600 [16:33<58:59,  1.66s/it]\rEvaluating:  41%|████      | 1465/3600 [16:34<52:58,  1.49s/it]\rEvaluating:  41%|████      | 1466/3600 [16:35<48:11,  1.35s/it]\rEvaluating:  41%|████      | 1467/3600 [16:37<56:29,  1.59s/it]\rEvaluating:  41%|████      | 1468/3600 [16:39<53:07,  1.49s/it]\rEvaluating:  41%|████      | 1469/3600 [16:40<55:18,  1.56s/it]\rEvaluating:  41%|████      | 1470/3600 [16:41<48:56,  1.38s/it]\rEvaluating:  41%|████      | 1471/3600 [16:43<51:11,  1.44s/it]\rEvaluating:  41%|████      | 1472/3600 [16:45<59:38,  1.68s/it]\rEvaluating:  41%|████      | 1473/3600 [16:47<56:07,  1.58s/it]\rEvaluating:  41%|████      | 1474/3600 [16:49<1:06:44,  1.88s/it]\rEvaluating:  41%|████      | 1475/3600 [16:51<1:01:26,  1.74s/it]\rEvaluating:  41%|████      | 1476/3600 [16:52<58:37,  1.66s/it]  \rEvaluating:  41%|████      | 1477/3600 [16:53<53:42,  1.52s/it]\rEvaluating:  41%|████      | 1478/3600 [16:54<48:18,  1.37s/it]\rEvaluating:  41%|████      | 1479/3600 [16:56<47:42,  1.35s/it]\rEvaluating:  41%|████      | 1480/3600 [16:58<55:03,  1.56s/it]\rEvaluating:  41%|████      | 1481/3600 [16:59<51:53,  1.47s/it]\rEvaluating:  41%|████      | 1482/3600 [17:01<58:19,  1.65s/it]\rEvaluating:  41%|████      | 1483/3600 [17:03<1:03:41,  1.81s/it]\rEvaluating:  41%|████      | 1484/3600 [17:06<1:13:30,  2.08s/it]\rEvaluating:  41%|████▏     | 1485/3600 [17:07<1:03:44,  1.81s/it]\rEvaluating:  41%|████▏     | 1486/3600 [17:09<1:04:46,  1.84s/it]\rEvaluating:  41%|████▏     | 1487/3600 [17:10<59:17,  1.68s/it]  \rEvaluating:  41%|████▏     | 1488/3600 [17:12<1:03:09,  1.79s/it]\rEvaluating:  41%|████▏     | 1489/3600 [17:14<1:03:59,  1.82s/it]\rEvaluating:  41%|████▏     | 1490/3600 [17:16<59:41,  1.70s/it]  \rEvaluating:  41%|████▏     | 1491/3600 [17:17<59:15,  1.69s/it]\rEvaluating:  41%|████▏     | 1492/3600 [17:19<1:02:56,  1.79s/it]\rEvaluating:  41%|████▏     | 1493/3600 [17:21<58:48,  1.67s/it]  \rEvaluating:  42%|████▏     | 1494/3600 [17:22<50:55,  1.45s/it]\rEvaluating:  42%|████▏     | 1495/3600 [17:23<49:05,  1.40s/it]\rEvaluating:  42%|████▏     | 1496/3600 [17:24<50:15,  1.43s/it]\rEvaluating:  42%|████▏     | 1497/3600 [17:26<53:36,  1.53s/it]\rEvaluating:  42%|████▏     | 1498/3600 [17:28<54:45,  1.56s/it]\rEvaluating:  42%|████▏     | 1499/3600 [17:29<55:07,  1.57s/it]\rEvaluating:  42%|████▏     | 1500/3600 [17:31<58:16,  1.66s/it]2026-01-18 22:23:44,127 - INFO -     Accuracy: 54.00% (54/100)\n2026-01-18 22:23:44,128 - INFO -   Language: fr\n\rEvaluating:  42%|████▏     | 1501/3600 [17:33<1:02:46,  1.79s/it]\rEvaluating:  42%|████▏     | 1502/3600 [17:35<1:01:35,  1.76s/it]\rEvaluating:  42%|████▏     | 1503/3600 [17:36<54:12,  1.55s/it]  \rEvaluating:  42%|████▏     | 1504/3600 [17:37<48:02,  1.38s/it]\rEvaluating:  42%|████▏     | 1505/3600 [17:40<1:00:34,  1.73s/it]\rEvaluating:  42%|████▏     | 1506/3600 [17:41<54:25,  1.56s/it]  \rEvaluating:  42%|████▏     | 1507/3600 [17:42<48:54,  1.40s/it]\rEvaluating:  42%|████▏     | 1508/3600 [17:43<45:17,  1.30s/it]\rEvaluating:  42%|████▏     | 1509/3600 [17:44<44:46,  1.28s/it]\rEvaluating:  42%|████▏     | 1510/3600 [17:45<44:01,  1.26s/it]\rEvaluating:  42%|████▏     | 1511/3600 [17:47<49:24,  1.42s/it]\rEvaluating:  42%|████▏     | 1512/3600 [17:49<52:21,  1.50s/it]\rEvaluating:  42%|████▏     | 1513/3600 [17:50<49:15,  1.42s/it]\rEvaluating:  42%|████▏     | 1514/3600 [17:52<56:09,  1.62s/it]\rEvaluating:  42%|████▏     | 1515/3600 [17:54<54:14,  1.56s/it]\rEvaluating:  42%|████▏     | 1516/3600 [17:55<52:53,  1.52s/it]\rEvaluating:  42%|████▏     | 1517/3600 [17:56<48:17,  1.39s/it]\rEvaluating:  42%|████▏     | 1518/3600 [17:59<59:40,  1.72s/it]\rEvaluating:  42%|████▏     | 1519/3600 [18:00<57:08,  1.65s/it]\rEvaluating:  42%|████▏     | 1520/3600 [18:01<54:32,  1.57s/it]\rEvaluating:  42%|████▏     | 1521/3600 [18:03<49:22,  1.43s/it]\rEvaluating:  42%|████▏     | 1522/3600 [18:04<52:04,  1.50s/it]\rEvaluating:  42%|████▏     | 1523/3600 [18:08<1:10:51,  2.05s/it]\rEvaluating:  42%|████▏     | 1524/3600 [18:09<1:03:23,  1.83s/it]\rEvaluating:  42%|████▏     | 1525/3600 [18:10<56:24,  1.63s/it]  \rEvaluating:  42%|████▏     | 1526/3600 [18:12<1:00:37,  1.75s/it]\rEvaluating:  42%|████▏     | 1527/3600 [18:13<55:59,  1.62s/it]  \rEvaluating:  42%|████▏     | 1528/3600 [18:15<52:48,  1.53s/it]\rEvaluating:  42%|████▏     | 1529/3600 [18:17<57:45,  1.67s/it]\rEvaluating:  42%|████▎     | 1530/3600 [18:18<52:15,  1.51s/it]\rEvaluating:  43%|████▎     | 1531/3600 [18:20<54:14,  1.57s/it]\rEvaluating:  43%|████▎     | 1532/3600 [18:22<1:04:08,  1.86s/it]\rEvaluating:  43%|████▎     | 1533/3600 [18:24<1:08:09,  1.98s/it]\rEvaluating:  43%|████▎     | 1534/3600 [18:26<1:09:25,  2.02s/it]\rEvaluating:  43%|████▎     | 1535/3600 [18:29<1:10:46,  2.06s/it]\rEvaluating:  43%|████▎     | 1536/3600 [18:31<1:10:14,  2.04s/it]\rEvaluating:  43%|████▎     | 1537/3600 [18:32<1:00:26,  1.76s/it]\rEvaluating:  43%|████▎     | 1538/3600 [18:33<56:42,  1.65s/it]  \rEvaluating:  43%|████▎     | 1539/3600 [18:35<1:00:10,  1.75s/it]\rEvaluating:  43%|████▎     | 1540/3600 [18:37<1:03:38,  1.85s/it]\rEvaluating:  43%|████▎     | 1541/3600 [18:40<1:08:57,  2.01s/it]\rEvaluating:  43%|████▎     | 1542/3600 [18:41<1:03:26,  1.85s/it]\rEvaluating:  43%|████▎     | 1543/3600 [18:42<55:17,  1.61s/it]  \rEvaluating:  43%|████▎     | 1544/3600 [18:45<1:07:16,  1.96s/it]\rEvaluating:  43%|████▎     | 1545/3600 [18:47<1:04:40,  1.89s/it]\rEvaluating:  43%|████▎     | 1546/3600 [18:49<1:13:24,  2.14s/it]\rEvaluating:  43%|████▎     | 1547/3600 [18:51<1:05:09,  1.90s/it]\rEvaluating:  43%|████▎     | 1548/3600 [18:53<1:09:29,  2.03s/it]\rEvaluating:  43%|████▎     | 1549/3600 [18:55<1:10:36,  2.07s/it]\rEvaluating:  43%|████▎     | 1550/3600 [18:57<1:07:43,  1.98s/it]\rEvaluating:  43%|████▎     | 1551/3600 [18:58<59:54,  1.75s/it]  \rEvaluating:  43%|████▎     | 1552/3600 [19:00<58:25,  1.71s/it]\rEvaluating:  43%|████▎     | 1553/3600 [19:02<1:04:03,  1.88s/it]\rEvaluating:  43%|████▎     | 1554/3600 [19:04<1:03:26,  1.86s/it]\rEvaluating:  43%|████▎     | 1555/3600 [19:06<1:04:13,  1.88s/it]\rEvaluating:  43%|████▎     | 1556/3600 [19:08<1:04:27,  1.89s/it]\rEvaluating:  43%|████▎     | 1557/3600 [19:09<55:41,  1.64s/it]  \rEvaluating:  43%|████▎     | 1558/3600 [19:11<58:08,  1.71s/it]\rEvaluating:  43%|████▎     | 1559/3600 [19:12<51:36,  1.52s/it]\rEvaluating:  43%|████▎     | 1560/3600 [19:13<51:26,  1.51s/it]\rEvaluating:  43%|████▎     | 1561/3600 [19:15<51:18,  1.51s/it]\rEvaluating:  43%|████▎     | 1562/3600 [19:16<50:25,  1.48s/it]\rEvaluating:  43%|████▎     | 1563/3600 [19:19<1:02:50,  1.85s/it]\rEvaluating:  43%|████▎     | 1564/3600 [19:20<58:16,  1.72s/it]  \rEvaluating:  43%|████▎     | 1565/3600 [19:22<1:03:23,  1.87s/it]\rEvaluating:  44%|████▎     | 1566/3600 [19:24<1:00:00,  1.77s/it]\rEvaluating:  44%|████▎     | 1567/3600 [19:26<1:01:14,  1.81s/it]\rEvaluating:  44%|████▎     | 1568/3600 [19:27<55:37,  1.64s/it]  \rEvaluating:  44%|████▎     | 1569/3600 [19:29<53:22,  1.58s/it]\rEvaluating:  44%|████▎     | 1570/3600 [19:30<51:10,  1.51s/it]\rEvaluating:  44%|████▎     | 1571/3600 [19:32<1:01:46,  1.83s/it]\rEvaluating:  44%|████▎     | 1572/3600 [19:35<1:06:04,  1.95s/it]\rEvaluating:  44%|████▎     | 1573/3600 [19:38<1:14:56,  2.22s/it]\rEvaluating:  44%|████▎     | 1574/3600 [19:39<1:05:41,  1.95s/it]\rEvaluating:  44%|████▍     | 1575/3600 [19:41<1:03:55,  1.89s/it]\rEvaluating:  44%|████▍     | 1576/3600 [19:42<53:54,  1.60s/it]  \rEvaluating:  44%|████▍     | 1577/3600 [19:43<52:15,  1.55s/it]\rEvaluating:  44%|████▍     | 1578/3600 [19:44<46:38,  1.38s/it]\rEvaluating:  44%|████▍     | 1579/3600 [19:45<43:04,  1.28s/it]\rEvaluating:  44%|████▍     | 1580/3600 [19:46<43:07,  1.28s/it]\rEvaluating:  44%|████▍     | 1581/3600 [19:48<49:35,  1.47s/it]\rEvaluating:  44%|████▍     | 1582/3600 [19:49<44:12,  1.31s/it]\rEvaluating:  44%|████▍     | 1583/3600 [19:51<53:26,  1.59s/it]\rEvaluating:  44%|████▍     | 1584/3600 [19:53<48:39,  1.45s/it]\rEvaluating:  44%|████▍     | 1585/3600 [19:54<47:41,  1.42s/it]\rEvaluating:  44%|████▍     | 1586/3600 [19:55<45:28,  1.35s/it]\rEvaluating:  44%|████▍     | 1587/3600 [19:56<45:12,  1.35s/it]\rEvaluating:  44%|████▍     | 1588/3600 [19:58<50:36,  1.51s/it]\rEvaluating:  44%|████▍     | 1589/3600 [19:59<46:36,  1.39s/it]\rEvaluating:  44%|████▍     | 1590/3600 [20:01<44:26,  1.33s/it]\rEvaluating:  44%|████▍     | 1591/3600 [20:02<49:11,  1.47s/it]","exitCode":null}}}
{"type":"assistant","message":{"id":"12ac03fc-1135-4c29-b7c2-0a82c24f239c","container":null,"model":"<synthetic>","role":"assistant","stop_reason":"stop_sequence","stop_sequence":"","type":"message","usage":{"input_tokens":0,"output_tokens":0,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":null,"cache_creation":{"ephemeral_1h_input_tokens":0,"ephemeral_5m_input_tokens":0}},"content":[{"type":"text","text":"Prompt is too long"}],"context_management":null},"parent_tool_use_id":null,"session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","uuid":"9ad11ec3-7f83-487d-8a39-9cceb5baaa6d","error":"invalid_request"}
{"type":"result","subtype":"success","is_error":true,"duration_ms":2105915,"duration_api_ms":429003,"num_turns":41,"result":"Prompt is too long","session_id":"8ed45433-2c52-44e0-b4ef-122e7bd83a86","total_cost_usd":2.9635447499999987,"usage":{"input_tokens":38,"cache_creation_input_tokens":204015,"cache_read_input_tokens":2078476,"output_tokens":16513,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":0,"ephemeral_5m_input_tokens":204015}},"modelUsage":{"claude-haiku-4-5-20251001":{"inputTokens":51863,"outputTokens":2331,"cacheReadInputTokens":0,"cacheCreationInputTokens":0,"webSearchRequests":0,"costUSD":0.06351800000000002,"contextWindow":200000},"claude-opus-4-5-20251101":{"inputTokens":1139,"outputTokens":23200,"cacheReadInputTokens":2078476,"cacheCreationInputTokens":204015,"webSearchRequests":0,"costUSD":2.9000267499999994,"contextWindow":200000}},"permission_denials":[],"uuid":"9efbf53c-96e4-4f69-a4ad-f9bb5a3dedec"}
